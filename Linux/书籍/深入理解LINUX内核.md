## 第1章 绪论

Linux是类Unix (Unix-like)操作系统大家族中的一名成员。1991年，Linus Torvalds开发出最初的Linux，它作为一个适用于基于Intel 80386微处理器的IBM PC兼容机的操作系统。Linux最吸引人的一个优点就在于它不是商业操作系统：它的源代码在GNU公共许可证(General Pwblic License， GPL)下是开放的，任何人都可以获得源代码并研究它。

从技术角度来说，Linux是一个真正的Unix内核，但它不是一个完全的Unix操作系统，这是因为它不包含全部的Unix应用程序，诸如文件系统实用程序、窗口系统及图形化桌面、系统管理员命令、文本编辑程序、编译程序等等。不过，因为以上大部分应用程序都可在GNU许可证下免费获得，因此，可以把它们安装在任何一个基于Linux内核的系统中。

### Linux 和 其他类Unix内核的比较

Linux与一些著名的商用Unix内核到底如何竞争，下面给予描述：

- 单块结构的内核(Monolithic kernel)

  它是一个庞大、复杂的自我完善(do-it-yourself)程序，由几个逻辑上独立的成分构成。在这一点上，它是相当传统的，大多数商用Unix变体也是单块结构。(一个显著的例外是Apple的Mac Os X和GNU的Hurd操作系统，它们都是从卡耐基-梅隆大学的Mach演变而来的，都遵循微内核的方法。)


- 编泽并静态连接的传统Unix内核

  大部分现代操作系统内核可以动态地装载和卸载部分内核代码(典型的例子如设备驱动程序)，通常把这部分代码称做模块(module)。Linux对模块的支持是很好的，因为它能自动按需装载或卸载模块。在主要的商用Unix变体中，只有SVR4.2和Solaris内核有类似的特点。


- 内核线程

  一些Unix内核，如Solaris和SVR4.2/MP，被组织成一组内核线程( kernel thread )。内核线程是一个能被独立调度的执行环境(context)，也许它与用户程序有关，也许仅仅执行一些内核函数。线程之间的上下文切换比普通进程之间的上下文切换花费的代价要少得多，因为前者通常在同一个地址空间执行。Linux以一种十分有限的方式使用内核线程来周期性地执行几个内核函数，但是，它们并不代表基本的执行上下文的抽象(这就是下面要讨论的议题)。


- 多线程应用程序支持

  大多数现代操作系统在某种程度上都支持多线程应用程序，也就是说，这些用户程序是根据很多相对独立的执行流来设计的，而这些执行流之间共享应用程序的大部分数据结构。一个多线程用户程序由很多轻量级进程(lightweight process， LWP)组成，这些进程可能对共同的地址空间、共同的物理内存页、共同的打开文件等等进行操作。Linux定义了自己的轻量级进程版本，这与SVR4， Solaris等其他系统上所使用的类型有所不同。当LWP的所有商用Unix变体都基于内核线程时，Linux却把轻量级进程当作基本的执行上下文，通过非标准的clone()系统调用来处理它们。


- 抢占式(preemptive) 

  当采用“可抢占的内核”选项来编译内核时，Linux2.6可以随意交错执行处于特权模式的执行流。除了Linux 2.6，还有其他一些传统的、通用的Unix系统(如Solaris和Mach3.0)是完全的抢占式内核。S V R4.2/M P通过引入一些固定抢占点(fixed preemption goint)的方法获得有限的抢占能力。


- 多处理器支持

  几种Unix内核变体都利用了多处理器系统。Linux 2.6支持不同存储模式的对称多处理(SMP)，包括NUMA：系统不仅可以使用多处理器，而且每个处理器可以毫无区别地处理任何一个任务。尽管通过一个单独的“大内核锁”使得内核中的少数代码依然串行执行，但公平地说，Linux 2.6以几乎最优化的方式使用SMP。


- 文件系统

  Linux标准文件系统呈现出多种风格。如果你没有特殊需要，就可以使用普通的Ext2文件系统。如果你想避免系统崩溃后冗长的文件系统检查，就可以切换到Ext3。如果你不得不处理很多小文件，ReiserFS文件系统可能就是最好的选择。除了Ext3和ReiserFS，还可以在Linux中使用另外几个日志文件系统，这些文件系统包括IBM AIX的日志文件系统(Journaling File System， JFS)和SGI公司IRIX 系统上的XFS文件系统。有了强大的面向对象虚拟文件系统技术(为Solaris和SVR4所采用)，把外部文件系统移植到Linux比移植到其他内核相对要容易。


- STREAMS

  尽管现在大部分的Unix内核内包含了SRV4引入的STREAMS I/O子系统，并且 已变成编写设备驱动程序、终端驱动程序及网络协议的首选接口，但是Linux并没有与此类似的子系统。

与商业化的操作系统相比，Linux已经具备足够的竞争力。而且，Linux一些独具特色的特点使其成为一种趣味盎然的操作系统。商业化的Unix内核为了赢得更大的市场份额通常也引入了新特征，但这些特征本是可有可无，其稳定性和效率都值得商榷。事实上，现代Unix内核有向更臃肿变化的倾向，而Linux以及其他开放源代码的操作系统不受市场因素的制约，因此可以根据设计者的想法(主要是Linus Torvalds的想法)自由地演进。尤其是，与商用竞争对手相比，Linux有如下优势：

- Linux是免费的。除硬件之外，你无需任何花费就能安装一套完整的Linux系统。

- Linux的所有成分都可以充分地定制。通过内核编译选项，你可以选择自己真正需要的特征来定制内核。
- Linux可以运行在低档、便宜的硬件平台上。你可以用一个4MB内存的旧Intel 80386系统构建网络服务器。
- Linux是强大的。由于充分挖掘了硬件部分的特点，使得Linux系统速度非常快。Linux的主要目标是效率，所以，商用系统的许多设计选择由于有降低性能的隐患而被Linus舍弃，如STREAMSI/O子系统。
- Linux的开发者都是非常出色的程序员。Linux系统非常稳定，有非常低的故障率和非常少系统维护时间。
- Linux内核非常小，而且紧凑。我们甚至可以把一个内核映像和一些系统程序放在一张1.4MB的软盘上!据我们所知，没有一个商用Unix变体能从一张软盘上启动。
- Linux与很多通用操作系统商度兼容。Linux可以让你直接安装以下文件系统的所有版本：MS-DOS和MS Windows， SVR4， OS/2，  Mac OS X， Solaris， SunOS， NEXTSTEP，还有很多BSD变体等等。另外， Linux也能对很多网络层进行操作，这些网络层如以太网[如：快速以太网和高速(Gbit/s及lOGbit/s)以太网]、光纤分布式数据接口(Fiber Distributed Data Interface， FDDI)、高性能并行接口( High Performance Parallel Interface，  HIPPI ) ，  IEEE 802.11(无线局域网)和IEEE802.15(蓝牙)。。通过使用适当的库函数，Linux系统甚至能直接运行为其他操作系统所编写的程序。例如，Linux能执行为以下操作系统所编写的应用程序： MS-DOS，  MS Windows， SVR3及SV R4， 4.4BSD，  SCO Unix， Xenix，以及其他在Intel 80x86平台上运行的操作系统。
- Linux有很好的技术支持。

### 硬件的依赖性

Linux试图在硬件无关的源代码与硬件相关的源代码之间保持清晰的界限。为了做到这点，在arch和include目录下包含了23个子目录，以对应Linux所支持的不同硬件平台。这些平台的标准名字如下：

| 平台            | 简介                                       |
| ------------- | ---------------------------------------- |
| alpha         | HP的Alpha工作站，最早属于Digital公司，后来属于Cpmpag公司，现在不再生产。 |
| arm，arm26     | 基于ARM处理器的计算机（如PDA）和嵌入式设备。                |
| cris          | Axis在它的瘦服务器中使用的“代码精简指令集（Code Reduced Instruction Set）”CPU，用在诸如Web摄像机或开发主板中。 |
| frv           | 基于Fujitsu FR-V系列微处理器的嵌入式系统。              |
| h8300         | Hitachi h8/300 和 h8S的8位和16位RISC微处理器。     |
| i386          | 基于80x86微处理器的IBM兼容个人计算机。                  |
| ia64          | 基于64位Itanium微处理器的工作站。                    |
| m32r          | 基于Renesas M32R系列微处理器的计算机。                |
| m68k，m68nommu | 基于Motorola MC680x0微处理器的个人计算机。            |
| mips          | 基于MIPS微处理器的工作站。                          |
| parisc        | 基于HP公司HP 9000 PA-RISC微处理器的工作站。           |
| ppc，ppc64     | 基于Motorola-IBM PowerPC32位和64位微处理器的工作站。   |
| s390          | IBM ESA/390及zSeries大型机。                  |
| sh，sh64       | 基于Hitachi和STMicroelectronics联合开发的SuperH微处理器的嵌入式系统。 |
| sparc，sparc64 | 基于Sun公司SPARC和64位Ultra SPARC微处理器的工作站。     |
| um            | 用户态的Linux——一个允许开发者在用户态下运行内核的虚拟平台。        |
| v850          | 集成了基于Harvard体系结构的32位RISC核心的NEC V850微控制器。 |
| x86_64        | 基于AMD的64位微处理器的工作站。                       |

### Linux版本

一直到2.5版本的内核，Linux都通过简单的编号来区别内核的稳定版和开发版。每个版本号用三个数字描述，由圆点分隔。前两个数字用来表示版本号，第三个数字表示发布号。第二位版本号表示内核的类型：如果为偶数，表示稳定的内核；否则，表示开发中的内核。

在Linux内核2.6版的开发过程中，内核版本的编号方式发生了很大的变化。主
要变化在于第二个数字已经不再用于表示一个内核是稳定版本还是正在开发的版本。因此，现在内核开发者都在当前的2.6版本中对内核进行大幅改进。只有在内核开发者必须对内核的重大修改进行测试时，才会采用一个新的内核分支。这种分支要么产生一个新的内核版本，要么干脆丢弃所修改的部分而回退到2.6版。

Linux这种新的开发模式意味着两种内核具有相同的版本号，但却有不同的发布号，如2.6.10和2.6.11内核就可能在核心部件和基本算法上有很大的差别。这样一来，具有新发布号的内核可能潜藏着不稳定性和各种错误。为了解决这个问题，内核开发者可能发布带有补丁程序的内核版本，并且用第四位数字表示带有不同补丁的内核版本。例如，2.6.11.12。

必须强调的是本书描述的是Linux2.6.11版的内核。

### 操作系统基本概念

任何计算机系统都包含一个名为操作系统的基本程序集合。在这个集合里，最重要的程序称为内核(kernel)。当操作系统启动时，内核被装入到RAM中，内核中包含了系统运行所必不可少的很多核心过程(procedure)。其他程序是一些不太重要的实用程序，尽管这些程序为用户提供了与计算机进行广泛交流的经验(以及用户买计算机要做的所有工作)，但系统根本的样子和能力还是由内核决定。内核也为系统中所有事情提供了主要功能，并决定高层软件的很多特性。因此，我们将经常使用术语“操作系统”作为“内核”的同义词。操作系统必须完成两个主要目标：

- 与硬件部分交互，为包含在硬件平台上的所有低层可编程部件提供服务。
- 为运行在计算机系统上的应用程序(即所谓用户程序)提供执行环境。

一些操作系统允许所有的用户程序都直接与硬件部分进行交互(典型的例子是MS-DOS)。与此相反，类Unix操作系统把与计算机物理组织相关的所有低层细节都对用户运行的程序隐藏起来。当程序想使用硬件资源时，必须向操作系统发出一个请求。内核对这个请求进行评估，如果允许使用这个资源，那么，内核代表应用程序与相关的硬件部分进行交互。

为了实施这种机制，现代操作系统依靠特殊的硬件特性来禁止用户程序直接与低层硬件部分进行交互，或者禁止直接访问任意的物理地址。特别是，硬件为CPU引入了至少两种不同的执行模式：用户程序的非特权模式和内核的特权模式。Unix把它们分别称为用户态(User Mode)和内核态(Kernel Mode )。

#### 多用户系统

多用户系统(multiuser system)就是一台能并发和独立地执行分别属于两个或多个用户的若干应用程序的计算机。

- “并发”(concurrently)意味着几个应用程序能同时处于活动状态并竟争各种资源，如CPU、内存、硬盘等等。
- “独立”( independently)意味着每个应用程序能执行自己的任务，而无需考虑其他用户的应用程序在干些什么。

当然，从应用程序切换会使每个应用程序的速度有所减慢，从而影响用户看到的响应时间。现代操作系统内核提供的许多复杂特性减少了强加在每个程序上的延迟时间，给用户提供了尽可能快的响应时间。

多用户操作系统必须包含以下几个特点：

- 核实用户身份的认证机制。
- 防止有错误的用户程序防碍其他应用程序在系统中运行的保护机制。
- 防止有恶意的用户程序干涉或窥视其他用户的活动的保护机制。
- 限制分配给每个用户的资源数的计账机制。

为了确保能实现这些安全保护机制，操作系统必须利用与CPU特权模式相关的硬件保护机制，否则，用户程序将能直接访问系统电路并克服强加于它的这些限制。unix是实施系统资源硬件保护的多用户系统。

#### 用户和组

在多用户系统中，每个用户在机器上都有私用空间；典型地，他拥有一定数量的磁盘空间来存储文件、接收私人邮件信息等等。操作系统必须保证用户空间的私有部分仅仅对其拥有者是可见的。特别是必须能保证，没有用户能够开发一个用于侵犯其他用户私有空间的系统应用程序。

所有的用户由一个惟一的数字来标识，这个数字叫用户标识符(User ID，  UID)。通常一个计算机系统只能由有限的人使用。当其中的某个用户开始一个工作会话时，操作系统要求输入一个登录名和口令，如果用户输入的信息无效，则系统拒绝访问。因为口令是不公开的，所以用户的保密性得到了保证。

为了和其他用户有选择地共享资料，每个用户是一个或多个用户组的一名成员，组由唯一的用户组标识符(user group ID)标识。每个文件也恰好与一个组相对应。例如，可以设置这样的访问权限，拥有文件的用户具有对文件的读写权限，同组用户仅有只读权限，而系统中的其他用户没有对文件的任何访问权限。

任何类Unix操作系统都有一个特殊的用户，叫做root，即超级用户(superuser)。系统管理员必须以root的身份登录，以便处理用户账号，完成诸如系统备份、程序升级等维护任务。root用户几乎无所不能，因为操作系统对他不使用通常的保护机制。尤其是，root用户能访向系统中的每一个文件，能干涉每一个正在执行的用户程序的活动。

#### 进程

所有的操作系统都使用一种基本的抽象：进程(process)。一个进程可以定义为：“程序执行时的一个实例”，或者一个运行程序的“执行上下文”。在传统的操作系统中，一个进程在地址空间(address space)中执行一个单独的指令序列。地址空间是允许进程引用的内存地址集合。现代操作系统允许具有多个执行流的进程，也就是说，在相同的地址空间可执行多个指令序列。

多用户系统必须实施一种执行环境，在这种环境里，几个进程能并发活动，并能竟争系统资源(主要是CPU )。允许进程并发活动的系统称为多道程序系统(multiprogramming)或多处理系统(multiprocessing)。区分程序和进程是非常重要的：几个进程能并发地执行同一程序，而同一个进程能顺序地执行几个程序。

在单处理器系统上，只有一个进程能占用CPU，因此，在某一时刻只能有一个执行流。一般来说，CPU的个数总是有限的，因而只有少数几个进程能同时执行。操作系统中叫做调度程序(scheduler)的部分决定哪个进程能执行。一些操作系统只允许有非抢占式(nonpreemptable)进程，这就意味着，只有当进程自愿放弃CPU时，调度程序才被调用。但是，多用户系统中的进程必须是抢占式的(preemptable )。操作系统记录下每个进程占有的CPU时间，并周期性地激活调度程序。

Unix是具有抢占式进程的多处理操作系统。即使没有用户登录，没有程序运行，也还是有几个系统进程在监视外围设备。尤其是，有几个进程在监听系统终端等待用户登录。当用户输人一个登录名，监听进程就运行一个程序来验证用户的口令。如果用户身份得到证实，那么监听进程就创建另一个进程来执行shell，此时在shell下可以输人命令。当一个图形化界面被激活时，有一个进程就运行窗口管理器，界面上的每个窗口通常都由一个单独的进程来执行。如果用户创建了一个图形化shell，那么，一个进程运行图形化窗口，而第二个进程运行用户可以输人命令的shell。对每一个用户命令，shell进程都创建执行相应程序的另一个进程。

Unix操作系统采用进程/内核模式。每个进程都自以为它是系统中唯一的进程，可以独占操作系统所提供的服务。只要进程发出系统调用(即对内核提出请求)，硬件就会把特权模式由用户态变成内核态，然后进程以非常有限的目的开始一个内核过程的执行。这样，操作系统在进程的执行上下文中起作用，以满足进程的请求。一旦这个请求完全得到满足，内核过程将迫使硬件返回到用户态，然后进程从系统调用的下一条指令继续执行。

#### 内核体系结构

如前所述，大部分Unix内核是单块结构：每一个内核层都被集成到整个内核程序中，并代表当前进程在内核态下运行。相反，微内核(microkernel)操作系统只需要内核有一个很小的函数集，通常包括几个同步原语、一个简单的调度程序和进程间通信机制。运行在微内核之上的几个系统进程实现从前操作系统级实现的功能，如内存分配程序、设备驱动程序、系统调用处理程序等等。

尽管关于操作系统的学术研究都是面向微内核的，但这样的操作系统一般比单块内核的效率低，因为操作系统不同层次之间显式的消息传递要花费一定的代价。不过，微内核操作系统比单块内核有一定的理论优势。微内核操作系统迫使系统程序员采用模块化的方法，因为任何操作系统层都是一个相对独立的程序，这种程序必须通过定义明确而清晰的软件接口与其他层交互。此外，已有的微内核操作系统可以很容易地移植到其他的体系结构上，因为所有与硬件相关的部分都被封装进微内核代码中。最后，微内核操作系统比单块内核更加充分地利用了RAM，因为暂且不需要执行的系统进程可以被调出或撤消。

为了达到微内核理论上的很多优点而又不影响性能，Linux内核提供了模块(module) 。模块是一个目标文件，其代码可以在运行时链接到内核或从内核解除链接。这种目标代码通常由一组函数组成，用来实现文件系统、驱动程序或其他内核上层功能。与微内核操作系统的外层不同，模块不是作为一个特殊的进程执行的。相反，与任何其他静态链接的内核函数一样，它代表当前进程在内核态下执行。

使用模块的主要优点包括：

- 摸块化方法

  任何模块都可以在运行时被链接或解除链接，因此，系统程序员必须提出良定义的软件接口以访问由模块处理的数据结构。这使得开发新模块变得容易。

- 平台无关性

  即使模块依赖于某些特殊的硬件特点，但它不依赖于某个固定的硬件平台。例如，符合SCSI标淮的磁盘驱动程序模块，在IBM兼容PC与HP的Alpha机上都能很好地工作。

- 节省内存使用

  当需要模块功能时，把它链接到正在运行的内核中，否则，将该模块解除链接。这种机制对于小型嵌入式系统是非常有用的。

- 无性能损关

  模块的目标代码一旦被链接到内核，其作用与静态链接的内核的目标代码完全等价。因此，当模块的函数被调用时，无需显式地进行消息传递。

### Unix文件系统概述

Unix操作系统的设计集中反映在其文件系统上。

#### 文件

Unix文件是以字节序列组成的信息载体(container)，内核不解释文件的内容。很多编程的库函数实现了更高级的抽象，例如，由字段构成的记录以及基于关键字编址的记录。然而，这些库中的程序必须依靠内核提供的系统调用。从用户的观点来看，文件被组织在一个树结构的命名空间中。

除了叶节点之外，树的所有节点都表示目录名。目录节点包含它下面文件及目录的所有信息。文件或目录名由除“/”和空字符“\0”之外的任意ASCII字符序列组成。大多数文件系统对文件名的长度都有限制，通常不能超过255个字符。与树的根相对应的目录被称为根目录(root directory)。按照惯例，它的名字是“/”。在同一目录中的文件名不能相同，而在不同目录中的文件名可以相同。

Unix的每个进程都有一个当前工作目录，它属于进程执行上下文(execution context)，标识出进程所用的当前目录。为了标识一个特定的文件，进程使用路径名(pcothname )，路径名由斜杠及一列指向文件的目录名交替组成。如果路径名的第一个字符是斜杠，那么这个路径就是所谓的绝对路径，因为它的起点是根目录。否则，如果第一项是目录名或文件名，那么这个路径就是所谓的相对路径，因为它的起点是进程的当前目录。

当标识文件名时，也用符号“.”和“..”。它们分别标识当前工作目录和父目录。如果当前工作目录是根目录，“.”和“..”就是一致的。

#### 硬链接和软链接

包含在目录中的文件名就是一个文件的硬链接(hard link)，或简称链接(Link)。在同一目录或不同的目录中，同一文件可以有几个链接，因此对应几个文件名。

```shell
ln P1 P2
```

用来创建一个新的硬链接，即为由路径P1标识的文件创建一个路径名为P2的硬链接。
硬链接有两方面的限制：

- 不允许用户给目录创建硬链接。因为这可能把目录树变为环形图，从而就不可能通过名字定位一个文件。
- 只有在同一文件系统中的文件之间才能创建链接。这带来比较大的限制，因为现代Unix系统可能包含了多种文件系统，这些文件系统位于不同的磁盘和/或分区，用户也许无法知道它们之间的物理划分。

为了克服这些限制，引入了软链接(soft link)[也称符号链接(symbolic link)]。符号链接是短文件，这些文件包含有另一个文件的任意一个路径名。路径名可以指向位于任意一个文件系统的任意文件或目录，甚至可以指向一个不存在的文件。

```shell
ln -s  P1  P2
```

创建一个路径名为P2的新软链接，P2指向路径名P1。当这个命令执行时，文件系统抽出P2的目录部分，并在那个目录下创建一个名为P2的符号链接类型的新项。这个新文件包含路径名P1。这样，任何对P2的引用都可以被自动转换成指向P1的一个引用。

#### 文件类型

- 普通文件(regular file)
- 目录
- 符号链接
- 面向块的设备文件(block-oriented device file)
- 面向字符的设备文件(character-oriented device file)
- 管道(pipe)和命名管道(named pipe )(也叫F1F0 )
- 套接字(socket)

前三种文件类型是所有Unix文件系统的基本类型。

设备文件与I/O设备以及集成到内核中的设备驱动程序相关。例如，当程序访问设备文件时，它直接访问与那个文件相关的I/O设备。

管道和套接字是用于进程间通信的特殊文件。

#### 文件描述符与索引点

Unix对文件的内容和描述文件的信息给出了清楚的区分。除了设备文件和特殊文件系统文件外，每个文件都由字符序列组成。文件内容不包含任何控制信息，如文件长度或文件结束(end-of-file，EOF )符。
文件系统处理文件需要的所有信息包含在一个名为索引节点(inode)的数据结构中。每个文件都有自己的索引节点，文件系统用索引节点来标识文件。

虽然文件系统及内核函数对索引节点的处理可能随Unix系统的不同有很大的差异，但它们必须至少提供在POSIX标准中指定的如下属性：

- 文件类型
- 与文件相关的硬链接个数
- 以字节为单位的文件长度
- 设备标识符(即包含文件的设备的标识符)
- 在文件系统中标识文件的索引节点号
- 文件拥有者的UID
- 文件的用户组ID
- 几个时间戳，表示索引节点状态改变的时间、最后访问时间及最后修改时间
- 访问权限和文件模式

#### 访问权限和文件模式

文件的潜在用户分为三种类型：

- 作为文件所有者的用户
- 同组用户，不包括所有者
- 所有剩下的用户(其他)

有三种类型的访问权限——读、写及执行，每组用户都有这三种权限。因此，文件访问权限的组合就用9种不同的二进制来标记。还有三种附加的标记，即：uid (Set User ID)，sgid (Set Group ID)，及sticky用来定义文件的模式。当这些标记应用到可执行文件时有如下含义：

- suid

  进程执行一个文件时通常保持进程拥有者的UID。然而，如果设置了可执行文件suid的标志位，进程就获得了该文件拥有者的UID。

- sgid

  进程执行一个文件时保持进程组的用户组ID。然而，如果设置了可执行文件sgid的标志位，进程就获得了该文件用户组的ID。

- sticky

  设置了sticky标志位的可执行文件相当于向内核发出一个请求，当程序执行结   束以后，依然将它保留在内存(已过时)。

当文件由一个进程创建时，文件拥有者的ID就是该进程的UID。而其用户组ID可以是进程创建者的ID，也可以是父目录的ID，这取决于父目录sgid标志位的值。

#### 文件操作的系统调用

当用户访问一个普通文件或目录文件的内容时，他实际上是访问存储在硬件块设备上的一些数据。从这个意义上说，文件系统是硬盘分区物理组织的用户级视图。因为处于用户态的进程不能直接与低层硬件交互，所以每个实际的文件操作必须在内核态下进行。因此，Unix操作系统定义了几个与文件操作有关的系统调用。

所有Unix内核都对硬件块设备的处理效率给予极大关注，其目的是为了获得非常好的系统整体性能。在后面的章节中，我们将描述Linux与文件操作相关的主题，尤其是讨论内核如何对文件相关的系统调用作出反应。为了理解这些内容，你需要知道如何使用文件操作的主要系统调用。下面对此给予描述。

##### 打开文件

进程只能访问“打开的”文件。为了打开一个文件，进程调用系统调用：

```c
fd = open(path， flag， mode);
```

- path：表示被打开文件的(相对或绝对)路径。
- flag：指定文件打开的方式(例如，读、写、读/写、追加)。它也指定是否应当创建一个不存在的文件。
- mode：指定新创建文件的访问权限。

这个系统调用创建一个“打开文件”对象，并返回所谓文件描述符(file descriptor)的标识符。一个打开文件对象包括：

- 文件操作的一些数据结构，如指定文件打开方式的一组标志;表示文件当前位置的offset字段，从这个位置开始将进行下一个操作(即所谓的文件指针)，等等。
- 进程可以调用的一些内核函数指针。这组允许调用的函数集合由参数flag的值决定。

POSIX语义所指定的一般特性：

-  文件描述符表示进程与打开文件之间的交互，而打开文件对象包含了与这种交互相关的数据。同一打开文件对象也许由同一个进程中的几个文件描述符标识。
-  几个进程也许同时打开同一文件。在这种情况下，文件系统给每个文件分配一个单独的打开文件对象以及单独的文件描述符。当这种情况发生时，Unix文件系统对进程在同一文件上发出的I/O操作之间不提供任何形式的同步机制。然而，有几个系统调用，如flock()，可用来让进程在整个文件或部分文件上对I/O操作实施同步。

为了创建一个新的文件，进程也可以调用create()系统调用，它与open()非常相似，都是由内核来处理。

##### 访问打开的文件

对普通Unix文件，可以顺序地访问，也可以随机地访问，而对设备文件和命名管道文件，通常只能顺序地访问。在这两种访问方式中，内核把文件指针存放在打开文件对象中，也就是说，当前位置就是下一次进行读或写操作的位置。

顺序访问是文件的默认访问方式，即read()和write()系统调用总是从文件指针的当前位置开始读或写。为了修改文件指针的值，必须在程序中显式地调用lseek ()系统调用。当打开文件时，内核让文件指针指向文件的第一个字节(偏移量为0)。

```c
newoffset=lseek(fd， offset，whence);
```

- fd：表示打开文件的文件描述符。
- offset：指定一个有符号整数值，用来计算文件指针的新位置。
- whence：指定文件指针新位置的计算方式。可以是offset加0，表示文件指针从文件头移动，也可以是offset加文件指针的当前位置，表示文件指针从当前位置移动;还可以是offset加文件最后一个字节的位置，表示文件指针从文件末尾开始移动。

```c
nread= read(fd， buf，count);
```

- fd：表示打开文件的文件描述符。
- buf：指定在进程地址空间中缓冲区的地址，所读的数据就放在这个缓冲区。
- count：表示所读的字节数。

当处理这样的系统调用时，内核会尝试从拥有文件描述符fd的文件中读count个字节，其起始位置为打开文件的offset字段的当前值。在某些情况下可能遇到文件结束、空管道等等，因此内核无法成功地读出全部count个字节。返回的nead值就是实际所读的字节数。给原来的值加上nread就会更新文件指针。write()的参数与read()相似。

##### 关闭文件

当进程无需再访问文件的内容时，就调用系统调用：

```c
res=close(fd);
```

释放与文件描述符fd相对应的打开文件对象。当一个进程终止时，内核会关闭其所有仍然打开着的文件。

##### 更名及删除文件

要重新命名或删除一个文件时，进程不需要打开它。实际上，这样的操作并没有对这个文件的内容起作用，而是对一个或多个目录的内容起作用。

```c
/*改变了文件链接的名字*/
res= rename(oldpath， newpath);
```

```c
/*减少了文件链接数，删除了相应的目录项。只有当链接数为0时，文件才被真正删除。*/
res= unlink(pathname);
```

### Unix 内核概述

Unix内核提供了应用程序可以运行的执行环境。因此，内核必须实现一组服务及相应的接口。应用程序使用这些接口，而且通常不会与硬件资源直接交互。

#### 进程/内核模式

CPU既可以运行在用户态下，也可以运行在内核态下。实际上，一些CPU可以有两种以上的执行状态。例如，Intel 80x86微处理器有四种不同的执行状态。但是，所有标准的Unix内核都仅仅利用了内核态和用户态。

当一个程序在用户态下执行时，它不能直接访问内核数据结构或内核的程序。然而，当应用程序在内核态下运行时，这些限制不再有效。每种CPU模型都为从用户态到内核态的转换提供了特殊的指令，反之亦然。一个程序执行时，大部分时间都处在用户态下，只有需要内核所提供的服务时才切换到内核态。当内核满足了用户程序的请求后，它让程序又回到用户态下。

进程是动态的实体，在系统内通常只有有限的生存期。创建、撤消及同步现有进程的任务都委托给内核中的一组例程来完成。

内核本身并不是一个进程，而是进程的管理者。进程/内核模式假定：请求内核服务的进程使用所谓系统调用(system call)的特殊编程机制。每个系统调用都设置了一组识别进程请求的参数，然后执行与硬件相关的CPU指令完成从用户态到内核态的转换。

除用户进程之外，Unix系统还包括几个所谓内核线程(kernel thread)的特权进程(被赋予特殊权限的进程)，它们具有以下特点：

- 以内核态运行在内核地址空间。
- 不与用户直接交互，因此不需要终端设备。
- 通常在系统启动时创建，然后一直处于活跃状态直到系统关闭。

在单处理器系统中，任何时候只有一个进程在运行，或处于用户态，或处于内核态。如果进程运行在内核态，处理器就执行一些内核例程。

Unix内核做的工作远不止处理系统调用。实际上，可以有几种方式激活内核例程：

- 进程调用系统调用。
- 正在执行进程的CPU发出一个异常(exception)信号，异常是一些反常情况，例如一个无效的指令。内核代表产生异常的进程处理异常。
- 外围设备向CPU发出一个中断(interrupt)信号以通知一个事件的发生，如一个要 求注意的请求、一个状态的变化或一个I/O操作已经完成等。每个中断信号都是由内核中的中断处理程序(interrupt handler)来处理的。因为外围设备与CPU异步操作，因此，中断在不可预知的时间发生。
- 内核线程被执行。因为内核线程运行在内核态，因此必须认为其相应程序是内核的一部分。

#### 进程实现

为了让内核管理进程，每个进程由一个进程描述符(process descriptor)表示，这个描述符包含有关进程当前状态的信息。
当内核暂停一个进程的执行时，就把几个相关处理器寄存器的内容保存在进程描述符中。这些寄存器包括：

- 程序计数器(PC) 和 栈指针(SP)寄存器
- 通用寄存器
- 浮点寄存器
- 包含CPU状态信息的处理器控制寄存器(处理器状态字，Processor Status Word)
- 用来跟踪进程对RAM访问的内存管理寄存器

当内核决定恢复执行一个进程时，它用进程描述符中合适的字段来装载CPU寄存器。因为程序计数器中所存的值指向下一条将要执行的指令，所以进程从它停止的地方恢复执行。

当一个进程不在CPU上执行时，它正在等待某一事件。Unix内核可以区分很多等待状态，这些等待状态通常由进程描述符队列实现。每个(可能为空)队列对应一组等待特定事件的进程。

#### 可重入内核

所有的Unix内核都是可重入的(reentrant)，这意味着若干个进程可以同时在内核态下执行。当然，在单处理器系统上只有一个进程在真正运行，但是有许多进程可能在等待CPU或某一I/O操作完成时在内核态下被阻塞。例如，当内核代表某一进程发出一个读磁盘请求后，就让磁盘控制器处理这个请求并且恢复执行其他进程。当设备满足了读请求时，有一个中断就会通知内核，从而以前的进程可以恢复执行。

提供可重入的一种方式是编写函数，以便这些函数只能修改局部变量，而不能改变全局数据结构，这样的函数叫可重入函数。但是可重入内核不仅仅局限于这样的可重入函数(尽管一些实时内核正是如此实现的)。相反，可重入内核可以包含非重入函数，并且利用锁机制保证一次只有一个进程执行一个非重人函数。

如果一个硬件中断发生，可重入内核能挂起当前正在执行的进程，即使这个进程处于内核态。这种能力是非常重要的，因为这能提高发出中断的设备控制器的吞吐量。一旦设备已发出一个中断，它就一直等待直到CPU应答它为止。如果内核能够快速应答，设备控制器在CPU处理中断时就能执行其他任务。

现在，让我们看一下内核的可重入性及它对内核组织的影响。内核控制路径(kernel control path)表示内核处理系统调用、异常或中断所执行的指令序列。在最简单的情况下，CPU从第一条指令到最后一条指令顺序地执行内核控制路径。然而，当下述事件之一发生时，CPU交错执行内核控制路径：

- 运行在用户态下的进程调用一个系统调用，而相应的内核控制路径证实这个请求无法立即得到满足，然后，内核控制路径调用调度程序选择一个新的进程投入运行。结果，进程切换发生。第一个内核控制路径还没完成，而CPU又重新开始执行其他的内核控制路径。在这种情况下，两条控制路径代表两个不同的进程在执行。
- 当运行一个内核控制路径时，CPU检测到一个异常(例如，访问一个不在RAM中的页)。第一个控制路径被挂起，而CPU开始执行合适的过程。在我们的例子中，这种过程能给进程分配一个新页，并从磁盘读它的内容。当这个过程结束时，第一个控制路径可以恢复执行。在这种情况下，两个控制路径代表同一个进程在执行。
- 当CPU正在运行一个启用了中断的内核控制路径时，一个硬件中断发生。第一个内核控制路径还没执行完，CPU开始执行另一个内核控制路径来处理这个中断。当这个中断处理程序终止时，第一个内核控制路径恢复。在这种情况下，两个内核控制路径运行在同一进程的可执行上下文中，所花费的系统CPU时间都算给这个进程。然而，中断处理程序无需代表这个进程运行。
- 在支持抢占式调度的内核中，CPU正在运行，而一个更高优先级的进程加入就绪队列，则中断发生。在这种情况下，第一个内核控制路径还没有执行完，CPU代表高优先级进程又开始执行另一个内核控制路径。只有把内核编译成支持抢占式调度之后，才可能出现这种情况。

下图显示了非交错的和交错的内核控制路径的几个例子。考虑以下三种不同的CPU状态：

- 在用户态下运行一个进程(User)
- 运行一个异常处理程序或系统调用处理程序(Excp)
- 运行一个中断处理程序(Intr)

![内核控制路径交错执行.jpg](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/%E5%86%85%E6%A0%B8%E6%8E%A7%E5%88%B6%E8%B7%AF%E5%BE%84%E4%BA%A4%E9%94%99%E6%89%A7%E8%A1%8C.jpg?raw=true)

#### 进程地址空间

每个进程运行在它的私有地址空间。在用户态下运行的进程涉及到私有栈、数据区和代码区。当在内核态运行时，进程访问内核的数据区和代码区，但使用另外的私有栈。

因为内核是可重入的，因此几个内核控制路径(每个都与不同的进程相关)可以轮流执行。在这种情况下，每个内核控制路径都引用它自己的私有内核栈。

尽管看起来每个进程访问一个私有地址空间，但有时进程之间也共享部分地址空间。在一些情况下，这种共享由进程显式地提出；在另外一些情况下，由内核自动完成共享以节约内存。

如果同一个程序(比如说编辑程序)由几个用户同时使用，则这个程序只被装人内存一次，其指令由所有需要它的用户共享。当然，其数据不被共享，因为每个用户将有独立的数据。这种共享的地址空间由内核自动完成以节省内存。

进程间也能共享部分地址空间，以实现一种进程间通信，这就是由System V引人并且已经被Linux支持的“共享内存”技术。
最后，Linux支持mmap()系统调用，该系统调用允许存放在块设备上的文件或信息的一部分映射到进程的部分地址空间。内存映射为正常的读写传送数据方式提供了另一种选择。如果同一文件由几个进程共享，那么共享它的每个进程地址空间都包含有它的内存映射。

#### 同步和临界区

实现可重入内核需要利用同步机制：如果内核控制路径对某个内核数据结构进行操作时被挂起，那么，其他的内核控制路径就不应当再对该数据结构进行操作，除非它已被重新设置成一致性(consistent)状态。否则，两个控制路径的交互作用将破坏所存储的信息。

当某个计算结果取决于如何调度两个或多个进程时，相关代码就是不正确的。我们说存在一种竟争条件(race condition)。
一般来说，对全局变量的安全访问通过原子操作(atomic operation)来保证。临界区(critical region)是这样的一段代码，进入这段代码的进程必须完成，之后另一个进程才能进入。

这些问题不仅出现在内核控制路径之间，也出现在共享公共数据的进程之间。几种同步技术已经被采用。以下将集中讨论怎样同步内核控制路径。

##### 非抢占式内核

在寻找彻底、简单地解决同步问题的方案中，大多数传统的Unix内核都是非抢占式的：当进程在内核态执行时，它不能被任意挂起，也不能被另一个进程代替。因此，在单处理器系统上，中断或异常处理程序不能修改的所有内核数据结构，内核对它们的访问都是安全的。

当然，内核态的进程能自愿放弃CPU，但是在这种情况下，它必须确保所有的数据结构都处于一致性状态。此外，当这种进程恢复执行时，它必须重新检查以前访问过的数据结构的值，因为这些数据结构有可能被改变。

如果内核支持抢占，那么在应用同步机制时，确保进入临界区前禁止抢占，退出临界区时启用抢占。

非抢占能力在多处理器系统上是低效的，因为运行在不同CPU上的两个内核控制路径本可以并发地访问相同的数据结构。
禁止中断单处理器系统上的另一种同步机制是：在进入一个临界区之前禁止所有硬件中断，离开时再重新启用中断。这种机制尽管简单，但远不是最佳的。如果临界区比较大，那么在一个相对较长的时间内持续禁止中断就可能使所有的硬件活动处于冻结状态。

此外，由于在多处理器系统中禁止本地CPU上的中断是不够的，所以必须使用其他的同步技术。

##### 信号量

广泛使用的一种机制是信号量(semaphore)，它在单处理器系统和多处理器系统上都有效。信号量仅仅是与一个数据结构相关的计数器。所有内核线程在试图访问这个数据结构之前，都要检查这个信号量。可以把每个信号量看成一个对象，其组成如下：

- 一个整数变量
- 一个等待进程的链表
- 两个原子方法：down()和up()

down()方法对信号量的值减1，如果这个新值小于0，该方法就把正在运行的进程加入到这个信号量链表，然后阻塞该进程(即调用调度程序)。up()方法对信号量的值加1，如果这个新值大于或等于0，则激活这个信号量链表中的一个或多个进程。

每个要保护的数据结构都有它自己的信号量，其初始值为1。当内核控制路径希望访问这个数据结构时，它在相应的信号量上执行down()方法。如果信号量的当前值不是负数，则允许访问这个数据结构。否则，把执行内核控制路径的进程加入到这个信号量的链表并阻塞该进程。当另一个进程在那个信号量上执行up()方法时，允许信号量链表上的一个进程继续执行。

##### 自旋锁

在多处理器系统中，信号量并不总是解决同步问题的最佳方案。系统不允许在不同CPU上运行的内核控制路径同时访问某些内核数据结构，在这种情况下，如果修改数据结构所需的时间比较短，那么，信号量可能是很低效的。为了检查信号量，内核必须把进程插入到信号量链表中，然后挂起它。因为这两种操作比较费时，完成这些操作时，其他的内核控制路径可能已经释放了信号量。在这些情况下，多处理器操作系统使用了自旋锁(spin lock)。自旋锁与信号量非常相似，但没有进程链表。当一个进程发现锁被另一个进程锁着时，它就不停地“旋转”，执行一个紧凑的循环指令直到锁打开。

当然，自旋锁在单处理器环境下是无效的。当内核控制路径试图访问一个上锁的数据结构时，它开始无休止循环。因此，内核控制路径可能因为正在修改受保护的数据结构而没有机会继续执行，也没有机会释放这个自旋锁。最后的结果可能是系统挂起。

##### 避免死锁

与其他控制路径同步的进程或内核控制路径很容易进入死锁(deadlock)状态。

只要涉及到内核设计，当所用内核信号量的数量较多时，死锁就成为一个突出问题。在这种情况下，很难保证内核控制路径在各种可能方式下的交错执行不出现死锁状态。有几种操作系统(包括Linux)通过按规定的顺序请求信号量来避免死锁。

#### 信号和进程间通信

Unix信号(signal)提供了把系统事件报告给进程的一种机制。每种事件都有自己的信号编号，通常用一个符号常量来表示，例如SIGTERM。有两种系统事件：

- 异步通告

  例如，当用户在终端按下中断键(通常为CTRL-C)时，即向前台进程发出中断信号SIGINT。

- 同步错误或异常

  例如，当进程访问内存非法地址时，内核向这个进程发送一个SIGSEGV信号。

POSIX标准定义了大约20种不同的信号，其中，有两种是用户自定义的，可以当作用户态下进程通信和同步的原语机制。一般来说，进程可以以两种方式对接收到的信号做出反应：

- 忽略该信号。

- 异步地执行一个指定的过程(信号处理程序)。

如果进程不指定选择何种方式，内核就根据信号的编号执行一个默认操作。五种可能的默认操作是：

- 终止进程。

- 将执行上下文和进程地址空间的内容写入一个文件(核心转储，core dump)，并终止进程。
- 忽略信号。
- 挂起进程。
- 如果进程曾被暂停，则恢复它的执行。

因为POSIX语义允许进程暂时阻塞信号，因此内核信号的处理相当精细。此外，SIGKILL和SIGSTOP信号不能直接由进程处理，也不能由进程忽略。

AT&T的Unix System V引入了在用户态下其他种类的进程间通信机制，很多Unix内核也采用了这些机制：信号量、消息队列及共享内存。它们被统称为System V lPC。

内核把它们作为IPC资源来实现：进程要获得一个资源，可以调用shmget()，semget()或msgget()系统调用。与文件一样，IPC资源是持久不变的，进程创建者、进程拥有者或超级用户进程必须显式地释放这些资源。

这里的信号量与本章“同步和临界区”一节中所描述的信号量是相似的，只是它们用在用户态下的进程中。消息队列允许进程利用msgsnd()及msgget()系统调用交换消息，msgsnd()表示把消息插入到指定的队列中，msgget()表示从队列中提取消息。

POSIX标准(IEEE Std 1003.1-2001)定义了一种基于消息队列的IPC机制，这就是所谓的POSIX消息队列。它们和System V IPC消息队列是相似的，但是，它们对应用程序提供一个更简单的基于文件的接口。

共享内存为进程之间交换和共享数据提供了最快的方式。通过调用shmget()系统调用来创建一个新的共享内存，其大小按需设置。在获得IPC资源标识符后，进程调用shmat()系统调用，其返回值是进程的地址空间中新区域的起始地址。当进程希望把共享内存从其地址空间分离出去时，就调用shmdt()系统调用。共享内存的实现依赖于内核对进程地址空间的实现。

#### 进程管理

Unix在进程和它正在执行的程序之间做出一个清晰的划分。fork()和_exit()系统调用分别用来创建一个新进程和终止一个进程，而调用exec()类系统调用则是装入一个新程序。当这样一个系统调用执行以后，进程就在所装入程序的全新地址空间恢复运行。

调用fork()的进程是父进程，而新进程是它的子进程。父子进程能互相找到对方，因为进程描述符包含有两个指针，一个直接指向它的父进程，另一个直接指向它的子进程。

实现fork()一种简单的方式就是将父进程的数据与代码都复制，并把这个拷贝赋予子进程。这会相当费时。当前依赖硬件分页单元的内核采用写时复制(Copy-On-Write)技术，即把页的复制延迟到最后一刻(也就是说，直到父或子进程需要时才写进页)。

_exit()系统调用终止一个进程。内核对这个系统调用的处理是通过释放进程所拥有的资源并向父进程发送SIGCHILD信号(默认操作为忽略)来实现的。

##### 任死进程(zombie process)

父进程如何查询其子进程是否终止了呢?wait4()系统调用允许进程等待，直到其中的一个子进程结束.它返回已终止子进程的进程标识符(Process ID，  PID)。

内核在执行这个系统调用时，检查子进程是否已经终止。引入僵死进程的特殊状态是为了表示终止的进程：父进程执行完wait4()系统调用之前，进程就一直停留在那种状态。系统调用处理程序从进程描述符字段中获取有关资源使用的一些数据；一旦得到数据，就可以释放进程描述符。当进程执行wait4()系统调用时如果没有子进程结束，内核就通常把该进程设置成等待状态，一直到子进程结束。

很多内核也实现了waitpid()系统调用，它允许进程等待一个特殊的子进程。其他wait4()系统调用的变体也是相当通用的。
在父进程发出wait4()调用之前，让内核保存子进程的有关信息是一个良好的习惯，但是，假设父进程终止而没有发出wait4()调用呢?这些信息占用了一些内存中非常有用的位置，而这些位置本来可以用来为活动着的进程提供服务。例如，很多shell允许用户在后台启动一个命令然后退出。正在运行这个shell命令的进程终止，但它的子进程继续运行。

解决的办法是使用一个名为init的特殊系统进程，它在系统初始化的时候被创建。当一个进程终止时，内核改变其所有现有子进程的进程描述符指针，使这些子进程成为init的孩子。init监控所有子进程的执行，并且按常规发布wait4()系统调用，其副作用就是除掉所有僵死的进程。

##### 进程组和登录会话

现代Unix操作系统引入了进程组(process group)的概念，以表示一种“作业(job)"的抽象。例如，为了执行命令行：

```shell
ls | sort | mort
```


Shell支持进程组，例如bash，为三个相应的进程ls，sort及more创建了一个新的组。shell以这种方式作用于这三个进程，就好像它们是一个单独的实体(更准确地说是作业)。每个进程描述符包括一个包含进程组ID的字段。每一进程组可以有一个领头进程(即其PID与这个进程组的ID相同的进程)。新创建的进程最初被插入到其父进程的进程组中。

现代Unix内核也引入了登录会话(login session)。非正式地说，一个登录会话包含在指定终端已经开始工作会话的那个进程的所有后代进程——通常情况下，登录会话就是shell进程为用户创建的第一条命令。进程组中的所有进程必须在同一登录会话中。一个登录会话可以让几个进程组同时处于活动状态，其中，只有一个进程组一直处于前台，这意味着该进程组可以访问终端，而其他活动着的进程组在后台。当一个后台进程试图访问终端时，它将收到SIGTTIN或SIGTTOUT信号。在很多shell命令中，用内部命令bg和fg把一个进程组放在后台或者前台。

#### 内存管理

内存管理是迄今为止Unix内核中最复杂的活动。

##### 虚拟内存

所有新近的Unix系统都提供了一种有用的抽象，叫虚拟内存(virtual memory)。虚拟内存作为一种逻辑层，处于应用程序的内存请求与硬件内存管理单元(Memory Management Unit，  MMU)之间。虚拟内存有很多用途和优点：

- 若干个进程可以并发地执行。
- 应用程序所需内存大于可用物理内存时也可以运行。
- 程序只有部分代码装入内存时进程可以执行它。
- 允许每个进程访问可用物理内存的子集。
- 进程可以共享库函数或程序的一个单独内存映像。
- 程序是可重定位的，也就是说，可以把程序放在物理内存的任何地方。
- 程序员可以编写与机器无关的代码，因为他们不必关心有关物理内存的组织结构。

虚拟内存子系统的主要成分是虚拟地址空间(virtual address space)的概念。进程所用的一组内存地址不同于物理内存地址。当进程使用一个虚拟地址时，内核和MMU协同定位其在内存中的实际物理位置。

现在的CPU包含了能自动把虚拟地址转换成物理地址的硬件电路。为了达到这个目标，把可用RAM划分成长度为4KB或8KB的页框(page frame)，并且引入一组页表来指定虚拟地址与物理地址之间的对应关系。这些电路使内存分配变得简单，因为一块连续的虚拟地址请求可以通过分配一组非连续的物理地址页框而得到满足。

##### 随机访问存储器(RAM)的使用

所有的Unix操作系统都将RAM毫无疑义地划分为两部分，其中若干兆字节专门用于存放内核映像(也就是内核代码和内核静态数据结构)。RAM的其余部分通常由虚拟内存系统来处理，并且用在以下三种可能的方面：

- 满足内核对缓冲区、描述符及其他动态内核数据结构的请求。
- 满足进程对一般内存区的请求及对文件内存映射的请求。
- 借助于高速缓存从磁盘及其他缓冲设备获得较好的性能。

每种请求类型都是重要的。但从另一方面来说，因为可用RAM是有限的，所以必须在请求类型之间做出平衡，尤其是当可用内存没有剩下多少时。此外，当可用内存达到临界阈值时，可以调用页框回收(page-frame-reclaiming)算法释放其他内存。

虚拟内存系统必须解决的一个主要问题是内存碎片。理想情况下，只有当空闲页框数太少时，内存请求才失败。然而，通常要求内核使用物理上连续的内存区域，因此，即使有足够的可用内存，但它不能作为一个连续的大块使用时，内存的请求也会失败。

##### 内核内存分配器

内核内存分配器(Kernel Memory Allocator， KMA)是一个子系统，它试图满足系统中所有部分对内存的请求。其中一些请求来自内核其他子系统，它们需要一些内核使用的内存，还有一些请求来自于用户程序的系统调用，用来增加用户进程的地址空间。一个好的KMA应该具有下列特点：

- 必须快。实际上，这是最重要的属性，因为它由所有的内核子系统(包括中断处理程序)调用。
- 必须把内存的浪费减到最少。
- 必须努力减轻内存的碎片(fragmentation)问题。
- 必须能与其他内存管理子系统合作，以便借用和释放页框。

基于各种不同的算法技术，已经提出了几种KMA，包括：

- 资源图分配算法(allocator)

- 2的幕次方空闲链表
- McKusick-Karels分配算法
- 伙伴(Buddy)系统
- Mach的区域(Zone)分配算法
- Dynix分配算法
- Solaris的Slab分配算法

Linux的KMA在伙伴系统之上采用了Slab分配算法。

##### 进程虚拟地址空间处理

进程的虚拟地址空间包括了进程可以引用的所有虚拟内存地址。内核通常用一组内存区描述符描述进程虚拟地址空间。例如，当进程通过exec()类系统调用开始某个程序的执行时，内核分配给进程的虚拟地址空间由以下内存区组成：

- 程序的可执行代码
- 程序的初始化数据
- 程序的未初始化数据
- 初始程序栈(即用户态栈)
- 所需共享库的可执行代码和数据
- 堆(由程序动态请求的内存)

所有现代Unix操作系统都采用了所谓请求调页(demand paging)的内存分配策略。有了请求调页，进程可以在它的页还没有在内存时就开始执行。当进程访问一个不存在的页时，MMU产生一个异常；异常处理程序找到受影响的内存区，分配一个空闲的页，并用适当的数据把它初始化。同理，当进程通过调用malloc()或brk()(由malloc()在内部调用)系统调用动态地请求内存时，内核仅仅修改进程的堆内存区的大小。只有试图引用进程的虚拟内存地址而产生异常时，才给进程分配页框。虚拟地址空间也采用其他更有效的策略，如前面提到的写时复制策略。例如，当一个新进程被创建时，内核仅仅把父进程的页框赋给子进程的地址空间，但是把这些页框标记为只读。一旦父或子进程试图修改页中的内容时，一个异常就会产生。异常处理程序把新页框赋给受影响的进程，并用原来页中的内容初始化新页框。

##### 高速缓存

物理内存的一大优势就是用作磁盘和其他块设备的高速缓存。这是因为硬盘非常慢：磁盘的访问需要数毫秒，与RAM的访问时间相比，这太长了。因此，磁盘通常是影响系统性能的瓶颈。通常，在最早的Unix系统中就已经实现的一个策略是：尽可能地推迟写磁盘的时间，因此，从磁盘读入内存的数据即使任何进程都不再使用它们，它们也继续留在RAM中。
这一策略的前题是有好机会摆在面前：新进程请求从磁盘读或写的数据，就是被撤消进程曾拥有的数据。当一个进程请求访问磁盘时，内核首先检查进程请求的数据是否在缓存中，如果在(把这种情况叫做缓存命中)，内核就可以为进程请求提供服务而不用访问磁盘。

sync()系统调用把所有“脏”的缓冲区(即缓冲区的内容与对应磁盘块的内容不一样)写入磁盘来强制磁盘同步。为了避免数据丢失，所有的操作系统都会注意周期性地把脏缓冲区写回磁盘。

#### 设备驱动程序

内核通过设备驱动程序(device driver)与I/O设备交互。设备驱动程序包含在内核中，由控制一个或多个设备的数据结构和函数组成，这些设备包括硬盘、键盘、鼠标、监视器、网络接口及连接到SCSI总线上的设备。通过特定的接口，每个驱动程序与内核中的其余部分(甚至与其他驱动程序)相互作用这种方式具有以下优点：

- 可以把特定设备的代码封装在特定的模块中。
- 厂商可以在不了解内核源代码而只知道接口规范的情况下，就能增加新的设备。
- 内核以统一的方式对待所有的设备，并且通过相同的接口访问这些设备。
- 可以把设备驱动程序写成模块，并动态地把它们装进内核而不需要重新启动系统。
- 不再需要时，也可以动态地卸下模块，以减少存储在RAM中的内核映像的大小。

下图说明了设备驱动程序与内核其他部分及进程之间的接口。

![设备驱动程序接口.jpg](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F%E6%8E%A5%E5%8F%A3.jpg?raw=true)

一些用户程序(P)希望操作硬件设备。这些程序就利用常用的、与文件相关的系统调用及在/dev目录下能找到的设备文件向内核发出请求。实际上，设备文件是设备驱动程序接口中用户可见的部分。每个设备文件都有专门的设备驱动程序，它们由内核调用以执行对硬件设备的请求操作。

这里值得一提的是，在Unix刚出现的时候，图形终端是罕见而且昂贵的，因此Unix内核只直接处理字符终端。当图形终端变得非常普遍时，一些如XWindow系统那样的特别的应用就出现了，它们以标准进程的身份运行，并且能直接访问图形界面的I/O端口和RAM的视频区域。一些新近的Unix内核，例如Linux 2.6，对图形卡的帧缓冲提供了一种抽象，从而允许应用软件无需了解图形界面的I/O端口的任何知识就能对其进行访问。

## 第2章 内存寻址

### 内存地址

逻辑地址（logical address）：机器语言指令中用来指定一个操作数或一条指令的地址。每一个逻辑地址都由一个段（segment）和偏移量（offset或displacement）组成，偏移量指明了从段开始的地方到实际地址之间的距离。这种寻址方式在80x86著名的分段结构中表现的尤为具体，它促使MS-DOS或Windows程序员把程序分成若干段。

线性地址（linear address）（或 虚拟地址 virtual address）：一个32位无符号整数，可以用来表示高达4GB（0x0000 0000 —— 0xffff ffff）的地址，也就是高达 4 * 1024 * 1024 * 1024个内存单元（字节）。

物理地址（physical address）：芯片级内存单元寻址。它们与从微处理器的地址引脚发送到内存总线上的电信号相对应。物理地址由32位或36位（开启PAE）无符号整数表示。

内存管理单元（MMU）通过分段单元（segmentation unit）把逻辑地址转换成线性地址；然后，通过分页单元（paging unit）把线性地址转换成物理地址。分段单元和分页单元都是一种硬件电路。

在多处理器系统中，所有CPU都共享同一内存。这意味着RAM芯片可以由独立的CPU并发地访问。因为在RAM芯片上的读或写操作必须串行地执行，因此一种所谓内存仲裁器(memory arbiter)的硬件电路插在总线和每个RAM芯片之间。其作用是如果某个RAM芯片空闲，就准予一个CPU访问，如果该芯片忙于为另一个处理器提出的请求服务，就延迟这个CPU的访问。即使在单处理器上也使用内存仲裁器，因为单处理器系统中包含一个叫做 DMA控制器 的特殊处理器，而DMA控制器与CPU并发操作（RAM）。在多处理器系统的情况下，因为仲裁器有多个输入端口，所以其结构更加复杂。例如，双Pentium在每个芯片的入口维持一个两端口仲裁器，并在试图使用公用总线前请求两个CPU交换同步信息。从编程观点看，因为仲裁器由硬件电路管理，因此它是隐藏的。

### 硬件中的分段

80286之前仅有实模式：数据总线 16位，地址总线20位，寄存器16位。

从80286模型开始，Intel微处理器以两种不同的方式执行地址转换：实模式（real mode）和保护模式（protected mode）（数据总线、地址总线32位，寄存器32位）。实模式存在的主要原因是要维持处理器与早期模型兼容，并让操作系统自举。

#### 段选择符和段寄存器

一个逻辑地址由两部分组成：段标识符和指定段内相对地址的偏移量。段标识符是一个16位长的字段，称为段选择符（Segment Selector），而偏移量是一个32位长的字段。



![段选择符.jpg](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/%E6%AE%B5%E9%80%89%E6%8B%A9%E7%AC%A6.jpg?raw=true)

为了快速方便地找到段选择符，处理器提供段寄存器，段寄存器的唯一目的是 存放段选择符。这些段寄存器称为cs，  ss， ds， es，  fs和gs。尽管只有6个段寄存器，但程序可以把同一个段寄存器用于不同的目的，方法是先将其值保存在内存中，用完后再恢复。
6个段寄存器中3个有专门的用途：
cs	代码段寄存器，指向包含程序指令的段。
ss	栈段寄存器，指向包含当前程序栈的段。
ds	数据段寄存器，指向包含静态数据或者全局数据段（初始化数据）。
其他3个段寄存器作一般用途，可以指向任意的数据段。
cs寄存器还有一个很重要的功能：它含有一个 两位的字段，用以指明CPU的 当前特权级(Current Privilege Level， CPL)。值为0代表最高优先级，而值为3代表最低优先级。Linux只用0级和3级，分别称之为内核态和用户态。

#### 段描述符

每个段由一个 8字节 的段描述符（Segment Descriptor）表示，它描述了段的特征。段描述符放在全局描述符表（Global Descriptor Table， GDT）或局部描述符表（Local Descriptor Table， LDT）中。

通常只定义一个GDT，而每个进程除了存放在GDT中段之外如果还需要创建附加的段，就可以有自己的LDT。GDT在主存中的地址和大小存放在gdtr控制寄存器中，当前正被使用的LDT地址和大小放在ldtr控制寄存器中。

![段描述符通用格式.jpg](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/%E6%AE%B5%E6%8F%8F%E8%BF%B0%E7%AC%A6%E9%80%9A%E7%94%A8%E6%A0%BC%E5%BC%8F.jpg?raw=true)

![几种段描述符格式.jpg](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/%E5%87%A0%E7%A7%8D%E6%AE%B5%E6%8F%8F%E8%BF%B0%E7%AC%A6%E6%A0%BC%E5%BC%8F.jpg?raw=true)

| 字段名   | 描述                                       |
| ----- | ---------------------------------------- |
| Base  | 包含段的首字节的线性地址 （32 bit）                    |
| G     | 粒度标志；置0，则段大小以字节为单位，否则以4096字节的倍数计         |
| Limit | 存放段中最后一个内存单元的偏移量，从而决定段的长度（20 bit）。如果G被置为0，则一个段的大小在1个字节到1MB之间变化；否则，将在4KB到4GB之间变化 |
| S     | 系统标志；置0，系统段，存储诸如LDT这种关键的数据结构，否则它是一个普通的代码段或数据段 |
| Type  | 描述了段的类型特征和它的存取权限                         |
| DPL   | 描述符特权级（Descriptor Privilege Level）字段；用于限制对这个段的存取。表示访问这个段要求的CPU最小的优先级 |
| P     | Segment-Present标志；为0表示段当前不在主存中。Linux总是把这个标志（第47位）设为1，因为它从来不把整个段交换到磁盘上去 |
| D或B   | 取决于是代码段还是数据段                             |
| AVL   | 操作系统使用，但被Linux忽略                         |

代码段和数据段描述符类型如下表：

![代码段和数据段描述符类型.png](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/%E4%BB%A3%E7%A0%81%E6%AE%B5%E5%92%8C%E6%95%B0%E6%8D%AE%E6%AE%B5%E6%8F%8F%E8%BF%B0%E7%AC%A6%E7%B1%BB%E5%9E%8B.png?raw=true)

代码段描述符：代表一个代码段，它可以放在GDT或LDT中。该描述符置S标志为1(非系统段)。

数据段描述符：代表一个数据段，它可以放在GDT或LDT中。该描述符置S标志为1。栈段是通过一般的数据段实现的。

任务状态段描述符（TSSD）：代表一个任务状态段(Task State Segment， TSS )，也就是说这个段用于保存处理器寄存器的内容。它只能出现在GDT中。根据相应的进程是否正在CPU上运行，其Type字段的值分别为11或9。这个描述符的S标志置为0。

局部描述符表描述符（LDTD）：代表一个包含LDT的段，它只出现在GDT中。相应的Type字段的值为2，S标志置为0。

段选择符字段：

| 字段名   | 描述                                       |
| ----- | ---------------------------------------- |
| index | 指定了放在GDT或LDT中的相应段描述符的入口                  |
| TI    | TI（Table Indicator）标志，指明段描述符是在GDT中（TI=0）或在LDT中（TI=1） |
| RPL   | 请求者特权级，当相应的段选择符装入到cs寄存器中时指示出CPU当前的特权级，它还可以用于在访问数据段时有选择地削弱处理器的特权级 |

#### 快速访问段描述符

重申：逻辑地址由16位段选择符和32位偏移量组成，段寄存器仅仅存放段选择符。

为了加速逻辑地址到线性地址的转换，80x86处理器提供一种附加的非编程的寄存器（不能被编程者设置的寄存器），供6个可编程的段寄存器使用。每一个非编程的寄存器含有8个字节的段描述符，由相应的段寄存器中的段选择符来指定。每当一个段选择符被装入段寄存器时，相应的段描述符就由内存装入到对应的非编程CPU寄存器。之后，针对那个段的逻辑地址转换就可以不访问主存中的GDT或LDT，处理器只需直接引用存放段描述符的CPU寄存器即可。仅当段寄存器的内容改变时，才有必要访问GDT或LDT。

![段选择符和段描述符.jpg](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/%E6%AE%B5%E9%80%89%E6%8B%A9%E7%AC%A6%E5%92%8C%E6%AE%B5%E6%8F%8F%E8%BF%B0%E7%AC%A6.jpg?raw=true)

由于一个段描述符是8字节，因此它在GDT或LDT内的相对地址是由段选择符的最高13位（index）的值乘以8得到的。例如：如果GDT在0x0002 0000（这个值保存在gdtr寄存器中），且由段选择符所指定的索引号为2，那么相应的段描述符地址是0x0002 0000 + (2 * 8)，或0x0002 0010。

GDT的第一项总是设为0。这就确保空段选择符的逻辑地址会被认为是无效的，因此引起一个处理器异常。能够保存在GDT中的段描述符的最大数目是8191，即2^13^ - 1。

#### 分段单元

下图显示一个逻辑地址转换的详细过程，分段单元（segmentation unit）执行以下操作：

- 先检查段选择符的TI字段，以决定段描述符保存在哪一个描述符表中。GDT中，分段单元从gdtr寄存器得到GDT的线性基地址；LDT中，分段单元从ldtr寄存器得到LDT的线性基地址。
- 从段选择符的index字段计算段描述符的地址，index字段的值乘以8（一个段描述符的大小），这个结果与gdtr或ldtr寄存器中的内容相加。
- 把逻辑地址的偏移量与段描述符Base字段的值相加就得到了线性地址。

![逻辑地址转换.jpg](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/%E9%80%BB%E8%BE%91%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2.jpg?raw=true)

有了与段寄存器相关的不可编程寄存器，只有当段寄存器的内容被改变时才需要执行前两个操作。

### Linux中的分段

分段使程序划分成逻辑上相关的实体，例如子程序或者全局与局部数据区。然而，Linux以非常有限的方式使用分段。实际上，分段和分页在某种程度上有点多余因为它们都可以划分进程的物理地址空间：分段可以给每个进程分配不同的线性地址空间，而分页可以把同一线性地址空间映射到不同的物理地址空间（页表映射不同）。与分段相比，Linux更喜欢用分页的方式：

- 当所有的进程使用相同的段寄存器值时，内存管理变得更简单，也就是它们能共享同样的一组线性地址。
- Linux设计目标之一是可以把它移植到绝大多数流行的处理器平台上。然而，RISC体系结构对分段的支持有限。

2.6版的Linux只有在x86结构下才需要分段。

运行在用户态的所有Linux进程都使用一对相同的段来对指令和数据寻址。这两个段就是所谓的用户代码段和用户数据段。类似地，运行在内核态的所有Linux进程都使用一对相同的段对指令和数据寻址：它们分别叫做内核代码段和内核数据段。

下表显示了这4个重要段的段描述符字段的值：

| 段     | Base        | G    | Limit   | S    | Type | DPL  | D/B  | p    |
| ----- | ----------- | ---- | ------- | ---- | ---- | ---- | ---- | ---- |
| 用户代码段 | 0x0000 0000 | 1    | 0xfffff | 1    | 10   | 3    | 1    | 1    |
| 用户数据段 | 0x0000 0000 | 1    | 0xfffff | 1    | 2    | 3    | 1    | 1    |
| 内核代码段 | 0x0000 0000 | 1    | 0xfffff | 1    | 10   | 0    | 1    | 1    |
| 内核数据段 | 0x0000 0000 | 1    | 0xfffff | 1    | 2    | 0    | 1    | 1    |

G为1，粒度为4KB，Limit为 0xfffff，则空间为 4GB

相应的段选择符由宏定义。

```c
  __USER_CS、__USER_DS、__KERNEL_CS、__KERNEL_DS
```

为了对内核代码段寻址，内核只需把\_\_KERNEL_CS宏产生的值装进cs段寄存器即可。

注意，与段相关的线性地址从0开始，达到2^23^ - 1的寻址限长。这就意味着在用户态或内核态下的所有进程可以使用相同的逻辑地址。

所有段都从0x0000 0000 开始，那么，在Linux下逻辑地址与线性地址是一致的，即逻辑地址的偏移量字段的值与相应的线性地址的值总是一致的。

如前所述，CPU的当前特权级(CPL)反映了进程是在用户态还是内核态，并由存放在cs寄存器中的段选择符的RPL字段指定。只要当前特权级被改变，一些段寄存器必须相应地更新。例如，当CPL=3时(用户态)，ds寄存器必须含有用户数据段的段选择符，而当CPL=0时，ds寄存器必须含有内核数据段的段选择符。

类似的情况也出现在ss寄存器中。当CPL为3时，它必须指向一个用户数据段中的用户栈，而当CPL为0时，它必须指向内核数据段中的一个内核栈。当从用户态切换到内核态时，Linux总是确保ss寄存器装有内核数据段的段选择符。

当对指向指令或者数据结构的指针进行保存时，内核根本不需要为其设置逻辑地址的段选择符，因为cs寄存器就含有当前的段选择符。例如，当内核调用一个函数时，它执行一条call汇编语言指令，该指令仅指定其逻辑地址的偏移量部分，而段选择符不用设置，它已经隐含在cs寄存器中了。因为“在内核态执行”的段只有一种，叫做代码段，由宏\_\_KERNEL_CS定义，所以只要当CPU切换到内核态时将\_\_KERNEL_CS装载进cs就足够了。同样的道理也适用于指向内核数据结构的指针(隐含地使用ds寄存器)以及指向用户数据结构的指针(内核显式地使用es寄存器)。

#### Linux GDT

在单处理器系统中只有一个GDT，而在多处理器系统中每个CPU对应一个GDT。所有的GDT都存放在cpu_gdt_table数组中，而所有GDT的地址和它们的大小(当初始化gdtr寄存器时使用)被存放在cpu_gdt_descr数组中。如果你到源代码索引中查看，可以看到这些符号都在文件arch/i386/kernel/head.S中被定义。

下图是GDT的布局示意图。每个GDT包含18个段描述符和14个空的，未使用的，或保留的项。插入未使用的项的目的是为了使经常一起访问的描述符能够处于同一个32字节的硬件高速缓存行中。

![全局描述符表.jpg](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/%E5%85%A8%E5%B1%80%E6%8F%8F%E8%BF%B0%E7%AC%A6%E8%A1%A8.jpg?raw=true)

每一个GDT中包含的18个段描述符指同下列的段：

- 用户态和内核态下的代码段和数据段，共4个。
- 任务状态段（TSS），每个处理器有1个。每个TSS相应的线性地址空间都是内核数据段相应线性地址空间的一个小子集。所有的任务状态段都顺序地存放在init_tss数组中，值得特别说明的是，第n个CPU的TSS描述符的Base字段指向init_tss数组的第n个元素。G(粒度)标志被清0，而Limit字段置为0xeb，  因为TSS段是236字节长。Type字段置为9或11(可用的32位TSS)，且DPL置    为0，因为不允许用户态下的进程访问TSS段。
- 1个包括缺省局部描述符表的段，这个段通常被所有进程共享。
- 3个局部线程存储（Thread-Local Storage， TLS）段：这种机制允许多线程应用程序使用最多3个局部于线程的数据段。系统使用set_thread_area()和get_thread_area()分别为正在执行的进程创建和撤销一个TLS段。
- 与高级电源管理（APM）相关的3个段：由于BIOS代码使用段，所以当Linux APM驱动程序调用BIOS函数来获取或者设置APM设备的状态时，就可以使用自定义的代码段和数据段。
- 与支持即插即用（PnP）功能的BIOS服务程序相关的5个段。
- 被内核用来处理“双重错误”异常（处理一个异常时可能会引发另一个异常）的特殊TSS段。

系统中每个处理器都有一个GDT副本。除少数几种情况外，所有GDT的副本都存放相同的表项：

- 每个处理器都有它自己的TSS段。
- GDT中只有少数项可能依赖于CPU正在执行的进程（LDT和TLS段描述符）。
- 在某些情况下，处理器可能临时修改GDT副本里的某个项，例如，当调用APM的BIOS例程时就会发生这种情况。

#### Linux LDT

大多数用户态下的Linux程序不使用局部描述符表，这样内核就定义了一个缺省的LDT供大多数进程共享。缺省的局部描述符表存放在default_ldt数组中。它包含5个项，但内核仅仅有效地使用了其中的两个项：用于iBCS执行文件的调用门和Solaris/x86可执行文件的调用门。调用门是80x86微处理器提供的一种机制，用于在调用预定义函数时改变CPU的特权级（参考Intel文档以获取更多详情）。

在某些情况下，进程仍然需要创建自己的LDT，像Wine那样的程序，它们执行面向段的微软Windows应用程序。modify_ldt()系统调用允许进程创建自己的LDT。任何被modify_ldt()创建的自定义局部描述符表仍然需要它自己的段。当处理器开始执行拥有自定义局部描述符表的进程时，该CPU的GDT副本中的LDT表项相应地就被修改了。

用户态下的程序同样也利用modify_ldt()来分配新的段，但内核却从不使用这些段，它也不需要了解相应的段描述符，因为这些段描述符被包含在进程自定义的局部描述符表中了。

### 硬件中的分页

分页单元(paging unit)把线性地址转换成物理地址。其中的一个关键任务是把所请求的访问类型与线性地址的访问权限相比较，如果这次内存访问是无效的，就产生一个缺页异常。

为了效率起见，线性地址被分成以固定长度为单位的组，称为页（page）。页内部连续的线性地址被映射到连续的物理地址中。这样，内核可以指定一个页的物理地址和其存取权限，而不用指定页所包含的全部线性地址的存取权限。我们遵循通常习惯，使用术语“页”既指一组线性地址，又指包含在这组地址中的数据。

分页单元把所有的RAM分成固定长度的叶框（page frame）（也叫做物理页）。每一个叶框包含一个页，也就是说叶框的长度与一个页的长度一致。页框是主存的一部分，因此也是一个存储区域。区分一页和一个页框是很重要的，前者只是一个数据块，可以存放在任何页框或磁盘中。

把线性地址映射到物理地址的数据结构称为页表(page table )。页表存放在主存中，并在启用分页单元之前必须由内核对页表进行适当的初始化。

从80386开始，所有的80x86处理器都支持分页，它通过设置cr0寄存器的PG标志启用。当PG=0时，线性地址就被解释成物理地址。<需要了解控制寄存器(cr0~cr3)的结构及作用>

#### 常规分页

从80386起，Intel处理器的分页单元处理4KB的页。32位的线性地址被分成3个域：

- Directory（目录）：最高10位
- Table（页表）：中间10位
- Offset（偏移量）：最低12位

线性地址的转换分两步完成，每一步都基于一种转换表，第一种转换表称为页目录表(page directory)，第二种转换表称为页表(page table )(小写的‘page table’表示保存线性地址和物理地址之间映射的页，而利用‘Page Table’表示在上层页表中的页)。

页目录 及 页表都分别存放在1个页中（4KB），其中每个表项也都是4个字节。

使用这种二级模式的目的在于减少每个进程页表所需RAM的数量。如果使用简单的一级页表，那将需要高达2^20^个表项(也就是，在每项4个字节时，需要4MB RAM)来表示每个进程的页表(如果进程使用全部4GB线性地址空间)，即使一个进程并不使用那个范围内的所有地址。二级模式通过只为进程实际使用的那些虚拟内存区请求页表来减少内存容量。

每个活动进程必须有一个分配给它的页目录。不过，没有必要马上为进程的所有页表都分配RAM。只有在进程实际需要一个页表时才给该页表分配RAM会更为有效率。

正在使用的页目录的物理地址存放在控制寄存器cr3中。线性地址内的Directory字段决定页目录中的目录项，而目录项指向适当的页表。地址的Table字段依次又决定页表中的表项，而表项含所有页所在页框的物理地址。Offset字段决定页框内的相对位置。由于它是12位长，故每一页含有4096字节的数据。

![x86处理器的分页.jpg](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/x86%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E5%88%86%E9%A1%B5.jpg?raw=true)

Directory字段和Table字段都是10位长，因此页目录和页表都可以多达1024项。那么一个页目录可以寻址到高达1024 * 1024 * 4096 = 2^32^个存储单元，这和你对32位地址所期望的一样。

页目录项和页表项有相同的结构，每项都包含下面的字段：

| 字段                | 描述                                       |
| ----------------- | ---------------------------------------- |
| Present标志         | 置为1，所指的页（或页表）就在主存中；为0，则这一页不在主存，此时这个表项剩余的位可由操作系统用于自己的目的。如果只需一个地址转换所需的页表项或页目录项中Present标志被清0，那么分页单元就把该线性地址存放在控制寄存器cr2中，并产生14号异常：缺页异常。 |
| 包含页框物理地址最高20位的字段  | 由于每一个页框有4KB的容量，它的物理地址必须是4096的倍数，因此物理地址的最低12位总是为0。若这个字段指向一个页目录，相应的页框就含有一个页表，若指向一个页表，相应的页框就含有一页数据。 |
| Accessed标志        | 每当分页单元对相应页框进行寻址时就设置这个标志。当选中的页被交换出去时，这一标志由操作系统使用。分页单元从来不重置这个标志，而是必须由操作系统去做。 |
| Dirty标志           | 只应用于页表项中。每当对一个页框进行写操作时就设置这个标志。与Accessed标志一样，“当选中…………系统去做”。 |
| Read/Write标志      | 含有页或页表的存取权限。                             |
| User/Supervisor标志 | 含有访问页或页表所需的特权级。                          |
| PCD和PWT标志         | 控制硬件高速缓存处理页或页表的方式。                       |
| Page Size标志       | 只应用于页目录项。置为1，则页目录指的是2MB或4MB的页框。          |
| Global标志          | 只应用于页表项。这个标志是在Pentium Pro中引入的，用来防止常用页从TLB（俗称“快表”）高速缓存中刷新出去。只有在cr4寄存器的页全局启用（Page Global Enable， PGE）标志置位时这个标志才起作用。 |

#### 扩展分页

从Pentium模型开始，80x86微处理器引入了扩展分页（extended paging），它允许页框大小为4MB而不是4KB。扩展分页用于把大段连续的线性地址转换成相应的物理地址，在这些情况下，内核可以不用中间页表进行地址转换，从而节省内存并保留TLB项。

通过设置页目录项的Page Size标志启用扩展分页功能。分页单元吧32位线性地址分成两个字段：

- Directory：最高10位
- Offset：其余22位

扩展分页和正常分页的目录项基本相同，除了：

- Page Size标志必须被设置。
- 32位物理地址字段只有最高10位是有意义的。这是因为每一个物理地址都是在以4MB为边界的地方开始的，故这个地址的最低22位为0。

通过设置cr4处理器寄存器的PSE标志能使扩展分页与常规分页共存。

#### 硬件保护方案

分页单元和分段单元的保护方案不同。尽管x86处理器允许一个段使用4种可能的特权级别，但与页和页表相关的特权级只有两个，因为特权由User/Supervisor标志所控制。若这个标志为0，只有当CPL小于3(这意味着对于Linux而言，处理器处于内核态)时才能对页寻址。若该标志为1，则总能对页寻址。

此外，与段的3种存取权限（读、写、执行）不同的是，页的存取权限只有两种（度、写）。如果页目录项或页表项的Read/Write标志等于0，说明相应的页表或页是只读的，否则是可读写的。

#### 常规分页举例

假定内核已给一个正在允许的进程分配的线性地址空间范围是0x2000 0000 到 0x2003 ffff。这个空间正好由64页组成。从分配给进程的线性地址的最高10位（Directory字段）开始。这两个地址都以2开头后面跟着0，因此高10位有相同的值，即0x080或十进制128。因此，这两个地址的Directory字段都指向进程页目录的第129项。相应的目录项中必须包含分配给该进程的页表的物理地址。如果没有给这个进程分配其他的线性地址，则页目录的其余1023项都填为0.

中间10位的值（Table）范围从0到0x03f，十进制的0到63，因而只有页表的前64个表项是有意义的，其余960个表项都填0。

假设进程需要读取线性地址 0x2002 1406中的字节，则处理方法：

1. Directory字段的0x80用于选择页目录的第0x80目录项，此目录项指向和该进程的页相关的页表。
2. Table字段0x21用于选择页表的第0x21表项，此表项指向包含所需页的页框。
3. 最后，Offset字段0x406用于在目标页框中读偏移量为0x406中的字节。

如果页表第0x21表项的Present标志为0，则此页就不在主存中，这种情况下，分页单元在线性地址转换的同时产生一个缺页异常。无论何时，当进程试图访问限定在0x2000 0000 到 0x2003 ffff范围之外的线性地址时，都将产生一个缺页异常，因为这些页表项都填充了0，尤其是它们的Present标志都被清0。

#### 物理地址扩展（PAE）分页机制

处理器所支持的RAM容量受连接到地址总线上的地址管脚数限制。早期Intel处理器从80386到Pentium使用32位物理地址。从理论上讲，这样的系统上可以安装高达4GB的RAM；而实际上，由于用户进程线性地址空间的需要，内核不能直接对1GB以上的RAM进行寻址，我们将会在后而"Linux中的分页”一节中看到这一点。

然而，大型服务器需要大于4GB的RAM来同时运行数以千计的进程，所以必须扩展32位x86结构所支持的RAM容量。Intel通过在它的处理器上把管脚数从32增加到36已经满足了这些需求。寻址能力可达到2^36^ = 64GB。不过，只有引入一种新的分页机制把32位线性地址转换为36位物理地址才能使用所增加的物理地址。

从Pentium Pro处理器开始，Intel引入一种叫做 物理地址扩展（Physical Address Extension， PAE）的机制。另外一种叫做页大小扩展[Page Size Extension (PSE-36)]的机制在Pentium 3处理器中引入，但是Linux并没有采用这种机制。

通过设置cr4控制寄存器中的物理地址扩展（PAE）标志激活PAE。页目录项中的页大小标志PS启用大尺寸页(在PAE启用时为2MB)。

Intel为了支持PAE已经改变了分页机制：

- 64GB的RAM被分为2^24^个页框（4KB），页表项的物理地址字段从20位扩展到了24位。因为PAE页表项必须包含12个标志位(在前面已描述)和24个物理地址位，总数之和为36，页表项大小从32位变为64位增加了一倍。结果，一个4KB的页表包含512个表项而不是1024个表项。
- 引入一个叫做页目录指针表(Page Directory Pointer Table，  PDPT)的页表新级别，它由4个64位表项组成。
- cr3控制寄存器包含一个27位的页目录指针表(PDPT)基地址字段。因为PDPT存放在RAM的前4GB中，并在32字节(2^5^)的倍数上对齐，因此27位足以表示这种表的基地址。
- 当把线性地址映射到4KB的页时(页目录项中的PS标志清0)， 32位线性地址按下列方式解释：
  - cr3：指向一个PDPT
  - 位31-30：指向PDPT中4个项中的一个
  - 位29-21：指向页目录中512个项目中的一个
  - 位20-12：指向页表中512项中的一个
  - 位11-0：4KB页中的偏移量
- 当把线性地址映射到2MB的页时(页目录项中的PS标志置为1)， 32位线性地址按下列方式解释：
  - cr3：指向一个PDPT
  - 位31-30：指向PDPT中4个项中的一个
  - 位29-21：指向页目录中512个项中的一个
  - 位20-0：2MB页中的偏移量

总之，一旦cr3被设置，就可能寻址高达4GB RAM。如果我们希望对更多的RAM寻址，就必须在cr3中放置一个新值，或改变PDPT的内容。然而，使用PAE的主要问题是线性地址仍然是32位长。这就迫使内核编程人员用同一线性地址映射不同的RAM区。很明显，PAE并没有扩大进程的线性地址空间，因为它只处理物理地址。此外，只有内核能够修改进程的页表，所以在用户态下运行的进程不能使用大于4GB的物理地址空间。另一方面，PAE允许内核使用容量高达64GB的RAM，从而显著增加了系统中的进程数量。

#### 64位系统中的分页

32位微处理器普遍采用两级分页。然而两级分页并不适用于采用64位系统的计算机。让我们用一种思维实验来解释为什么：首先假设一个大小为4KB的标准页。因为1KB覆盖2^10^个地址的范围，4KB覆盖2^12^个地址，所以offset字段是12位。这样线性地址就剩下52位分配给Table和Directory字段。如果我们现在决定仅仅使用64位中的48位来寻址(这个限制仍然使我们自在地拥有256TB的寻址空间！)，剩下的48-12=36位将被分配给Table和Directory字段。如果我们现在决定为两个字段各预留18位，那么每个进程的页目录和页表都含有2^18^个项，即超过256000个项。

由于这个原因，所有64位处理器的硬件分页系统都使用了额外的分页级别。使用的级别数量取决于处理器的类型。

| 平台名称   | 页大小  | 寻址使用的位数 | 分页级别数 | 线性地址分级      |
| ------ | ---- | ------- | ----- | ----------- |
| alpha  | 8KB  | 43      | 3     | 10+10+10+13 |
| ia64   | 4KB  | 39      | 3     | 9+9+9+12    |
| ppc64  | 4KB  | 41      | 3     | 10+10+9+12  |
| sh64   | 4KB  | 41      | 3     | 10+10+9+12  |
| x86_64 | 4KB  | 48      | 4     | 9+9+9+9+12  |

#### 硬件高速缓存

当今的微处理器时钟频率接近几个GHz，而动态RAM（DRAM）芯片的存取时间是时钟周期的数百倍。这意味着，当从RAM中取操作数或向RAM中存放结果这样的指令执行时，CPU可能等待很长时间。

为了缩小CPU和RAM之间的速度不匹配，引入了硬件高速缓存内存(hardware cache memory )。硬件高速缓存基于著名的 局部性原理(locality principle)，该原理既适用程序结构也适用数据结构。这表明由于程序的循环结构及相关数组可以组织成线性数组，最近最常用的相邻地址在最近的将来又被用到的可能性极大。因此，引入小而快的内存来存放最近最常使用的代码和数据变得很有意义。为此，x86体系结构中引入了一个叫 行(line)的新单位。行由几十个连续的字节组成，它们以脉冲突发模式(burst mode)在慢速DRAM和快速的用来实现高速缓存的片上静态RAM ( SRAM)之间传送，用来实现高速缓存。

高速缓存再被细分为行的子集。在一种极端的情况下，高速缓存可以是直接映射的(direct mapped)，这时主存中的一个行总是存放在高速缓存中完全相同的位置。在另一种极端情况下，高速缓存是充分关联的(fully  associative)，这意味着主存中的任意一个行可以存放在高速缓存中的任意位置。但是大多数高速缓存在某种程度上是N-路组关联的(N-way set associative)，意味着主存中的任意一个行可以存放在高速缓存N行中的任意一行中。例如，内存中的一个行可以存放到一个2路组关联高速缓存两个不同的行中。

![处理器硬件高速缓存.png](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/%E5%A4%84%E7%90%86%E5%99%A8%E7%A1%AC%E4%BB%B6%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98.png?raw=true)

高速缓存单元插在分页单元和主内存之间。它包含一个硬件高速缓存内存(hardware cache memory)和一个高速缓存控制器(cache controller) 。高速缓存内存存放内存中真正的行。高速缓存控制器存放一个表项数组，每个表项对应高速缓存内存中的一个行。每个表项有一个标签（tag）和描述高速缓存行状态的几个标志（flag）。这个标签由一些位组成，这些位让高速缓存控制器能够辨别由这个行当前所映射的内存单元。这种内存物理地址通常分为3组：最高几位对应标签，中间几位对应高速缓存控制器的子集索引，最低几位对应行内的偏移量。

当访问一个RAM存储单元时，CPU从物理地址中提取出子集的索引号并把子集中所有行的标签与物理地址的高几位相比较。如果发现某一个行的标签与这个物理地址的高位相同，则CPU命中一个高速缓存(cache hit);否则，高速缓存没有命中(cache miss )。

当命中一个高速缓存时，高速缓存控制器进行不同的操作，具体取决于存取类型。对于读操作，控制器从高速缓存行中选择数据并送到CPU寄存器;不需要访问RAM因而节约了CPU时间，因此，高速缓存系统起到了其应有的作用。对于写操作，控制器可能采用以下两个基本策略之一，分别称之为通写（write-through）和回写(write-back)。在通写中，控制器总是既写RAM也写高速缓存行，为了提高写操作的效率关闭高速缓存。回写方式只更新高速缓存行，不改变RAM的内容，提供了更快的功效。当然，回写结束以后，RAM最终必须被更新。只有当CPU执行一条要求刷新高速缓存表项的指令时，或者当一个FLUSH硬件信号产生时(通常在高速缓存不命中之后)，高速缓存控制器才把高速缓存行写回到RAM中。

当高速缓存没有命中时，高速缓存行被写回到内存中，如果有必要的话，把正确的行从RAM中取出放到高速缓存的表项中。

多处理器系统的每一个处理器都有个单独的硬件高速缓存，因此它们去要额外的硬件电路用于保持高速缓存内容的同步。每个CPU都有自己的本地硬件高速缓存。但是，现在更新变得更耗时：只要一个CPU修改了它的硬件高速缓存，它就必须检查同样的数据是否包含在其他的硬件高速缓存中;如果是，它必须通知其他CPU用适当的值对其更新。常把这种活动叫做高速缓存侦听（cache snooping）。所有这一切都在硬件级处理，内核无需关心。

处理器的cr0寄存器的CD标志位用来启用或禁用高速缓存电路。这个寄存器中的NW标志指明高速缓存是使用通写还是回写策略。

Pentium处理器高速缓存的另一个有趣的特点是，让操作系统把不同的高速缓存管理策略与每一个页框相关联。为此，每一个页目录项和每一个页表项都包含两个标志：PCD(Page Cache Disablt)标志指明当访问包含在这个页框中的数据时，高速缓存功能必须被启用还是禁用。PWT(page Write-Through)标志指明当把数据写到页框时，必须使用的策略是回写策略还是通写策略。Linux清除了所有页目录项和页表项中的PCD和PWT标志；结果是：对于所有的页框都启用高速缓存，对于写操作总是采用回写策略。

#### 转换后援缓冲器（TLB）

除了通用硬件高速缓存之外，x86处理器还包含了另一个称为转换后援缓冲器或TLB(Translation Lookaside Buffer)的高速缓存用于加快线性地址的转换。当一个线性地址被第一次使用时，通过慢速访问RAM中的页表计算出相应的物理地址。同时，物理地址被存放在一个TLB表项(TLB entry)中，以便以后对同一个线性地址的引用可以快速地得到转换。

在多处理系统中，每个CPU都有自己的TLB，这叫做该CPU的本地TLB。与硬件高速缓存相反，TLB中的对应项不必同步，这是因为运行在现有CPU上的进程可以使同一线线性地址与不同的物理地址发生联系。

当CPU的cr3控制寄存器被修改时，硬件自动使本地TLB中的所有项都无效，这是因为新的一组页表被启用而TLB指向的是旧数据。

### Linux中的分页

Linux采用了一种同时适用于32位和64位系统的普通分页模型。正像前面所解释的那样，两级页表对32位系统来说已经足够了，但64位系统需要更多数量的分页级别。直到2.6.10版本，Linux采用三级分页的模型。从2.6.11版本开始，采用了四级分页模型。下图中展示的4种页表分别被为：

- 页全局目录(Page Global Directory )
- 页上级目录(Page Upper Directory )
- 页中级目录(Page Middle Directory )
- 页表(Page Table)

![Linux分页模式.jpg](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/Linux%E5%88%86%E9%A1%B5%E6%A8%A1%E5%BC%8F.jpg?raw=true)

页全局目录包含若干页上级目录的地址，页上级目录又依次包含若干页中间目录的地址，而页中间目录又包含若干页表的地址。每一个页表项指向一个页框。线性地址因此被分成五个部分。每一部分的大小与具体的计算机体系结构有关。

对于没有启用物理地址扩展的32位系统，两级页表已经足够了。Linux通过使“页上级目录”位和“页中间目录”位全为0，从根本上取消了页上级目录和页中间目录字段。不过，页上级目录和页中间目录在指针序列中的位置被保留，以便同样的代码在32位系统和64位系统下都能使用。内核为页上级目录和页中间目录保留了一个位置，这是通过把它们的页目录项数设置为1，并把这两个目录项映射到页全局目录的一个适当的目录项而实现的。

启用了物理地址扩展（PAE）的32位系统使用了三级页表。Linux的页全局目录对应x86的页目录指针表(PDPT)，取消了页上级目录，页中间目录对应x86的页目录，Linux的页表对应x86的页表。

最后，64位系统使用二级还是四级分页取决于硬件对线性地址的位的划分。

Linux的进程处理很大程度上依赖于分页。事实上，线性地址到物理地址的自动转换使下面的设计目标变得可行：

- 给每一个进程分配一块不同的物理地址空间，这确保了可以有效地防止寻址错误。
- 区别页(即一组数据)和页框(即主存中的物理地址)之不同。这就允许存放在某个页框中的一个页，然后保存到磁盘上，以后重新装入这同一页时又可以被装在不同的页框中。这就是虚拟内存机制的基本要素。

每个进程有它自己的页全局目录和自己的页表集。当发生进程切换时，Linux把cr3控制寄存器的内存保存在前一个执行进程的描述符中，然后把下一个要执行进程的描述符的值装入cr3寄存器中。因此，当新进程重新开始在CPU上执行时，分页单元指向一组正确的页表。

把线性地址映射到物理地址虽然有点复杂，但现在已经成了一种机械式的任务。下面会列举一些函数和宏，它们检索内核为了查找地址和管理表格所需的信息；其中大多数函数只有一两行。

#### 线性地址字段

下列宏简化了页表处理。

| 宏名                                       | 描述                                       |
| ---------------------------------------- | ---------------------------------------- |
| PAGE_SHIFT                               | 指定Offset字段的位数；当用于x86处理器时，它产生的值为12。由于页内所有地址都必须能放到Offset字段中，因此x86系统的页的大小是2^12^=4096字节。 |
| PMD_SHIFT                                | 指定线性地址的Offset字段和Table字段的总位数。换句话说，是页中间目录项可以映射的区域大小的对数。PMD_SIZE宏用于计算由页中间目录的一个单独表项所映射的区域大小，也就是一个页表的大小。PMD_MASK宏用于屏蔽Offset字段与Table字段的所有位。当PAE被禁用时，PMD_SHIFT产生的值为22(来自Offset的12位加上来自Table的10位)，PMD_SIZE产生的值为2^22^或4 MB ， PMD_MASK产生的值为0xffc000000相反，当PAE被激活时，PMD_SHIFT产生的值为21(来自Offset的12位加上来自Table的9位)，PMD_SIZE产生的值为2^21^或2 MB，  PMD_MASK产生的值为0xffe00000。大型页不使用最后一级页表，所以产生大型页尺寸的LARGE_PAGE_SIZE宏等于PMD_SIZE(2PMD_SHIFT)，而在大型页地址中用于屏蔽Offset字段和Table字段的所有位的LARGE_PAGE_MASK宏，就等于PMD_MASK。 |
| PUD_SHIFT                                | 确定页上级目录项能映射的区域大小的对数。PUD_SIZE宏用于计算页全局目录中的一个单独表项所能映射的区域大小。PUD_ MASK宏用于屏蔽Offset字段、Table字段、Middle Air字段和Upper Air字段的所有位。在x86处理器上，PUD_SHIFT总是等价于PMD_SHIFT，而PUD_SIZE则等于4MB或2MB。 |
| PGDIR_SHIFT                              | 确定页全局目录项能映射的区域大小的对数。PGDIR_SIZE宏用于计算页全局目录中一个单独表项所能映射区域的大小。PGDIR_MASK宏用于屏蔽Offset， Table， Middle Air及Upper Air字段的所有位。当PAE被禁止时，PGDIR_SHIFT产生的值为22(与PMD-SHIFT和PUD_SHIFT产生的值相同)，PGDIR_SIZE产生的值为2^22^或4MB，以及PGDIR_MASK产生的值为0xffc00000。相反，当PAE被激活时，PGDIR_SHIFT产生的值为30(12位Offset加9位Table再加9位Middle Air)，PGD工R_S工ZE产生的值为2^30^或1 GB以及PGDIR_ MASK产生的值为0xc0000000。 |
| PTRS_PER_PTE  PTRS_PER_PMD PTRS_PER_PUD PTRS_PER_PGD | 用于计算页表、页中间目录、页上级目录和页全局目录表中表项的个数。当PAE被禁止时，它们产生的值分别为1024，1，1和1024。当PAE被激活时，产生的值分别为512，512，1和4。 |

#### 页表处理

pte_t， pmd_t， pud_t和pgd_t分别描述页表项、页中间目录项、页上级目录和页全局目录项的格式。当PAE被激活时它们都是64位的数据类型，否则都是32位数据类型。pgprot_t是另一个64位(PAE激活时)或32位(PAE禁用时)的数据类型，它表示与一个单独表项相关的保护标志。

五个类型转换宏(\_\_pte、\_\_pmd、\_\_pud、\_\_pgd和__pgprot)把一个无符号整数转换成所需的类型。另外的五个类型转换宏(pte_val， pmd_val， pud_val， pgd_val和pgprot_val)执行相反的转换，即把上面提到的四种特殊的类型转换成一个无符号整数。
内核还提供了许多宏和函数用于读或修改页表表项：

- 如果相应的表项值为0，那么，宏pte_none， pmd_none， pud_none和pgd_none产生的值为1，否则产生的值为0。
- 宏pte_clear， pmd_clear， pud_clear和pgd_clear清除相应页表的一个表项，由此禁止进程使用由该页表项映射的线性地址。ptep_get and_clear()函数清除一个页表项并返回前一个值。
- set_pte， set_pmd， set_pud和 set_pgd向一个页表项中写入指定的值。set_pte_atomic与set_pte的作用相同，但是当PAE被激活时它同样能保证64位的值被原子地写入。
- 如果a和b两个页表项指向同一页并且指定相同的访问优先级，那么pte_same(a，b)返回1，否则返回0。
- 如果页中间目录项e指向一个大型页(2MB或4MB )，那么pmd_large(e)返回1，否贝返回0。

宏pmd_bad由函数使用并通过输入参数传递来检查页中间目录项。如果目录项指向一个不能使用的页表，也就是说，如果至少出现以下条件中的一个，则这个宏产生的值为1：

- 页不在主存中(Present标志被清除)。
- 页只允许读访问(Read/Write标志被清除)。
- Acessed或者Dirty位被清除(对于每个现有的页表，Linux总是强制设置这些 标志)。

宏pud_bad和pgd_bad总是产生0。没有定义pte_bad宏，因为页表项引用一个不在主存中的页、一个不可写的页或一个根本无法访问的页都是合法的。

如果一个页表项的Present标志或者Page Size标志等于1，则pte_present宏产生的值为1，否则为0。前面讲过页表项的Page Size标志对微处理器的分页单元来讲没有意义，然而，对于当前在主存中却又没有读、写或执行权限的页，内核将其Present和Page Size分别标记为0和1。这样，任何试图对此类页的访问都会引起一个缺页异常，因为页的Present标志被清0，而内核可以通过检查Page Size的值来检测到产生异常并不是因为缺页。

如果相应表项的Present标志等于1，也就是说，如果对应的页或页表被载入主存，pmd_present宏产生的值为1。pud_present宏和pgd_present宏产生的值总是1。

下表列出的函数用来查询页表项中任意一个标志的当前值；除了pte_file()外，其他函数只有在pte_present返回1的时候，才能正常返回页表项中任意一个标志。

| 函数名称                       | 说明                                       |
| -------------------------- | ---------------------------------------- |
| pte_user()                 | 读User/Supervisor标志                       |
| pte_read()                 | 读User/Supervisor标志（x86处理器上的页不受读的保护）      |
| pte_write()                | 读Read/Write标志                            |
| pte_exec()                 | 读User/Supervisor标志（x86处理器上的页不受代码执行的保护）   |
| pte_dirty()                | 读Dirty标志                                 |
| pte_young()                | 读Accessed标志                              |
| pte_file()                 | 读Dirty标志（当Present标志被清除而Dirty标志被设置时，页属于一个非线性磁盘文件映射） |
| mk_pte_huge()              | 设置页表项中的Page Size和Present标志               |
| pte_wrprotect()            | 清除Read/Write标志                           |
| pte_rdprotect()            | 清除User/Supervisor标志                      |
| pte_exprotect()            | 清除User/Supervisor标志                      |
| pte_mkwrite()              | 设置Read/Write标志                           |
| pte_mkread()               | 设置User/Supervisor标志                      |
| pte_mkexec()               | 设置User/Supervisor标志                      |
| pte_mkclean()              | 清除Dirty标志                                |
| pte_mkdirty()              | 设置Dirty标志                                |
| pte_mkold                  | 清除Accessed标志（此页标记为未访问）                   |
| pte_mkyoung                | 设置Accessed标志（此页标记为访问过）                   |
| pte_modify(p， v)           | 把页表项p的所有访问权限设置为指定的值v                     |
| ptep_set_wrprotect()       | 类似pre_wrprotect()，但作用于指向页表项的指针           |
| ptep_set_access_flags()    | 如果Dirty标志被设置为1，则将页的存取权限设置为指定的值，并调用flush_tlb_page()函数。 |
| ptep_mkdirty()             | 类似pte_mkdirty()，但作用于指向页表项的指针             |
| pte_test_and_clear_dirty() | 类似pte_mkclean()，但作用于指向页表项的指针并返回Dirty标志的旧值 |
| pte_test_and_clear_young() | 类似pte_mkold()，但作用于指向页表项的指针并返回Accessed标志的旧值 |

下表为一些宏，它们把一个页地址和一组保护标志组合成页表项，或者执行相反的操作，从一个页表项中提取出页地址。注意这其中一些宏对页的引用是通过“页描述符”的线性地址，而不是通过该页本身的线性地址。

| 宏名称                         | 说明                                       |
| --------------------------- | ---------------------------------------- |
| pgd_index(addr)             | 找到线性地址addr对应的目录项在页全局目录中的索引（相对位置）         |
| pgd_offset(mm，addr)         | 以内存描述符和线性地址作为参数。产生地址addr在页全局目录中相应表项的线性地址；通过内存描述符mm内的一个指针可以找到这个页全局目录 |
| pgd_offset_k(addr)          | 产生主内核页全局目录中的某个项的线性地址，该项                  |
| pgd_page(pgd)               | 通过页全局目录项pgd产生页上级目录所在页框的页描述符地址。在两级或三级分页系统中，该宏等价于pud_page()，后者应用于页上级目录项 |
| pud_offset(pgd，addr)        | 接收指向页全局目录项的指针pgd和线性地址addr作为参数。这个宏产生页上级目录中目录项addr对应的线性地址。在两级或三级分页系统中，该宏产生pgd，即一个页全局目录项的地址 |
| pud_page(pud)               | 通过页上级目录项pud产生相应的页中间目录的线性地址。在两级分页系统中，该宏等价于pmd_page() ，后者应用于页中间目录项 |
| pmd_index(addr)             | 产生线性地址addr在页中间目录中所对应目录项的索引(相对位置)         |
| pmd_offset(pud，addr)        | 接收指向页上级目录项的指针pud和线性地址addr作为参数。这个宏产生目录项addr在页中间目录中的偏移地址。在两级或三级分页系统中，它产生pud，即页全局目录项的地址 |
| pmd_page(pmd)               | 通过页中间目录项pmd产生相应页表的页描述符地址。在两级或三级分页系统中，pmd实际上是页全局目录中的一项 |
| mk_pte(p，prot)              | 接收页描述符地址P和一组存取权限prot作为参数，并创建相应的页表项       |
| pte_index(addr)             | 产生线性地址addr对应的表项在页表中的索引(相对位置)             |
| pte_offset_kernel(dir，addr) | 线性地址addr在页中间目录dir中有一个对应的项，该宏就产生这个对应项，即页表的线性地址。另外，该宏只在主内核页表上使用 |
| pte_offset_map(dir，addr)    | 接收指向一个页中间目录项的指针dir和线性地址addr作为参数，它产生与线性地址addr相对应的页表项的线性地址。如果页表被保存在高端内存中，那么内核建立一个临时内核映射，并用pte_unmap对它进行释放。pte_offset_map_nested宏和pte_unmap_nested宏是相同的，但它们使用不同的临时内核映射 |
| pte_page(x)                 | 返回页表项x所引用页的描述符地址                         |
| pte_to_pgoff(pte)           | 从一个页表项的pte字段内容中提取出文件偏移量，这个偏移量对应着一个非线性文件内存映射所在的页 |
| pgoff_to_pte(offset)        | 为非线性文件内存映射所在的页创建对应页表项的内容                 |

下表罗列最后一组函数来简化页表项的创建和撤消。

当使用两级页表时，创建或删除一个页中间目录项是不重要的。页中间目录仅含有一个指向下属页表的目录项。所以，页中间目录项只是页全局目录中的一项而已。然而当处理页表时，创建一个页表项可能很复杂，因为包含页表项的那个页表可能就不存在。在这样的情况下，有必要分配一个新页框，把它填写为0，并把这个表项加入。

如果PAE被激活，内核使用三级页表。当内核创建一个新的页全局目录时，同时也分配四个相应的页中间目录;只有当父页全局目录被释放时，这四个页中间目录才得以释放。

当使用两级或三级分页时，页上级目录项总是被映射为页全局目录中的一个单独项。

| 函数名称                            | 说明                                       |
| ------------------------------- | ---------------------------------------- |
| pgd_alloc(mm)                   | 分配一个新的页全局目录。如果PAE被激活，它还分配3个对应用户态线性地址的子页中间目录。mm在x86体系结构上被忽略 |
| pgd_free(pgd)                   | 释放页全局目录中地址为pgd的项。如果PAE被激活，它还将释放用户态线性地址对应的三个页中间目录 |
| pud_alloc(mm，pgd，addr)          | 在两级或三级分页系统下，这个函数什么也不做：它仅仅返回页全局目录项pgd的线性地址 |
| pud_free(x)                     | 在两级或三级分页系统下，这个宏什么也不做                     |
| pmd_alloc(mm，pud，addr)          | 定义这个函数以使普通三级分页系统可以为线性地址addr分配一个新的页中间目录。如果PAE未被激活，这个函数只是返回输入参数pud的值，也就是说，返回页全局目录中目录项的地址。如果PAE被激活，该函数返回线性地址addr对应的页 |
| pmd_free(x)                     | 该函数什么也不做，因为页中间目录的分配和释放是随同它们的父全局目录一同进行的   |
| pte_alloc_map(mm，pmd，addr)      | 接收页中间目录项的地址pmd和线性地址addr作为参数，并返回与addr对应的页表项的地址。如果页中间目录项为空，该函数通过调用函数pte_alloc_one()分配一个新页表。如果分配了一个新页表，addr对应的项就被创建，同时User/Supervisor标志被设置为1。如果页表被保存在高端内存，贝内核建立一个临时内核映射，并用pte_unmap对它进行释放 |
| pte_alloc_kernel(mm，pmd，addr)   | 如果与地址addr相关的页中间目录项pmd为空，该函数分配一个新页表。然后返回与addr相关的页表项的线性地址。该函数仅被主内核页表使用 |
| pte_free(pte)                   | 释放与页描述符指针pte相关的页表                        |
| pte_free_kernel(pte)            | 等价于pte_free()，但由主内核页表使用                  |
| clear_page_range(mmu，start，end) | 从线性地址start到end通过反复释放页表和清除页中间目录项来清除进程页表的内容 |

#### 物理内存布局

可参考   [地址空间布局](http：//www.cnblogs.com/chengxuyuancc/archive/2013/04/17/3026920.html)

在初始化阶段，内核必须建立一个物理地址映射来指定哪些物理地址范围对内核可用而哪些不可用。

内核将下列页框记为保留：

- 在不可用的物理地址范围内的页框。
- 含有内核代码和已初始化的数据结构的页框。

保留页框中的页绝不能被动态分配或交换到磁盘上。

一般来说，Linux内核安装在RAM中从物理地址0x00100000开始的地方，也就是说，从第二个MB开始。所需页框总数依赖干内核的配置方案：典型的配置所得到的内核可以被安装在小于3MB的RAM中。

为什么内核没有安装在RAM第一个MB开始的地方?因为PC体系结构有几个独特的地方必须考虑到。例如：

- 页框0由BIOS使用，存放加电自检(Power-On Self-Test， POST)期间检查到的系统硬件配置。因此，很多膝上型电脑的BIOS甚至在系统初始化后还将数据写到该页框。
- 物理地址从0x000a0000到0x000fffff的范围通常留给BIOS例程，并且映射ISA图形卡上的内部内存。这个区域就是所有IBM兼容PC上从640KB到1MB之间著名的洞：物理地址存在但被保留，对应的页框不能由操作系统使用。
- 第一个MB内的其他页框可能由特定计算机模型保留。例如，IBM Thinkpnd把0xa0页框映射到0x9f页框。

在启动过程的早期阶段，内核询问BIOS并了解物理内存的大小。在新近的计算机中，内核也调用BIOS过程建立一组物理地址范围和其对应的内存类型。

随后，内核执行machine_specific_memory_setup()函数，该函数建立物理地址映射。当然，如果这张表是可获取的，那是内核在BIOS列表的基础上构建的。否则，内核按保守的缺省设置构建这张表：从0x9f000(LOWMEMSIZE())到0x100000(HIGH_MEMORY)号的所有页框都标记为保留。

| 开始          | 结束           | 类型        |
| ----------- | ------------ | --------- |
| 0x0000 0000 | 0x0009 ffff  | Usable    |
| 0x000f 0000 | 0x000f ffff  | Reserved  |
| 0x0010 0000 | 0x07fe ffff  | Usable    |
| 0x07ff 0000 | 0x07ff 2ffff | ACPI data |
| 0x07ff 3000 | 0x07ff ffff  | ACPI NVS  |
| 0xffff 0000 | 0xffff ffff  | Reserved  |

上表显示了具有128MB(0x0800 0000) RAM计算机的典型配置。从0x07ff 0000到0x07ff 2fff 的物理地址范围中存有加电自检(POST)阶段由BIOS写入的系统硬件设备信息。在初始化阶段，内核把这些信息拷贝到一个合适的内核数据结构中，然后认为这些页框是可用的。相反，从0x07ff3000到0x07ff ffff的物理地址范围被映射到硬件设备的ROM芯片。从0xffff 0000开始的物理地址范围标记为保留，因为它由硬件映射到BIOS的ROM芯片。注意BIOS也许并不提供一些物理地址范围的信息(在上述表中，范围是0x000a 0000到0x000e ffff)。为安全可靠起见，Linux假定这样的范围是不可用的。

内核可能不会见到BIOS报告的所有物理内存：例如，如果未使用PAE支持来编译，即使有更大的物理内存可供使用，内核也只能寻址4GB大小的RAM。setup_memory()函数在machine_specific_memory_setup()执行后被调用：它分析物理内存区域表并初始化一些变量来描述内核的物理内存布局，这些变量如下表所示。

| 变量名称            | 说明                        |
| --------------- | ------------------------- |
| num_physpages   | 最高可用页框的页框号                |
| totalram_pages  | 可用页框的总数量                  |
| min_low_pfn     | RAM中在内核映像后第一个可用页框的页框号     |
| max_pfn         | 最后一个可用页框的页框号              |
| max_low_pfn     | 被内核直接映射的最后一个页框的页框号（低地址内存） |
| totalhigh_pages | 内核非直接映射的页框总数（高地址内存）       |
| highstart_pfn   | 内核非直接映射的第一个页框的页框号         |
| highend_pfn     | 内核非直接映射的最后一个页框的页框号        |

为了避免把内核装入一组不连续的页框里，Linux更愿跳过RAM的第一个MB。明确地说，Linux用PC体系结构未保留的页框来动态存放所分配的页。下图显示了Linux怎样填充前3MB的RAM：

![Linux2.6的前768个页框（3MB）.jpg](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/Linux2.6%E7%9A%84%E5%89%8D768%E4%B8%AA%E9%A1%B5%E6%A1%86%EF%BC%883MB%EF%BC%89.jpg?raw=true)

符号\_text对应于物理地址0x0010 0000，表示内核代码第一个字节的地址。内核代码的结束位代由另外一个类似的符号\_etext表示。内核数据分为两组：初始化过的数据的和没有初始化的数据。初始化过的数据在\_etext后开始，在\_edata处结束。紧接着是未初始化的数据并以\_end结束。

图中出现的符号并没有在Linux源代码中定义，它们是编译内核时产生的（可以在System.map文件中找到这些符号，System.map是编译内核以后所创建的）。

#### 进程页表

进程的线性地址空间分成两部分：

- 从0x0000 0000——0xbfff ffff的线性地址，无论进程运行在用户态还是内核态都可以寻址（0—3GB）。
- 从0xc000 0000——0xffff ffff的线性地址，只有内核的进程才能寻址。

进程运行在用户态时，所产生的线性地址小于0xc000 0000，而运行在内核态时，执行内核代码，所产生的地址大于等于0xc000 0000。但是，在某些情况下，内核为了检索或存放数据必须访问用户态线性地址空间。

宏PAGE_OFFSET产生的值是0xc000 0000，这就是进程在线性地址空间中的偏移量，也是内核生存空间的开始之处。

页全局目录的第一部分表项映射的线性地址小于0xc000 0000(在PAE未启用时是前768项，PAE启用时是前3项)，具体大小依赖于特定进程。相反，剩余的表项对所有进程来说都应该是相同的，它们等于主内核页全局目录的相应表项。

#### 内核页表

内核维持着一组自己使用的页表，驻留在所谓的主内核页全局目录(master kernel Page Global Directory)中。系统初始化后，这组页表还从未被任何进程或任何内核线程直接使用；更确切地说，主内核页全局目录的最高目录项部分作为参考模型，为系统中每个普通进程对应的页全局目录项提供参考模型。

内核初始化自己的页表，这个过程分为两个阶段。事实上，内核映像刚刚被装入内存后，CPU仍然运行于实模式，所以分页功能没有被启用。

第一个阶段，内核创建一个有限的地址空间，包括内核的代码段和数据段、初始页表和用于存放动态数据结构的共128KB大小的空间。这个最小限度的地址空间仅够将内核装入RAM和对其初始化的核心数据结构。

第二个阶段，内核充分利用剩余的RAM并适当地建立分页表。下一节解释这个方案是怎样实施的。

#### 临时内核页表

临时页全局目录是在内核编译过程中静态地初始化的，而临时页表是由startup_32()汇编语言函数(定义于arch/i386/kernel/head.S)初始化的。我们不再过多提及页上级目录和页中间目录，因为它们相当于页全局目录项。在这个阶段PAE支持并未激活。

临时页全局目录放在swapper_pg_dir变量中。临时页表在pg0变量处开始存放，紧接在内核未初始化的数据段(_end符号)后面。为简单起见，我们假设内核使用的段、临时页表和128KB的内存范围能容纳于RAM前8MB空间里。为了映射RAM前8MB的空间，需要用到两个页表。

分页第一个阶段的目标是允许在实模式下和保护模式下都能很容易地对这8MB寻址。因此，内核必须创建一个映射，把从0x0000 0000到0x007f ffff的线性地址和从0xc000 0000到0xc07f ffff的线性地址映射到从0x0000 0000到0x007f ffff的物理地址。换句话说，内核在初始化的第一阶段，可以通过与物理地址相同的线性地址或者通过从0xc000 0000开始的8MB线性地址对RAM的前8MB进行寻址。

内核通过把swapper_pg_dir所有项都填充为0来创建期望的映射，不过，0、1、0x300(十进制768)和0x301(十进制769)这四项除外。后两项包含了从0xc000 0000到0xc07f ffff间的所有线性地址。0、1、0x300和0x301按以下方式初始化：

- 0项和0x300项的地址字段置为pg0的物理地址，而1项和0x301项的地址字段 置为紧随pg0后的页框的物理地址。
- 把这四个项中的Present、Read/Write和User/Supervisor标志置位。
- 把这四个项中的Accessed、Dirty、PCD、PWD和Page Size标志清0。

汇编语言函数startup_32()也启用分页单元，通过向cr3控制寄存器装入swapper_pg_dir的地址及设置cr0控制寄存器的PG标志来达到这一目的。下面是等价的代码片段：

```c
movl $swapper_pg_dir-0xc0000000，%eax
movl %eax，%cr3		/*设置页表指针*/
movl %cr0，%eax
orl $0x80000000，%eax
movl %eax，%cr0		/*设置分页(PG)位“/
```

#### 当RAM小于896MB时的最终内核页表

由内核页表所提供的最终映射必须把从0xc0000000开始的线性地址转化为从0开始的物理地址。

宏\_\_pa用于把从PAGE_OFFSET开始的线性地址转换成相应的物理地址，而宏\_\_va做相反的转化。

主内核页全局目录仍然保存在swapper_pg_dir变量中。它由paging_init()函数初始化。该函数进行如下操作：

1. 调用pagetable_init()适当地建立页表项。
2. 把swapper_pg_dir的物理地址写入cr3控制寄存器中。
3. 如果CPU支持PAE并且如果内核编译时支持PAE，则将cr4控制寄存器的PAE标志置位。
4. 调用\_\_flush_tlb_all()使TLB的所有项无效。

pagetable_init()执行的操作既依赖于现有RAM的容量，也依赖于CPU模型。让我们从最简单的情况开始。我们的计算机有小于896MB(1024-128，128MB留给其他映射)的RAM， 32位物理地址足以对所有可用RAM进行寻址，因而没有必要激活PAE机制。
swapper_pg_dir页全局目录由如下等价的循环重新初始化：

```c
pgd = swapper_pg_dir + pgd_index(PAGE_OFFSET);	/*768*/
phys_addr = 0x00000000;
while(phys_addr < (max_low_pfn * PAGE_SIZE))
{
    pmd = one_md_table_init(pgd);	/*返回pgd*/
  	set_pmd(pmd， __pmd(phys_addr | pgprot_val(__pgprot(0x1e3))));
  /*0x1e3 == Present，Accessed，Dirty，Read/Write，Page Size，Global*/
  	phys_addr += PTRS_PER_PTE * PAGE_SIZE;	/*0X400000*/
  	++pgd;
}
```

我们假定CPU是支持4MB页和“全局(global)" TLB表项的最新x86微处理器。注意如果页全局目录项对应的是0xc0000000之上的线性地址，则把所有这些项的User/Supervisor标志清0，由此拒绝用户态进程访问内核地址空间。还要注意Page Size被置位使得内核可以通过使用大型页来对RAM进行寻址(“扩展分页”)。

由startup_32()函数创建的物理内存前8MB的恒等映射用来完成内核的初始化阶段。当这种映射不再必要时，内核调用zap_low_mappings()函数清除对应的页表项。

实际上，这种描述并未说明全部事实。我们将在后面“固定映射的线性地址”一节看到，内核也调整与“固定映射的线性地址”对应的页表项。

#### 当RAM大小在896MB—4096MB时的最终内核页表

在这种情况下，并不把RAM全部映射到内核地址空间。Linux在初始化阶段可以做的最好的事是把一个具有896MB的RAM窗口(window)映射到内核线性地址空间。如果一个程序需要对现有RAM的其余部分寻址，那就必须把某些其他的线性地址间隔映射到所需的RAM。这意味着修改某些页表项的值。将在以后（L-B：第八章 内存管理）讨论这种动态重映射是如何进行的。

内核使用与前一种情况相同的代码来初始化页全局目录。

#### 当RAM大于4096MB时的最终内核页表

现在考虑RAM大于4GB计算机的内核页表初始化;更确切地说，处理以下发生的情况：

- CPU模型支持物理地址扩展(PAE)
- RAM容量大于4GB
- 内核以PAE支持来编译

尽管PAE处理36位物理地址，但是线性地址依然是32位地址。如前所述，Linux映射一个896MB的RAM窗口到内核线性地址空间，剩余RAM留着不映射，并由动态重映射来处理，（L-B：第八章 内存管理）将对此进行描述。与前一种情况的主要差异是使用三级分页模型，因此页全局目录按以下循环代码来初始化：

```c
pgd_idx = pgd_index(PAGE_OFFSET);	/* 3 */
for(i = 0; i < pgd_idx; i++)
    set_pgd(swapper_pg_dir + i， __pgd(__pa(empty_zero_page) + 0x001));		/* 0x001 == Present */
pgd = swapper_pg_dir + pgd_idx;
phys_addr = 0x00000000;
for(; i < PTRS_PER_PGD; ++i， ++pgd)
{
    pmd = (pmd_t *)alloc_bootmem_low_pages(PAGE_SIZE);
  	set_pgd(pgd， __pgd(__pa(pmd) | 0x001));
  	if(phys_addr < max_low_pfn * PAGE_SIZE)
      	for(j = 0; j < PTRS_PER_PMD && phys_addr < max_low_pfn * PAGE_SIZE; ++j)
        {
            set_pmd(pmd， __pmd(phys_addr | pgprot_val(__pgprot(0x1e3))));
          	/*0x1e3 == Present，Accessed，Dirty，Read/Write，Page Size，Global*/
            phys_addr += PTRS_PER_PTE * PAGE_SIZE;	/* 0x200000 */
        }
}
swapper_pg_dir[0] = swapper_pg_dir(pgd_idx);
```

页全局目录中的前三项与用户线性地址空间相对应，内核用一个空页(empty_zeropage)的地址对这三项进行初始化。第四项用页中间目录(pmd)的地址初始化，该页中间目录是通过调用alloc_bootmem_low_pages()分配的。页中间目录中的前448项(有512项，但后64项留给非连续内存分配)用RAM前896MB的物理地址填充。

注意，支持PAE的所有CPU模型也支持大型2MB页和全局页。正如前一种情况一样，只要可能，Linux使用大型页来减少页表数。

然后页全局目录的第四项被拷贝到第一项中，这样好为线性地址空间的前896MB中的低物理内存映射作镜像。为了完成对SMP系统的初始化，这个映射是必需的：当这个映射不再必要时，内核通过调用zap_low_mappings()函数来清除对应的页表项，正如先前的情况一样。

#### 固定映射的线性地址

内核线性地址第四个GB的初始部分映射系统的物理内存。但是，至少128MB的线性地址总是留作他用，因为内核使用这些线性地址实现非连续性内存分配和固定映射的线性地址。

非连续内存分配仅仅是动态分配和释放内存页的一种特殊方式。

固定映射的线性地址（fix-mapped linear address）基本上是一种类似于0xffff c000这样的常量线性地址，其对应的物理地址不必等于线性地址减去0xc000 0000，而是可以以任意方式建立。因此，每个固定映射的线性地址都映射一个物理内存的页框。之后会看到，内核使用固定映射的线性地址来代替指针变量，因为这些指针变量的值从不改变。

固定映射的线性地址概念上类似于对RAM前896MB映射的线性地址。不过，固定映射的线性地址可以映射任何物理地址，而由第4GB初始部分的线性地址所建立的映射是线性的（线性地址X 映射物理地址X-PAGE_OFFSET）。
就指针变量而言，固定映射的线性地址更有效。事实上，间接引用一个指针变量比间接引用一个立即常量地址要多一次内存访问。此外，在间接引用一个指针变量之前对其值进行检查是一个良好的编程习惯；相反，对一个常量线性地址的检查则是没有必要的。

每个固定映射的线性地址都由定义于enum fixed_addresses的数据结构中的整型索引来表示：

```c
enum fixed_addresses {
#ifdef CONFIG_X86_32
	FIX_HOLE，
	FIX_VDSO，
#else
	VSYSCALL_LAST_PAGE，
	VSYSCALL_FIRST_PAGE = VSYSCALL_LAST_PAGE
			    + ((VSYSCALL_END-VSYSCALL_START) >> PAGE_SHIFT) - 1，
	VSYSCALL_HPET，
#endif
	FIX_DBGP_BASE，
	FIX_EARLYCON_MEM_BASE，
#ifdef CONFIG_PROVIDE_OHCI1394_DMA_INIT
	FIX_OHCI1394_BASE，
#endif
#ifdef CONFIG_X86_LOCAL_APIC
	FIX_APIC_BASE，	/* local (CPU) APIC) -- required for SMP or not */
#endif
#ifdef CONFIG_X86_IO_APIC
	FIX_IO_APIC_BASE_0，
	FIX_IO_APIC_BASE_END = FIX_IO_APIC_BASE_0 + MAX_IO_APICS - 1，
#endif
#ifdef CONFIG_X86_VISWS_APIC
	FIX_CO_CPU，	/* Cobalt timer */
	FIX_CO_APIC，	/* Cobalt APIC Redirection Table */
	FIX_LI_PCIA，	/* Lithium PCI Bridge A */
	FIX_LI_PCIB，	/* Lithium PCI Bridge B */
#endif
#ifdef CONFIG_X86_F00F_BUG
	FIX_F00F_IDT，	/* Virtual mapping for IDT */
#endif
#ifdef CONFIG_X86_CYCLONE_TIMER
	FIX_CYCLONE_TIMER， /*cyclone timer register*/
#endif
#ifdef CONFIG_X86_32
	FIX_KMAP_BEGIN，	/* reserved pte's for temporary kernel mappings */
	FIX_KMAP_END = FIX_KMAP_BEGIN+(KM_TYPE_NR*NR_CPUS)-1，
#ifdef CONFIG_PCI_MMCONFIG
	FIX_PCIE_MCFG，
#endif
#endif
#ifdef CONFIG_PARAVIRT
	FIX_PARAVIRT_BOOTMAP，
#endif
	FIX_TEXT_POKE1，	/* reserve 2 pages for text_poke() */
	FIX_TEXT_POKE0， /* first page is last， because allocation is backward */
	__end_of_permanent_fixed_addresses，
	/*
	 * 256 temporary boot-time mappings， used by early_ioremap()，
	 * before ioremap() is functional.
	 *
	 * If necessary we round it up to the next 256 pages boundary so
	 * that we can have a single pgd entry and a single pte table：
	 */
#define NR_FIX_BTMAPS		64
#define FIX_BTMAPS_SLOTS	4
#define TOTAL_FIX_BTMAPS	(NR_FIX_BTMAPS * FIX_BTMAPS_SLOTS)
	FIX_BTMAP_END =
	 (__end_of_permanent_fixed_addresses ^
	  (__end_of_permanent_fixed_addresses + TOTAL_FIX_BTMAPS - 1)) &
	 -PTRS_PER_PTE
	 ? __end_of_permanent_fixed_addresses + TOTAL_FIX_BTMAPS -
	   (__end_of_permanent_fixed_addresses & (TOTAL_FIX_BTMAPS - 1))
	 ： __end_of_permanent_fixed_addresses，
	FIX_BTMAP_BEGIN = FIX_BTMAP_END + TOTAL_FIX_BTMAPS - 1，
#ifdef CONFIG_X86_32
	FIX_WP_TEST，
#endif
#ifdef CONFIG_INTEL_TXT
	FIX_TBOOT_BASE，
#endif
	__end_of_fixed_addresses
};
```

每个固定映射的线性地址都存放在线性地址第四个GB的末端。fix_to_virt()函数计算从给定索引开始的常量线性地址：

```c
static __always_inline unsigned long fix_to_virt(const unsigned int idx)
{
	/*
	 * this branch gets completely eliminated after inlining，
	 * except when someone tries to use fixaddr indices in an
	 * illegal way. (such as mixing up address types or using
	 * out-of-range indices).
	 *
	 * If it doesn't get removed， the linker will complain
	 * loudly with a reasonably clear error message..
	 */
	if (idx >= __end_of_fixed_addresses)
		__this_fixmap_does_not_exist();

	return __fix_to_virt(idx);
}
```

假定某个内核函数调用fix_to_virt(FIX_IO_APIC_BASE\_0)。因为该函数声明为"\_\_always_inline"，所以C编译程序不调用fix_to_virt()，而仅仅把它的代码插入到调用函数中。此外，运行时从不对这个索引值进行检查。事实上，FIX_IO_APIC_BASE_0是个等于3的常量，因此编译程序可以去掉if语句，因为它的条件在编译时为假。相反，如果条件为真，或者参数不是一个常量，则编译程序在连接阶段产生一个错误，因为符号__this_fixmap_does_not_exist在别处没有定义。最后，编译程序计算0xffff f000-(3 << PAGE_SHIFT)，并用常量线性地址0xfff c000代替fix_to_virt()函数调用。

为了把一个物理地址与固定映射的线性地址关联起来，内核使用set_fixmap(idx，phys)和set_fixmap_nocache(idx，phys)宏。这两个函数都把fix_to_virt(idx)线性地址对应的一个页表项初始化为物理地址phys；不过，第二个函数也把页表项的PCD标志置位，因此，当访问这个页框中的数据时禁用硬件高速缓存。反过来，clear_fixmap(idx)用来撤消固定映射线性地址idx和物理地址之间的连接。

#### 处理硬件高速缓存和TLB

硬件高速缓存是通过高速缓存行(cache line)寻址的。L1_CACHE_BYTES宏产生以字节为单位的高速缓存行的大小。在早于Pentium 4的Intel模型中，这个宏产生的值为32;在Pentium 4上，它产生的值为128。

- 为了使高速缓存的命中率达到最优化，内核在下列决策中考虑体系结构：
  一个数据结构中最常使用的字段放在该数据结构内的低偏移部分，以便它们能够处于高速缓存的同一行中。
- 当为一大组数据结构分配空间时，内核试图把它们都存放在内存中，以便所有高速缓存行按同一方式使用。

x86微处理器自动处理高速缓存的同步，所以应用于这种处理器的Linux内核并不处理任何硬件高速缓存的刷新。不过内核却为不能同步高速缓存的处理器提供了高速缓存刷新接口。

处理器不能自动同步它们自己的TLB高速缓存，因为决定线性地址和物理地址之间映射何时不再有效的是内核，而不是硬件。

Linux 2.6提供了几种在合适时机应当运用的TLB刷新方法，这取决于页表更换的类型。

| 方法名称                   | 说明                      | 典型的应用时机        |
| ---------------------- | ----------------------- | -------------- |
| flush_tlb_all          | 刷新所有TLB表项               | 改变内核页表项时       |
| flush_tlb_kernel_range | 刷新给定线性地址范围内的所有TLB表项     | 更换一个范围内的内核页表项时 |
| flush_tlb              | 刷新当前进程拥有的非全局页相关的所有TLB表项 | 执行进程切换时        |
| flush_tlb_mm           | 刷新指定进程拥有的非全局页相关的所有TLB表项 | 创建一个新的子进程时     |
| flush_tlb_range        | 刷新指定进程的线性地址间隔对应的TLB表项   | 释放某个进程的线性地址间隔时 |
| flush_tlb_pgtables     | 刷新指定进程中特定的相临页表集相关的TLB表项 | 释放进程的一些页表时     |
| flush_tlb_page         | 刷新指定进程中单个页表项相关的TLB表项    | 处理缺页异常时        |

尽管普通Linux内核提供了丰富的TLB方法，但通常每个微处理器都提供了更受限制的一组使TLB无效的汇编语言指令。在这个方面，一个更为灵活的硬件平台就是Sun的U1traSPARC。与之相比，Intel微处理器只提供了两种使TLB无效的技术：

- 在向cr3寄存器写入值时所有Pentium处理器自动刷新相对于非全局页的TLB表项。
- 在Pentium Pro及以后的处理器中，invlpg汇编语言指令使映射指定线性地址的单个TLB表项无效。

下表列出了采用这种硬件技术的Linux宏；这些宏是实现独立于系统的方法（上表）的基本要素。

| 宏名称                      | 描述                                       | 使用对象                                   |
| ------------------------ | ---------------------------------------- | -------------------------------------- |
| __flush_tlb()            | 将cr3寄存器的当前值重新写回cr3                       | flush_tlb，flush_tlb_mm，flush_tlb_range |
| __flush_tlb_global()     | 通过清除cr4的PGE禁用全局页，将cr3寄存器的当前值重新写回cr3，并在此设置PGE标志 | flush_tlb_all，flush_tlb_kernel_range   |
| __flush_tlb_single(addr) | 以addr为参数执行invlpg汇编语言指令                   | flush_tlb_page                         |

上表中没有flush tlb_pgtables方法：在x86系统中，当页表与父页表解除链接时什么也不需要做，所以实现这个方法的函数为空。

独立于体系结构的使TLB无效的方法非常简单地扩展到了多处理器系统上。在一个CPU上运行的函数发送一个处理器间中断给其他的CPU来强制它们执行适当的函数使TLB无效。

一般来说，任何进程切换都会暗示着更换活动页表集。相对于过期页表，本地TLB表项必须被刷新；这个过程在内核把新的页全局目录的地址写入cr3控制寄存器时会自动完成。不过内核在下列情况下将避免TLB被刷新：

- 当两个使用相同页表集的普通进程之间执行进程切换时。
- 当在一个普通进程和一个内核线程间执行进程切换时。（内核线程无自己的页表集，使用上一个普通进程的页表集）

除了进程切换以外，还有其他几种情况下内核需要刷新TLB中的一些表项。例如，当内核为某个用户态进程分配页框并将它的物理地址存入页表项时，它必须刷新与相应线性地址对应的任何本地TLB表项。在多处理器系统中，如果有多个CPU在使用相同的页表集，那么内核还必须刷新这些CPU上使用相同页表集的TLB表项。

为了避免多处理器系统上无用的TLB刷新，内核使用一种叫做懒惰TLB (lazy TLB)模式的技术。其基本思想是，如果几个CPU正在使用相同的页表，而且必须对这些CPU上的一个TLB表项刷新，那么，在某些情况下，正在运行内核线程的那些CPU上的刷新就可以延迟。

事实上，每个内核线程并不拥有自己的页表集，它使用一个普通进程的的页表集。不过，没有必要使一个用户态线性地址对应的TLB表项无效，因为内核线程不访问内核态地址空间。（flush_tlb_all方法不使用懒惰TLB模式机制）

当某个CPU开始运行一个内核线程时，内核把它置为懒惰TLB模式。当发出清除TLB表项的请求时，处于懒惰TLB模式的每个CPU都不刷新相应的表项。但是，CPU记住它的当前进程正运行在一组页表上，而这组页表的TLB表项对用户态地址是无效的。只要处于懒惰TLB模式的CPU用一个不同的页表集切换到一个普通进程，硬件就自动刷新TLB表项，同时内核把CPU设置为非懒惰TLB模式。然而，如果处于懒惰TLB模式的CPU切换到的进程与刚才运行的内核线程拥有相同的页表集，那么，任何使TLB无效的延迟操作必须由内核有效地实施；这种使TLB无效的“懒惰”操作可以通过刷新CPU的所有非全局TLB项来有效地获取。

为了实现懒惰TLB模式，需要一些额外的数据结构。cpu_tlbstate变量是一个具有NR_CPUS个结构的静态数组，这个结构有两个字段，一个是指向当前进程内存描述符的active_ mm字段，一个是具有两个状态值的state字段：TLBSTATE_ OK(非懒惰TLB模式)或TLBSTATE_LAZY(懒惰TLB模式)。此外，每个内存描述符中包含一个cpu_vm_mask字段，该字段存放的是CPU(这些CPU将要接收与TLB刷新相关的处理器间中断)下标；只有当内存描述符属于当前运行的一个进程时这个字段才有意义。

当一个CPU开始执行内核线程时、内核把该CPU的cpu_tlbstate元素的state字段置为TLBSTATE_LAZY。此外，活动(active)内存描述符的cpu_vm_mask字段存放系统中所有CPU(包括进入懒惰TLB模式的CPU)的下标。对于与给定页表集相关的所有CPU的TLB表项，当另外一个CPU想使这些表项无效时，该CPU就把一个处理器间中断发送给下标处于对应内存描述符的cpu_vm_mask字段中的那些CPU。

当CPU接受到一个与TLB刷新相关的处理器间中断，并验证它影响了其当前进程的页表集时，它就检查它的cpu_tlbstate元素的state字段是否等于TLBSTATE_LAZY；如果等于，内核就拒绝使TLB表项无效，并从内存描述符的cpu_vm_mask字段删除该CPU下标。这有两种结果：

- 只要CPU还处于懒惰TLB模式，它将不接受其他与TLB刷新相关的处理器间中断。
- 如果CPU切换到另一个进程，而这个进程与刚被替换的内核线程使用相同的页表集，那么内核调用\_\_flush_tlb()使该CPU的所有非全局TLB表项无效。

##  第3章 进程

进程是任何多道程序设计操作系统中的基本概念。

### 进程、轻量级进程和线程

进程是程序执行的一个实例，是充分描述程序已经执行到何种程度的数据结构的汇集。

从内核观点看，进程的目的就是担当分配系统资源（CPU时间、内存等）的实体。

拥有很多相对独立执行流的用户程序共享应用程序的大部分数据结构。一个进程由几个用户线程(或简单地说，线程)组成，每个线程都代表进程的一个执行流。大部分多线程应用程序都是用pthread(POSIX thread)库的标准库函数集编写的。

Linux内核的早期版本没有提供多线程应用的支持。从内核观点看，多线程应用程序仅仅是一个普通进程。多线程应用程序多个执行流的创建、处理、调度整个都是在用户态进行的(通常使用POSIX兼容的pthread库)。

但是，这种多线程应用程序的实现方式不那么令人满意。例如，假设一个象棋程序使用两个线程：其中一个控制图形化棋盘，等待人类选手的移动并显示计算机的移动，而另一个思考棋的下一步移动。尽管第一个线程等待选手移动时，第二个线程应当继续运行，以此利用选手的思考时间。但是，如果象棋程序仅是一个单独的进程，第一个线程就不能简单地发出等待用户行为的阻塞系统调用。否则，第二个线程也被阻塞。相反，第一个线程必须使用复杂的非阻塞技术来确保进程仍然是可运行的。

Linux使用轻量级进程(lightwetght process)对多线程应用程序提供更好的支持。两个轻量级进程基本上可以共享一些资源，诸如地址空间、打开的文件等等。只要其中一个修改共享资源，另一个就立即查看这种修改。当然，当两个线程访问共享资源时就必须同步它们自己。

实现多线程应用程序的一个简单方式就是把轻量级进程与每个线程关联起来。这样，线程之间就可以通过简单地共享同一内存地址空间、同一打开文件集等来访问相同的应用程序数据结构集。同时，每个线程都可以由内核独立调度，以便一个睡眠的同时另一个仍然是可运行的。POSIX兼容的pthread库使用Linux轻量级进程有3个例子，它们是LinuxThreads， Native Posix Thread Library(NPTL)和IBM的下一代Posix线程包NGPT(Next Generation Posix Threading Package)。

POSIX兼容的多线程应用程序由支持“线程组”的内核来处理。在Linux中，一个线程组基本上就是实现了多线程应用的一组轻量级进程，对于像getpid()，kill()，和_exit()这样的一些系统调用，它像一个组织，起整体的作用。

### 进程描述符

为了管理进程，内核必须对每个进程所做的事情进行清楚的描述。例如，内核必须知道进程的优先级，它是正在CPU上运行还是因某些事件而被阻塞，给它分配了什么样的地址空间，允许它访问哪个文件等等。这正是进程描述符(process descriptor)的作用——进程描述符都是task struct类型结构，它的字段包含了与一个进程相关的所有信息。它不仅包含了很多进程属性的字段，而且一些字段还包括了指向其他数据结构的指针，依此类推。

![Linux进程描述符.png](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/Linux%E8%BF%9B%E7%A8%8B%E6%8F%8F%E8%BF%B0%E7%AC%A6.png?raw=true)

#### 进程状态

进程描述符中的state字段描述了进程当前所处的状态。它由一组标志组成，其中每个标志描述一种可能的进程状态，且状态是互斥的。

| 标志                              | 描述                                       |
| ------------------------------- | ---------------------------------------- |
| 可运行状态(TASK_RUNNING)             | 进程要么在CPU上执行，要么准备执行。                      |
| 可中断的等待状态(TASK_INTERRUPTIBLE)    | 进程被挂起(睡眠)，直到某个条件变为真。产生一个硬件中断，释放进程正等待的系统资源，或传递一个信号都是可以唤醒进程的条件(把进程的状态放回到TASK_RUNNING)。 |
| 不可中断的等待状态(TASK_UNINTERRUPTIBLE) | 与可中断的等待状态类似，但是，把信号传递到睡眠进程不能改变它的状态。这种状态在一些特定的情况下(进程必须等待，直到一个不能被中断的事件发生)是很有用的。例如，当进程打开一个设备文件，其相应的设备驱动程序开始探测相应的硬件设备时会用到这种状态。探测完成以前，设备驱动程序不能被中断，否则，硬件设备会处于不可预知的状态。 |
| 暂停状态(TASK_STOPPED)              | 进程的执行被暂停。当进程接收到SIGSTOP， SIGTSTP，  SIGTTIN或SIGTTOU信号后，进入暂停状态。 |
| 跟踪状态(TASK_TRACED)               | 进程的执行已由debugger程序暂停。当一个进程被另一个进程监控时(例如    debugger执行ptrace()系统调用监控一个测试程序)，任何信号都可以把这个进程置于TASK_TRACED状态。 |
| 僵死状态(EXIT_ZOMBIE)               | 可存放在exit_state字段中。进程的执行被终止，但是，父进程还没有发布wait4()或waitpid()系统调用来返回有关死亡进程的信息。发布wait()类系统调用前，内核不能丢弃包含在死进程描述符中的数据，因为父进程可能还需要它。 |
| 僵死撤消状态(EXIT_DEAD)               | 最终状态：由于父进程刚发出wait4()或waitpid()系统调用，因而进程由系统删除。为了防止其他执行线程在同一个进程上也执行wait()类系统调用(这是一种竞争条件)，而把进程的状态由僵死(EXIT_ZOMBIE)状态改为僵死撤消状态 (EXIT_DEAD)。 |

内核使用set_task_state和set_current_state宏分别设置指定进程的状态和当前执行进程的状态。此外，这些宏确保编译程序或CPU控制单元不把赋值操作与其他指令混合。混合指令的顺序有时会导致灾难性的后果。

#### 标识一个进程

能被独立调度的每个执行上下文都必须拥有它自己的进程描述符。因此，即使共享内核大部分数据结构的轻量级进程，也有它们自己的task_struct结构。

进程和进程描述符之间有非常严格的一一对应关系，这使得用32位进程描述符地址标识进程成为一种方便的方式。进程描述符指针指向这些地址，内核对进程的大部分引用是通过进程描述符指针进行的。

另一方面，类Unix操作系统允许用户使用一个叫做进程标识符process ID(或PID)的数来标识进程，PID存放在进程描述符的pid字段中。PID被顺序编号，新创建进程的PID通常是前一个进程的PID加1。不过，PID的值有一个上限，当内核使用的PID达到这个上限值的时候就必须开始循环使用已闲置的小PID号。系统管理员可以通过往/proc/sys/kernel/pid_max这个文件中写入一个值来更改PID的上限值。

由于循环使用PID编号，内核必须通过管理一个pidmap-array位图来表示当前已分配的PID号和闲置的PID号。因为一个页框包含32768个位，所以在32位体系结构中pidmap-array位图存放在一个单独的页中。然而，在64位体系结构中，当内核分配了超过当前位图大小的PID号时，需要为PID位图增加更多的页。系统会一直保存这些页不被释放。

Linux把不同的PID与系统中每个进程或轻量级进程相关联(多处理器系统上稍有例外)。这种方式能提供最大的灵活性，因为系统中每个执行上下文都可以被唯一地识别。

另一方面，Unix程序员希望同一组中的线程有共同的PID。例如，把指定PID的信号发送给组中的所有线程。事实上，POSIX 1003.1c标准规定一个多线程应用程序中的所有线程都必须有相同的PID。

遵照这个标准，Linux引入线程组的表示。一个线程组中的所有线程使用和该线程组的领头线程(thread group leader)相同的PID，也就是该组中第一个轻量级进程的PID，它被存入进程描述符的tgid字段中。getpid()系统调用（sys_getpid()）返回当前进程的tgid值而不是pid的值，因此，一个多线程应用的所有线程共享相同的PID。绝大多数进程都属于一个线程组，包含单一的成员。线程组的领头线程其tgid的值与pid的值相同，因而getpid()系统调用对这类进程所起的作用和一般进程是一样的。

从进程的PID中有效地导出它的描述符指针，效率至关重要，因为像kill()这样的很多系统调用使用PID表示所操作的进程。

#### 进程描述符处理

进程是动态实体，其生命周期范围从几毫秒到几个月。因此，内核必须能够同时处理很多进程，并把进程描述符存放在动态内存中，而不是放在永久分配给内核的内存区(线性地址在3GB之上)。

对每个进程来说，Linux都把两个不同的数据结构紧凑地存放在一个单独为进程分配的存储区域内：一个是内核态的进程堆栈，另一个是紧挨进程描述符的小数据结构thread_info，叫做线程描述符。这块存储区域的大小通常为8192个字节(两个页框)。考虑到效率的因素，内核让这8K空间占据连续的两个页框并让第一个页框的起始地址是2^13^的倍数。当几乎没有可用的动态内存空间时，就会很难找到这样的两个连续页框，因为空闲空间可能存在大量碎片。因此，在80x86体系结构中，在编译时可以进行设置，以使内核栈和线程描述符跨越一个单独的页框(4096个字节)。

在第二章“Linux中的分段”一节中我们已经知道，内核态的进程访问处于内核数据段的栈，这个栈不同于用户态的进程所用的栈。因为内核控制路径使用很少的栈，因此只需要几千个字节的内核态堆栈。所以，对栈和thread_info结构来说，8KB足够了。不过，当使用一个页框存放内核态堆栈和thread_info结构时，内核要采用一些额外的栈以防止中断和异常的深度嵌弃而引起的溢出。

下图显示了在2页(8KB)内存区中存放两种数据结构的方式。线程描述符驻留于这
个内存区的开始，而栈从末端向下增长。该图还显示了分别通过task和thread_info字段使thread_info结构与task_struct结构互相关联。

![进程内核栈.jpg](https：//github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/%E8%BF%9B%E7%A8%8B%E5%86%85%E6%A0%B8%E6%A0%88.jpg?raw=true)


esp寄存器是CPU栈指针，用来存放栈顶单元的地址。在80x86系统中，栈起始于末端，并朝这个内存区开始的方向增长。从用户态刚切换到内核态以后，进程的内核栈总是空的，因此，esp寄存器指向这个栈的顶端。

一旦数据写入堆栈，esp的值就递减。因为thread_info结构是52个字节长，因此内核栈能扩展到8140个字节。

C语言使用下列的联合结构方便地表示一个进程的线程描述符和内核栈：

```c
union thread_union {
	struct thread_info thread_info;
	unsigned long stack[THREAD_SIZE/sizeof(long)];/*2048 or 1024*/
};
```

如上图所示，thread_info结构从0x015f 0000地址处开始存放，而栈从0x015f c000地址处开始存放。esp寄存器的值指向地址为0x012f a878的当前栈顶。

内核使用alloc_thread_info和free_thread_info宏分配和释放存储thread_info结构和内核栈的内存区。

#### 标识当前进程

从效率的观点来看，thread_info结构与内核态堆栈之间的紧密结合提供的主要好处是：内核很容易从esp寄存器的值获得当前在CPU上正在运行进程的thread_ info结构的地址。如果thread_union结构长度是8K(2^13^字节)，则内核屏蔽掉esp的低13位有效位就可以获得thread_info结构的基地址。而如果thread_union结构长度是4K，内核需要屏蔽掉esp的低12位有效位。这项工作由current_thread_ info()函数来完成，它产生如下一些汇编指令：

```c
movl $0xffffe000， %ecx	/*或者是用于4K堆栈的Oxfffff000*/
andl %esp， %ecx
movl %ecx， p
```

这三条指令执行以后，p就包含在执行指令的CPU上运行的进程的thread_info结构的指针。

进程最常用的是进程描述符的地址而不是thread_info结构的地址。为了获得当前在CPU上运行进程的描述符指针，内核要调用current宏，该宏本质上等价于current_thread_info()->task，它产生如下汇编语言指令：

```c
movl $0xffffe000， %ecx	/*或者是用于4K堆栈的Oxfffff000*/
andl %esp，%ecx
movl (%ecx)，p
```

因为task字段在thread_info结构中的偏移量为0，所以执行完这三条指令之后，p就包含在CPU上运行进程的描述符指针。

current宏经常作为进程描述符字段的前缀出现在内核代码中，例如，current->pid返回在CPU上正在执行的进程的PID。

用栈存放进程描述符的另一个优点体现在多处理器系统上：如前所述，对于每个硬件处理器，仅通过检查栈就可以获得当前正确的进程。早先的Linux版本没有把内核栈与进程描述符存放在一起，而是强制引入全局静态变量current来标识正在运行进程的描述符。在多处理器系统上，有必要把current定义为一个数组，每一个元素对应一个可用CPU。

#### 进程链表

每个task_struct结构都包含一个list_head类型的tasks字段，这个类型的prev和next字段分别指向前面和后面的task_struct元素。

进程链表的头是init_task描述符，它是所谓的0进程(process 0)或swapper进程的进程描述符(参见本章“内核线程”一节)。init_task的tasks.prev字段指向链表中最后插入的进程描述符的tasks字段。

SET_LINKS和REMOVE_LINKS宏分别用于从进程链表中插入和删除一个进程描述符。这些宏考虑了进程间的父子关系(见本章后面“如何组织进程”一节)。

还有一个很有用的宏就是for_each_process，它的功能是扫描整个进程链表，其定义如下：
```c
define next_task(p)	list_entry((p)->tasks.next， struct task_struct， tasks)
define prev_task(p)	list_entry((p)->tasks.prev， struct task_struct， tasks)
define for_each_process(p) \
	for (p = &init_task ; (p = next_task(p)) != &init_task ; )
```
这个宏是循环控制语句，内核开发者利用它提供循环。注意init_task进程描述符是如何起到链表头作用的。这个宏从指向init_task的指针开始，把指针移到下一个任务，然后继续，直到又到init_task为止。在每一次循环时，传递给这个宏的参变量中存放的是当前被扫描进程描述符的地址，这与list_entry宏的返回值一样。

#### TASK_RUNNING状态的进程链表

当内核寻找一个新进程在CPU上运行时，必须只考虑可运行进程(即处在TASK_RUNNING状态的进程)。

早先的Linux版本把所有的可运行进程都放在同一个叫做运行队列(runqueue)的链表中，由于维持链表中的进程按优先级排序开销过大，因此，早期的调度程序不得不为选择“最佳”可运行进程而扫描整个队列。

Linux2.6实现的运行队列有所不同。其目的是让调度程序能在固定的时间内选出“最佳”可运行进程，与队列中可运行的进程数无关。第七章会详细描述这种新的运行队列。

提高调度程序运行速度的诀窍是建立多个可运行进程链表，每种进程优先权对应一个不同的链表。每个task_struct描述符包含一个list_head类型的字段run_list。如果进程的优先权等于k(其取值范围是0到139)，run_list字段把该进程链人优先权为k的可运行进程的链表中。此外，在多处理器系统中，每个CPU都有它自己的运行队列，即它自己的进程链表集。这是一个通过使数据结构更复杂来改善性能的典型例子：调度程序的操作效率的确更高了，但运行队列的链表却为此而被拆分成140个不同的队列!

正如我们将看到的，内核必须为系统中每个运行队列保存大量的数据，不过运行队列的主要数据结构还是组成运行队列的进程描述符链表，所有这些链表都由一个单独的prio_array_t数据结构来实现，其字段说明如下表所示：

| 类型                     | 字段        | 描述                               |
| ---------------------- | --------- | -------------------------------- |
| int                    | nr_active | 链表中进程描述符的数量                      |
| unsigned long [5]      | bitmap    | 优先权位图：当且仅当某个优先权的进程链表不为空时设置相应的位标志 |
| struct list_head [140] | queue     | 140个优先权队列的头结点                    |

enqueue_task(p,array)函数把进程描述符插入某个运行队列的链表，其代码本质上等同于：

```c
static void enqueue_task(struct task_struct *p, prio_array_t *array)
{
	sched_info_queued(p);
	list_add_tail(&p->run_list, array->queue + p->prio);
	__set_bit(p->prio, array->bitmap);
	array->nr_active++;
	p->array = array;
}
```

进程描述符的prio字段存放进程的动态优先权，而array字段是一个指针，指向当前运行队列的prio_array_t数据结构。类似地，dequeue_task(p,array)函数从运行队列的链表中删除一个进程的描述符。

#### 进程间的关系

程序创建的进程具有父/子关系。如果一个进程创建多个子进程时，则子进程之间具有兄弟关系。在进程描述符中引入几个字段来表示这些关系，表示给定进程P的这些字段列在下表中。进程0和进程1是由内核创建的。稍后我们将看到，进程1  (init)是所有进程的祖先。

| 字段名         | 说明                                       |
| ----------- | ---------------------------------------- |
| real_parent | 指向创建了P的进程的描述符，如果P的父进程不再存在，就指向进程1 (init)的描述符(因此，如果用户运行一个后台进程而且退出了shell，后台进程就会成为init的子进程) |
| parent      | 指向P的当前父进程(这种进程的子进程终止时，必须向父进程发信号)。它的值通常与real_parent一致，但偶尔也可以不同，例如，当另一个进程发出监控P的ptrace()系统调用请求时(参见第二十章中“执行跟踪”一节) |
| children    | 链表的头部，链表中的所有元素都是P创建的子进程                  |
| sibling     | 指向兄弟进程链表中的下一个元素或前一个元素的指针，这些兄弟进程的父进程都是P   |

![五个进程间的亲属关系.jpg](https://github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/%E4%BA%94%E4%B8%AA%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E4%BA%B2%E5%B1%9E%E5%85%B3%E7%B3%BB.jpg?raw=true)

上图显示了一组进程间的亲属关系。进程P0接连创建了P1,P2和P3。进程P3又创建了P4。

特别要说明的是，进程之间还存在其他关系:一个进程可能是一个进程组或登录会话的领头进程(参见第一章“进程管理”一节)，也可能是一个线程组的领头进程(参见本章前面“标识一个进程”一节)，它还可能跟踪其他进程的执行(参见第二二章“执行跟踪”一节)。下表列出了进程描述符中的一些字段，这些字段建立起了进程P和其他进程之间的关系。

| 字段名             | 说明                                   |
| --------------- | ------------------------------------ |
| group_leader    | P所在进程组的领头进程的描述符指针                    |
| signal->pgrp    | P所在进程组的领头进程的PID                      |
| tgid            | P所在线程组的领头进程的PID                      |
| signal->session | P的登录会话领头进程的PID                       |
| ptrace_children | 链表的头，该链表包含所有被debugge程序跟踪的P的子进程       |
| ptrace_list     | 指向所跟踪进程其实际父进程链表的前一个和下一个元素(用于P被跟踪的时候) |

##### pidhash表及链表

在几种情况下，内核必须能从进程的PID导出对应的进程描述符指针。例如，为kill()系统调用提供服务时就会发生这种情况:当进程P1希望向另一个进程P2发送一个信号时，P1调用kill()系统调用，其参数为P2的PID，内核从这个PID导出其对应的进程描述符，然后从P2的进程描述符中取出记录挂起信号的数据结构指针。

顺序扫描进程链表并检查进程描述符的pid字段是可行但相当低效的。为了加速查找，引入了4个散列表。需要4个散列表是因为进程描述符包含了表示不同类型PID的字段(见下表)，而且每种类型的PID需要它自己的散列表。

| Hash表的类型     | 字段名     | 说明          |
| ------------ | ------- | ----------- |
| PIDTYPE_PID  | pid     | 进程的PID      |
| PIDTYPE_TGID | tgid    | 线程组领头进程的PID |
| PIDTYPE_PGID | pgrp    | 进程组领头进程的PID |
| PIDTYPE_SID  | session | 会话领头进程的PID  |

内核初始化期间动态地为4个散列表分配空间，并把它们的地址存入pid_hash数组。一个散列表的长度依赖于可用RAM的容量，例如:一个系统拥有512MB的RAM，那么每个散列表就被存在4个页框中，可以拥有2048个表项。

用pid_hashfn宏把PID转化为表索引，pid_hashfn宏展开为:

```c
#define pid_hashfn(nr) hash_long((unsigned long)nr, pidhash_shift)
```

变量pidhash_shift用来存放表索引的长度(以位为单位的长度，在我们的例子里是11位)。很多散列函数都使用hash_long()，在32位体系结构中它基本等价于：

```c
#define GOLDEN_RATIO_PRIME 0x9e370001UL
#define BITS_PER_LONG 32
static inline unsigned long hash_long(unsigned long val, unsigned int bits)
{
	unsigned long hash = val;
	/* On some cpus multiply is faster, on others gcc will do shifts */
	hash *= GOLDEN_RATIO_PRIME;
	/* High bits are more random, so use them. */
	return hash >> (BITS_PER_LONG - bits);
}
```

因为在我们的例子中pidhash_shift等于11，所以pid_hashfn的取值范围是0到2^11^-1=2047。

散列(hash)函数并不总能确保PID与表的索引一一对应。两个不同的PID散列(hash)到相同的表索引称为冲突(colliding)。

```
魔数常量：常量0x9e370001究竟是怎么得出的？这种散列函数是基于表索引乘以一个适当的大数，于是结果溢出，就把留在32位变量中的值作为模数操作的结果。Knuth建议，要得到满意的结果，这个大乘数就应当是接近黄金比例的2^32^的一个素数(32位是80x86寄存器的大小)。这里，0x9e370001就是接近2^32^的一个素数。
```

Linux利用链表来处理冲突的PID:每一个表项是由冲突的进程描述符组成的双向链表。

具有链表的散列法比从PID到表索引的线性转换更优越，这是因为在任何给定的实例中，系统中的进程数总是远远小于32768(所允许的进程PID的最大数)。如果在任何给定的实例中大部分表项都不使用的话，那么把表定义为32768项会是一种存储浪费。

由于需要跟踪进程间的关系，PID散列表中使用的数据结构非常复杂。看一个例子:假设内核必须回收一个指定线程组中的所有进程，这意味着这些进程的tgid的值是相同的，都等于一个给定值。如果根据线程组号查找散列表，只能返回一个进程描述符，就是线程组领头进程的描述符。为了能快速返回组中其他所有进程，内核就必须为每个线程组保留一个进程链表。在查找给定登录会话或进程组的进程时也会有同样的情形。

PID散列表的数据结构解决了所有这些难题，因为它们可以为包含在一个散列表中的任何PID号定义进程链表。最主要的数据结构是四个pid结构的数组，它在进程描述符的pids字段中，下表显示pid结构的字段。

| 类型                | 名称        | 描述              |
| ----------------- | --------- | --------------- |
| int               | nr        | pid的数值          |
| struct hlist_node | pid_chain | 链接散列表的下一个和前一个元素 |
| struct list_head  | pid_list  | 每个pid的进程链表头     |

![PID散列表.jpg](https://github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/PID%E6%95%A3%E5%88%97%E8%A1%A8.jpg?raw=true)

上图给出了PIDTYPE_TGID类型散列表的例子。pid_hash数组的第二个元素存放散列表的地址，也就是用hlist_head结构的数组表示链表的头。在散列表第71项为起点形成的链表中，有两个PID号为246和4351的进程描述符(双箭头线表示一对向前和向后的指针)。PID的值存放在pid结构的nr字段中，而pid结构在进程描述符中。(顺便提一下，由于线程组的号和它的首创者的PID相同，因此这些PID值也存在进程描述符的pid字段中。)我们考虑线程组4351的PID链表:散列表中的进程描述符的pid_list字段中存放链表的头，同时每个PID链表中指向前一个元素和后一个元素的指针也存放在每个链表元素的pid_list字段中。

下面是处理PID散列表的函数和宏：

| 名称                                       | 描述                                       |
| ---------------------------------------- | ---------------------------------------- |
| #define do_each_task_pid(who, type, task)          #define while_each_task_pid(who, type, task) | 标记do-while循环的开始和结束，循环作用在PID值等于nr的PID链表上，链表的类型由参数type给出，task参数指向当前被扫描的元素的进程描述符。 |
| find_task_by_pid_type(int type, int nr)  | 在type类型的散列表中查找PID等于nr的进程。该函数返回所匹配的进程描述符指针，若没有匹配的进程，函数返回NULL。 |
| #define find_task_by_pid(nr)             | 与find_task_by_pid_type(int type, int nr)相同。 |
| attach_pid(task_t *task, enum pid_type type, int nr) | 把task指向的PID等于nr的进程描述符插人type类型的散列表中。如果一个PID等于nr的进程描述符已经在散列表中，这个函数就只把task插入已有的PID进程链表中。 |
| detach_pid(task_t *task, enum pid_type type) | 从type类型的PID进程链表中删除task所指向的进程描述符。如果删除后PID进程链表没有变为空，则函数终止，否则，该函数还要从type类型的散列表中删除进程描述符。最后，如果PID的值没有出现在任何其他的散列表中，为了这个值能够被反复使用，该函数还必须清除PID位图中的相应位。 |
| next_thread(const task_t *p)             | 返回PIDTYPE_TGID类型的散列表链表中task指示的下一个轻量级进程的进程描述符。由于散列链表是循环的，若应用于传统的进程，那么该宏返回进程本身的描述符地址。 |

#### 如何组织进程

运行队列链表把处于TASK_RUNNING状态的所有进程组织在一起。没有为处于TASK_STOPPED, EXIT_ZOMBIE或EXIT_DEAD状态的进程建立专门的链表。由于对处于暂停、僵死、死亡状态进程的访问比较简单，或者通过PID,或者通过特定父进程的子进程链表，所以不必对这三种状态进程分组。

##### 等待队列

等待队列在内核中有很多用途，尤其用在中断处理、进程同步及定时。进程必须经常等待某些事件的发生，例如，等待一个磁盘操作的终止，等待释放系统资源，或等待时间经过固定的间隔。等待队列实现了在事件上的条件等待:希望等待特定事件的进程把自己放进合适的等待队列，并放弃控制权。因此，等待队列表示一组睡眠的进程，当某一条件变为真时，由内核唤醒它们。

等待队列由双向链表实现，其元素包括指向进程描述符的指针。每个等待队列都有一个等待队列头(wait queue head)，等待队列头是一个类型为wait_queue_head_t的数据结构:

```c
struct __wait_queue_head {
	spinlock_t lock;
	struct list_head task_list;
};
typedef struct __wait_queue_head wait_queue_head_t;
```

因为等待队列是由中断处理程序和主要内核函数修改的，因此必须对其双向链表进行保护以免对其进行同时访问而导致不可预测的后果。同步是通过等待队列头中的lock自旋锁达到的。task_list字段是等待进程链表的头。

等待队列链表中的元素类型为wait_queue_t：

```c
struct __wait_queue {
	unsigned int flags;
#define WQ_FLAG_EXCLUSIVE	0x01
	struct task_struct * task;
	wait_queue_func_t func;
	struct list_head task_list;
};
typedef struct __wait_queue wait_queue_t;
```

等待队列链表中的每个元素代表一个睡眠进程，该进程等待某一事件的发生;它的描述符地址存放在task字段中。task_list字段中包含的是指针，由这个指针把一个元素链接到等待相同事件的进程链表中。

然而，要唤醒等待队列中所有睡眠的进程有时并不方便。例如，如果两个或多个进程正在等待互斥访问某一要释放的资源，仅唤醒等待队列中的一个进程才有意义。这个进程占有资源，而其他进程继续睡眠。(这就避免了所谓“雷鸣般兽群”问题，即唤醒多个进程只为了竟争一个资源，而这个资源只能有一个进程访问，结果是其他进程必须再次回去睡眠。)

因此，有两种睡眠进程:互斥进程(等待队列元素的flags字段为1)由内核有选择地唤醒，而非互斥进程(falgs值为0)总是由内核在事件发生时唤醒。等待访问临界资源的进程就是互斥进程的典型例子。等待相关事件的进程是非互斥的。例如，我们考虑等待磁盘传输结束的一组进程:一但磁盘传输完成，所有等待的进程都会被唤醒。正如我们将在下面所看到的那样，等待队列元素的fun。字段用来表示等待队列中睡眠进程应该用什么方式唤醒。

##### 等待队列操作

DECLARE_WAIT_QUEUE_HEAD(name)宏静态地声明一个叫name的等待队列的头变量并对该变量的lock和task_list字段进行初始化。函数init_waitqueue_head()可以初始化动态分配的等待队列的头变量。

函数init_waitqueue_entry(wait_queue_t *q, struct task_struct *p)初始化wait_queue_t结构的变量q：
```c
q->flags = 0;
q->task = p;
q->func = default_wake_function;
```

非互斥进程p将由default_wake_function()唤醒：

```c
int default_wake_function(wait_queue_t *curr, unsigned mode, int sync, void *key)
{
	task_t *p = curr->task;
	return try_to_wake_up(p, mode, sync);	/*第七章讨论*/
}
```

也可以选择DEFINE_WAIT宏声明一个wait_queue_t类型的新变量，并用CPU上运行的当前进程的描述符和唤醒函数autoremove_wake_function()的地址初始化这个新变量。这个函数调用default_wake_function()来唤醒睡眠进程，然后从等待队列的链表中删除对应的元素(每个等待队列链表中的一个元素其实就是指向睡眠进程描述符的指针)。最后，内核开发者可以通过init_waitqueue_func_entry()函数来自定义唤醒函数，该函数负责初始化等待队列的元素。

一旦定义了一个元素，必须把它插人等待队列。add_wait_queue()函数把一个非互斥进程插入等待队列链表的第一个位置。add_wait_queue_exclusive()函数把一个互斥进程插入等待队列链表的最后一个位置。remove_wait_queue()函数从等待队列链表中删除一个进程。waitqueue_active()函数检查一个给定的等待队列是否为空。

要等待特定条件的进程可以调用如下列表中的任何一个函数：

- sleep_on()对当前进程进行操作：

  ```c
  #define	SLEEP_ON_VAR					\
  	unsigned long flags;				\
  	wait_queue_t wait;				\
  	init_waitqueue_entry(&wait, current);

  #define SLEEP_ON_HEAD					\
  	spin_lock_irqsave(&q->lock,flags);		\
  	__add_wait_queue(q, &wait);			\
  	spin_unlock(&q->lock);

  #define	SLEEP_ON_TAIL					\
  	spin_lock_irq(&q->lock);			\
  	__remove_wait_queue(q, &wait);			\
  	spin_unlock_irqrestore(&q->lock, flags);

  void fastcall __sched sleep_on(wait_queue_head_t *q)
  {
  	SLEEP_ON_VAR

  	current->state = TASK_UNINTERRUPTIBLE;

  	SLEEP_ON_HEAD
  	schedule();
  	SLEEP_ON_TAIL
  }
  ```

  该函数把当前进程的状态设置为TASK_UNINTERRUPTIBLE，并把它插入到特定的等待队列。然后，它调用调度程序，而调度程序重新开始另一个程序的执行。当睡眠进程被唤醒时，调度程序重新开始执行sleep_on()函数，把该进程从等待队列中删除。

- interruptible_sleep_on()函数sleep_on()函数是一样的，但此函数把当前进程状态设置为TASK_INTERRUPTIBLE，因此，接受一个信号就可以唤醒当前进程。

  ```c
  void fastcall __sched interruptible_sleep_on(wait_queue_head_t *q)
  {
  	SLEEP_ON_VAR

  	current->state = TASK_INTERRUPTIBLE;

  	SLEEP_ON_HEAD
  	schedule();
  	SLEEP_ON_TAIL
  }
  ```


- sleep_on_timeout()和interruptible_sleep_on timeout()与前面函数类似，但它们允许调用者定义一个时间间隔，过了这个间隔以后，进程将由内核唤醒。为了做到这点，它们调用schedule_timeout()函数而不是schedule()函数(参见第六章中“动态定时器的应用”一节)。


- 在Linux 2.6中引入的prepare_to_wait(), prepare_to_wait_exclusive()和
  finish_wait()函数提供了另外一种途径来使当前进程在一个等待队列中睡眠。它们的典型应用如下：

  ```c
  DEFINE_WAIT(wait);
  prepare_to_wait exclusive(&wq, &wait，TASK_INTERRUPTIBLE);
                                            /*wq是等待队列的头*/
  ...
  if(!condition)
  	schedule();
  finish_wait(&wq,&wait)
  ```
  函数prepare_to_wait()和prepare_to_wait_ exclusive()用传递的第三个参数设置进程的状态，然后把等待队列元素的互斥标志flag分别设置为0(非互斥)或1(互斥)，最后，把等待元素wait插人到以wq为头的等待队列的链表中。

  进程一但被唤醒就执行finish_wait()函数，它把进程的状态再次设置为TASK RUNNING(仅发生在调用schedule()之前，唤醒条件变为真的情况下)，并从等待队列中删除等待元素(除非这个工作已经由唤醒函数完成)。

- wait_event和wait_event_interruptible宏使它们的调用进程在等待队列上睡眠，一直到修改了给定条件为止。例如，宏wait_event(wq,condition)本质上实现下面的功能：

  ```c
  #define __wait_event(wq, condition) 					\
  do {									\
  	DEFINE_WAIT(__wait);						\
  									\
  	for (;;) {							\
  		prepare_to_wait(&wq, &__wait, TASK_UNINTERRUPTIBLE);	\
  		if (condition)						\
  			break;						\
  		schedule();						\
  	}								\
  	finish_wait(&wq, &__wait);					\
  } while (0)

  #define wait_event(wq, condition) 					\
  do {									\
  	if (condition)	 						\
  		break;							\
  	__wait_event(wq, condition);					\
  } while (0)
  ```

对上面列出的函数做一些说明:sleep_on()类函数在以下条件下不能使用，那就是必须测试条件并且当条件还没有得到验证时又紧接着让进程去睡眠;由于那些条件是众所周知的竞争条件产生的根源，所以不鼓励这样使用。此外，为了把一个互斥进程插人等待队列，内核必须使用prepare_to_wait_exclusive()函数[或者只是直接调用add_wait_queue_exclusive()]。所有其他的相关函数把进程当作非互斥进程来插人。最后，除非使用DEFINE_WAIT或finish_wait()，否则内核必须在唤醒等待进程后从等待队列中删除对应的等待队列元素。

内核通过下面的任何一个宏唤醒等待队列中的进程并把它们的状态置为TASK_RUNNING：
wake_up、wake_up_nr、wake_up_all、wake_up_interruptible、wake_up_interruptible_nr、wake_up_interruptible_all、
wake_up_interruptible_sync和wake_up_locked。从每个宏的名字我们可以明白其功能：

- 所有宏都考虑到处于TASK_INTERRUPTIBLE状态的睡眠进程;如果宏的名字中不含字符串”interruptible"，那么处于TASK_UNINTERRUPTIBLE状态的睡眠进程也被考虑到。
- 所有宏都唤醒具有请求状态的所有非互斥进程(参见上一项)。    名字中含有“nr”字符串的宏唤醒给定数的具有请求状态的互斥进程;这个数字是
- 宏的一个参数。名字中含有“all”字符串的宏唤醒具有请求状态的所有互斥进程。最后，名字中不含“nr”或“all”字符串的宏只唤醒具有请求状态的一个互斥进程。
- 名字中不含有“sync”字符串的宏检查被唤醒进程的优先级是否高于系统中正在运行进程的优先级，并在必要时调用schedule()。这些检查并不是由名字中含有“sync”字符串的宏进行的，造成的结果是高优先级进程的执行稍有延迟。
- wake_up_locked宏和wake_up宏相类似，仅有的不同是当wait_queue_head_t中的自旋锁已经被持有时要调用wake_up_locked。

例如，wake_up宏等价于下列代码片段：

```c
void wake_up(wait_queue_head_t *q)
{
	struct list_head *tmp;
	wait_queue_t *curr;
	list_for_each(tmp, &q->task_list){
		curr=list_entry(tmp, wait_queue_t，task_list)
		if (curr->func(curr, TASK_INTERRUPTIBLE|TASK_UNINTERRUPTIBLE, 0, NULL) && curr->flags)
			break;
	}
}
```
list_for_each宏扫描双向链表q->task_list中的所有项，即等待队列中的所有进程。对每一项，list_entry宏都计算wait_queue_t变量对应的地址。这个变量的func字段存放唤醒函数的地址，它试图唤醒由等待队列元素的task字段标识的进程。如果一个进程已经被有效地唤醒(函数返回1)并且进程是互斥的(curr->flags等于1)，循环结束。因为所有的非互斥进程总是在双向链表的开始位置，而所有的互斥进程在双向链表的尾部，所以函数总是先唤醒非互斥进程然后再唤醒互斥进程，如果有进程存在的话(一个队列同时包含互斥和非互斥进程的情况是非常罕见的)。

#### 进程资源限制

每个进程都有一组相关的资源限制(resource limit)，限制指定了进程能使用的系统资源数量。这些限制避免用户过分使用系统资源(CPU、磁盘空间等)。

对当前进程的资源限制存放在current->signal->rlim字段，即进程的信号描述符的一个字段(参见第十一章“与信号相关的数据结构”一节)。该字段是类型为rlimit结构的数组，每个资源限制对应一个元素：

```c
struct rlimit {
	unsigned long	rlim_cur;
	unsigned long	rlim_max;
};
```

| 字段名               | 说明                                       |
| ----------------- | ---------------------------------------- |
| RLIMIT_CPU (0)    | 进程使用CPU的最长时间(以秒为单位)。如果进程超过了这个限制，内核就向它发一个SIGXCPU信号，然后如果进程还不终止，再发一个SIGKILL信号(参见第十一章) |
| RLIMIT_FSIZE      | 文件大小的最大值(以字节为单位)。如果进程试图把一个文件的大小扩充到大于这个值，内核就给这个进程发SIGXFSZ信号 |
| RLIMIT_DATA       | 堆大小的最大值(以字节为单位)。在扩充进程的堆之前，内核检查这个值(参见第九章中“堆的管理”一节) |
| RLIMIT_STACK      | 栈大小的最大值(以字节为单位)。内核在扩充进程的用户态堆栈之前检查这个值(参见第九章“异常处理”一节) |
| RLIMIT_CORE       | 内存信息转储文件的大小(以字节为单位)。当一个进程异常终止时，内核在进程的当前目录下创建内存信息转储文件之前检查这个值(参见第十一章的“传递信号之前所执行的操作”一节)。如果这个限制为0，那么，内核就不创建这个文件 |
| RLIMIT_RSS (5)    | 进程所拥有的页框最大数(目前是非强制的)                     |
| RLIMIT_NPROC      | 用户能拥有的进程最大数(参见本章“clone(), fork()及vfork()系统调用”一节) |
| RLIMIT_NOFILE     | 打开文件描述符的最大数。当打开一个新文件或复制一个文件描述符时，内核检查这个值(参见第十二章) |
| RLIMIT_MEMLOCK    | 非交换内存的最大值(以字节为单位)。当进程试图通过mlock()或mlockall()系统调用锁住一个页框时，内核检查这个值(参见第九章“分配线性地址区间”一节) |
| RLIMIT_AS         | 进程地址空间的最大数(以字节为单位)。当进程使用malloc()或相关函数扩大它的地址空间时，内核检查这个值(参见第九章“进程的地址空间”一节) |
| RLIMIT_LOCKS (10) | 文件锁的最大值(目前是非强制的)                         |
| RLIMIT_SIGPENDING | 进程挂起信号的最大数(参见第十一章)                       |
| RLIMIT_MSGQUEUE   | POSIX消息队列中的最大字节数(参见第十九章“POSIX消息队列”一节)    |
| RLIMIT_NICE       |                                          |
| RLIMIT_RTPRIO     | 最大实时优先级                                  |

rlim_cur 表示资源的当前限制，例如 current->signal->rlim[RLIMIT_CPU]，rlim_cur表示正运行进程所占用CPU时间的当前限制。

rlim_max字段是资源限制所允许的最大值。利用getrlimit()和setrlimit()系统调用，用户总能把一些资源的rlim_cur限制增加到rlim_max。然而，只有超级用户(或更确切地说，具有CAP_SYS_RESOURCE权能的用户)才能改变rlim_max字段，或把rlim_cur字段设置成大于相应rlim_max字段的一个值。

大多数资源限制包含值RLIMIT_INFINITY(0xffffffff)，它意味着没有对相应的资源施加用户限制(当然，由于内核设计上的限制，可用RAM、可用磁盘空间等，实际的限制还是存在的)。然而，系统管理员可以给一些资源选择施加更强的限制。只要用户注册进系统，内核就创建一个由超级用户拥有的进程，超级用户能调用setrlimit()以减少一个资源rlim_max和rlim_cur字段的值。随后，同一进程执行一个login shell, 该进程就变为由用户拥有。由用户创建的每个新进程都继承其父进程rlim数组的内容，因此，用户不能忽略系统强加的限制。

### 进程切换

为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换(process switch)、任务切换(task switch)或上下文切换(context switch)。

#### 硬件上下文

尽管每个进程可以拥有属于自己的地址空间，但所有进程必须共享CPU寄存器。因此，在恢复一个进程的执行之前，内核必须确保每个寄存器装入了挂起进程时的值。

进程恢复执行前必须装入寄存器的一组数据称为硬件上下文(hardware context)。硬件上下文是进程可执行上下文的一个子集，因为可执行上下文包含进程执行时需要的所有信息。在Linux中，进程硬件上下文的一部分存放在TSS段，而剩余部分存放在内核态堆栈中。

在下面的描述中，我们假定用prev局部变量表示切换出的进程的描述符，next表示切换进的进程的描述符。因此，我们把进程切换定义为这样的行为：保存prev硬件上下文，用next硬件上下文代替prev。因为进程切换经常发生，因此减少保存和装入硬件上下文所花费的时间是非常重要的。

早期的Linux版本利用80x86体系结构所提供的硬件支持，并通过far jmp指令(far jmp 指令既修改cs寄存器，也修改eip寄存器，而简单的jmp指令只修改eip寄存器)跳到next进程TSS描述符的选择符来执行进程切换。当执行这条指令时，CPU通过自动保存原来的硬件上下文，装人新的硬件上下文来执行硬件上下文切换。但基于以下原因，Linux 2.6使用软件执行进程切换：

- 通过一组mov指令逐步执行切换，这样能较好地控制所装入数据的合法性。尤其是，这使检查ds和es段寄存器的值成为可能，这些值有可能被恶意伪造。当用单独的far jmp指令时，不可能进行这类检查。


- 旧方法和新方法所需时间大致相同。然而，尽管当前的切换代码还有改进的余地，却不能对硬件上下文切换进行优化。

进程切换只发生在内核态。在执行进程切换之前，用户态进程使用的所有寄存器内容都已保存在内核态堆栈上(参见第四章)，这也包括ss和esp这对寄存器的内容(存储用户态堆栈指针的地址)。

#### 任务状态段

80x86体系结构包括了一个特殊的段类型，叫任务状态段(Task State Segment ,TSS)来存放硬件上下文。尽管Linux并不使用硬件上下文切换，但是强制它为系统中每个不同的CPU创建一个TSS。这样做的两个主要理由为：

- 当80x86的一个CPU从用户态切换到内核态时，它就从TSS中获取内核态堆栈的地址(参见第四章“中断和异常的硬件处理”一节和第十章“通过sysenter指令发送系统调用”一节)。


- 当用户态进程试图通过in或out指令访问一个I/O端口时，CPU需要访问存放在TSS中的I/O许可权位图(Permission Bitmap)以检查该进程是否有访问端口的权力。

  更确切地说，当进程在用户态下执行in或out指令时，控制单元执行下列操作：

  1. 它检查eflags寄存器中的2位IOPL字段。如果该字段值为3，控制单元就执行I/O指令。否则，执行下一个检查。
  2. 访问tr寄存器以确定当前的TSS和相应的I/O许可权位图。
  3. 检查I/O指令中指定的I/O端口在I/O许可权位图中对应的位。如果该位清0，这条I/O指令就执行，否贝控制单元产生一个“General protection”异常。

tss_struct结构描述TSS的格式。正如第二章所提到的，init_tss数组为系统上每个不同的CPU存放一个TSS。在每次进程切换时，内核都更新TSS的某些字段以便相应的CPU控制单元可以安全地检索到它需要的信息。因此，TSS反映了CPU上的当前进程的特权级，但不必为没有在运行的进程保留TSS。

```c
struct tss_struct {
	u32 reserved1;
	u64 rsp0;	
	u64 rsp1;
	u64 rsp2;
	u64 reserved2;
	u64 ist[7];
	u32 reserved3;
	u32 reserved4;
	u16 reserved5;
	u16 io_bitmap_base;
	/*
	 * The extra 1 is there because the CPU will access an
	 * additional byte beyond the end of the IO permission
	 * bitmap. The extra byte must be all 1 bits, and must
	 * be within the limit. Thus we have:
	 *
	 * 128 bytes, the bitmap itself, for ports 0..0x3ff
	 * 8 bytes, for an extra "long" of ~0UL
	 */
	unsigned long io_bitmap[IO_BITMAP_LONGS + 1];
} __attribute__((packed)) ____cacheline_aligned;
```

每个TSS有它自己8字节的任务状态段描述符(Task State Segment Descriptor, TSSD )。这个描述符包括指向TSS起始地址的32位Base字段，20位Limit字段。TSSD的S标志位被清0，以表示相应的TSS是系统段的事实(参见第二章“段描述符”一节)。

Type字段置为11或9以表示这个段实际上是一个TSS。在Intel的原始设计中，系统中的每个进程都应当指向自己的TSS；Type字段的第二个有效位叫做Busy位，如果进程正由CPU执行，则该位置1，否则置0。在Linux的设计中，每个CPU只有一个TSS,因此，Busy位总置为1。

由Linux创建的TSSD存放在全局描述符表(GDT)中，GDT的基地址存放在每个CPU的gdtr寄存器中。每个CPU的tr寄存器包含相应TSS的TSSD选择符，也包含了两个隐藏的非编程字段:TSSD的Base字段和Limit字段。这样，处理器就能直接对TSS寻址而不用从GDT中检索TSS的地址。

##### thread字段

在每次进程切换时，被替换进程的硬件上下文必须保存在别处。不能像Intel原始设计那样把它保存在TSS中，因为Linux为每个处理器而不是为每个进程使用TSS。

因此，每个进程描述符包含一个类型为thread_struct的thread字段，只要进程被切换出去，内核就把其硬件上下文保存在这个结构中。随后我们会看到，这个数据结构包含的字段涉及大部分CPU寄存器，但不包括诸如eax,ebx等等这些通用寄存器，它们的值保留在内核堆栈中。

#### 执行进程切换

进程切换可能只发生在精心定义的点:schedule()函数(在第七章会用很长的篇幅来讨论)。这里，我们仅关注内核如何执行一个进程切换。

从本质上说，每个进程切换由两步组成：

1. 切换页全局目录以安装一个新的地址空间（在第九章描述这一步）。
2. 切换内核态堆栈和硬件上下文，因为硬件上下文提供了内核执行新进程所需要的所有信息，包含CPU寄存器。

假定prev指向被替换进程的描述符，而next指向被激活进程的描述符。

##### switch_to宏

进程切换的第二步由switch_to宏执行。它是内核中与硬件关系最密切的例程之一，首先，该宏有三个参数，它们是prev，next和last。prev和next是局部变量prev和next的占位符，即它们是输入参数，分另表示被替换进程和新进程描述符的地址在内存中的位置。

那第三个参数last呢？在任何进程切换中，涉及到三个进程而不是两个。假设内核决定暂停进程A而激活进程B。在schedule()函数中，prev指向A的描述符而next指向B的描述符。switch_to宏一但使A暂停，A的执行流就冻结。

随后，当内核想再次此激活A，就必须暂停另一个进程C(这通常不同于B)，于是就要用prev指向C而next指向A来执行另一个switch_to宏。当A恢复它的执行流时，就会找到它原来的内核栈，于是prev局部变缺还是指向A的描述符而next指向B的描述符。此时，代表进程A执行的内核就失去了对C的任何引用。但是，事实表明这个引用对于完成进程切换是很有用的(更多细节参见第七章)。

switch_to宏的最后一个参数是输出参数，它表示宏把进程C的描述符地址写在内存的什么位置了(这是在A恢复执行之后完成的)。在进程切换之前，宏把第一个输入参数prey(即在A的内核堆栈中分配的prev局部变量)表示的变量的内容存人CPU的eax寄存器。在完成进程切换，A已经恢复执行时，宏把CPU的eax寄存器的内容写入由第三个输出参数——last所指示的A在内存中的位置。因为CPU寄存器不会在切换点发生变化，所以C的描述符地址也存在内存的这个位置。在schedule()执行过程中，参数last指向A的局部变量prev，所以prev被C的地址覆盖。

下图显示了进程A,B,C内核堆栈的内容以及eax寄存器的内容。必须注意的是：图中显示的是在被eax寄存器的内容覆盖以前的prev局部变量的值。

![通过一个进程切换保留对进程C的引用.jpg](https://github.com/LiuChengqian90/Study-notes/blob/master/image/Linux/%E9%80%9A%E8%BF%87%E4%B8%80%E4%B8%AA%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2%E4%BF%9D%E7%95%99%E5%AF%B9%E8%BF%9B%E7%A8%8BC%E7%9A%84%E5%BC%95%E7%94%A8.jpg?raw=true)

由于switch_to宏采用扩展的内联汇编语言编码，所以可读性比较差:实际上这段代码通过特殊位置记数法使用寄存器，而实际使用的通用寄存器由编译器自由选择。我们将采用标准汇编语言而不是麻烦的内联汇编语言来描述switch_to宏在80x86微处理器上所完成的典型工作。

1. 在eax和edx寄存器中分别保存prev和next的值：

   ```c
   movl prev, %eax
   movl next, %edx
   ```

2. 把eflags和ebp寄存器的内容保存在prev内核栈中。必须保存它们的原因是编译器认为在switch_to结束之前它们的值应当保持不变。

   ```c
   pushfl
   pushl $ebp
   ```

3. 把esp的内容保存到prey->thread.esp中以使该字段指向prev内核栈的栈顶：

   ```c
   movl %esp, 484(%eax)
   ```
   484(%eax)操作数表示内存单元的地址为eax内容加上484。

4. 把next->thread.esp装人esp。此时，内核开始在next的内核栈上操作，因此这条指令实际上完成了从prev到next的切换。由于进程描述符的地址和内核栈的地址紧挨着，所以改变内核栈意味着改变当前进程。
    ```c
    movl 484(%edx)，%esp
    ```

5. 把标记为1的地址(本节后面所示)存入prev->thread.eip。当被替换的进程重新恢复执行时，进程执行被标记为1的那条指令：
  ```c
  movl $lf, 480(%eax)
  ```

6. 宏把next->thread.eip的值(绝大多数情况下是一个被标记为1的地址)压入next的内核栈：
  ```c
  pushl 480(%edx)
  ```

7. 跳到\_\_switch_to() C函数：
  ```c
  jmp __switch_to
  ```

8. 这里被进程B替换的进程A再次获得CPU:它执行一些保存eflags和ebp寄存器内容的指令，这两条指令的第一条指令被标记为1。
  ```c
  1:
  	popl $ebp
  	popfl
  ```

  注意这些pop指令是怎样引用prev进程的内核栈的。当进程调度程序选择了prev作为新进程在CPU上运行时，将执行这些指令。于是，以prev作为第二个参数调用switch_to。因此，esp寄存器指向prev的内核栈。

9. 拷贝eax寄存器(上面步骤1中被装载)的内容到switch_to宏的第三个参数last标识的内存区域中 

  ```c
  movl %eax, last
  ```

  正如先前讨论的，eax寄存器指向刚被替换的进程的描述符(当前执行的schedule()函数重新使用了prev局部变量，于是汇编语言指令就是：movl %eax, prev)。


##### \_\_switch_to()函数

\_\_switch_to()函数执行大多数开始于switch_to()宏的进程切换。这个函数作用于prev_p和next_p参数，这两个参数表示前一个进程和新进程。这个函数的调用不同于一般函数的调用，因为\_\_switch_to()从eax和edx取参数prev_p和next_p(fastcall，ecx、edx，我们在前面已看到这些参数就是保存在那里)，而不像大多数函数一样从栈中取参数。为了强迫函数从寄存器取它的参数，内核利用\_\_attribute\_\_和regparm关键字，这两个关键字是C语言非标准的扩展名，由gcc编译程序实现。在include/asm-1386/system.h头文件中，\_\_switch_to()函数的声明如下：

	__switch_to(struct task_struct *prev, struct task_struct *next}
	__attribute__(regparm(3));

函数执行的步骤如下：

1. 执行由\_\_unlazy_fpu()宏产生的代码(参见本章稍后“保存和加载FPU, MMX及XMM寄存器”一节)，以有选择地保存prev_p进程的FPU, MMX及XMM寄存器的内容。

      ```c
      __unlazy_fpu(prev_p);
      ```

      ​

2. 执行smp_processor_id()宏获得本地(local)CPU的下标，即执行代码的CPU。该宏从当前进程的thread_info结构的cpu字段获得下标并将它保存到cpu局部变量。

      ​

3. 把next->thread.esp0装入对应于本地CPU的TSS的esp0字段;将在第十章的“通过sysenter指令发生系统调用”一节看到，以后任何由sysenter汇编指令产生的从用户态到内核态的特权级转换将把这个地址拷贝到esp寄存器中:

      ```c
      init_tss[cpu].esp0=next->thread.esp0;
      ```

      ​

4. 把next_p进程使用的线程局部存储(TLS)段装入本地CPU的全局描述符表;三
  个段选择符保存在进程描述符内的tls_array数组中(参见第二章的“Linu、中的
  分段”一节)。

  ```c
  cpu_gdt_table[cpu}[6] = next->thread.tls_array[0];
  cpu_gdt_table[cpu][7] = next->thread.tls_array[1];
  cpu_gdt_table[cpu][8] = next->thread.tls_array[2];
  ```

  ​

5. 把fs和gs段寄存器的内容分别存放在prev_p->thread.fs和prev_p->thread.gs
  中，对应的汇编语言指令是：

  ```C
  movl %fs，40(%esi)
  movl %gs，44(%esi)
  ```

  esi寄存器指向prev_p->thread结构。

  ​

6. 如果fs或gs段寄存器已经被prev_p或next_p进程中的任意一个使用(也就是说如果它们有一个非0的值)，则将next_p进程的thread_struct描述符中保存的值装入这些寄存器中。这一步在逻辑上补充了前一步中执行的操作。主要的汇编语言指令如下：

      ```c
       movl 40(%ebx)，%fs
       movl 44(%ebx)，%gs
      ```

       ebx寄存器指向next_p->thread结构。代码实际上更复杂，因为当它检测到一个无效的段寄存器值时，CPU可能产生一个异常。代码采用一种“修正(fix-up)”途径来考虑这种可能性(参见第十章“动态地址检查:修正代码”一节)。

      ​

7. 用next_p->thread.debugreg数组的内容装载dr0，……，dr7中的6个调试寄存器(x86调试器允许进程被硬件监控。最多可定义4个断点区域)。只有在next_p被挂起时正在使用调试寄存器(也就是说，next_p->thread.debugreg[7]字段不为0)，这种操作才能进行。这些寄存器不需要被保存，因为只有当一个调试器想要监控prev时prev_p->thread.debugreg才会被修改。

      ```c
      if  (next_p->thread.debugreg[7]){
      	loaddebug(&next_p->thread, 0);
        	loaddebug(&next_p->thread, 1);
        	loaddebug(&next_p->thread, 2);
        	loaddebug(&next_p->thread, 3);
        	/*没有4和5*/
        	loaddebug(&next_p->thread, 6);
        	loaddebug(&next_p->thread, 7);
      }
      ```

8. 如果必要，更新TSS中的I/O位图。当next_p或prev_p有其自己的定制I/O权限位图时必须这么做：

  ```c
  	if (prev}一>thread.io_bitmap_ptr || next_p->thread.io_ bitmap_ptr)
  	handle_io_bitmap(&next_p->thread, &init_tss[cpu]);
  ```


  因为进程很少修改I/O权限位图，所以该位图在“懒”模式中被处理:当且仅当一个进程在当前时间片内实际访问I/O端口时，真实位图才被拷贝到本地CPU的TSS中。进程的定制I/O权限位图被保存在thread_info结构的io_bitmap_ptr字段指向的缓冲区中。handle_io_bitmap()函数为next_p进程设置本地CPU使用的TSS的io_bitmap字段如下：

  - 如果next_p进程不拥有自己的I/O权限位图，则TSS的io_bitmap字段被设为0x8000。


  - 如果next_p进程拥有自己的I/O权限位图，则TSS的io_bitmap字段被设为0x9000。

  TSS的io_bitmap字段应当包含一个在TSS中的偏移量，其中存放实际位图。无论何时用户态进程试图访问一个1/O端口，0x8000和0x9000指向TSS界限之外并将因此引起“General protection”异常(参见第四章的“异常”一节)。do_general_protection()异常处理程序将检查保存在io_bitmap字段的值;如果是0x8000,函数发送一个SIGSEGV信号给用户态进程;如果是0x9000,函数把进程位图(由thread_info结构中的io_bitmap_ptr字段指示)拷贝到本地CPU的TSS中，把io_bitmap字段设为实际位图的偏移(104)，并强制再一次执行有缺陷的汇编语言指令。

9. 终止。\_\_switch_to() C函数通过使用下列声明结束：

      ```c
       return prev_p;
      ```

      由编译器产生的相应汇编语言指令是:
        	

      ```c
      movl %edi, %eax
      ret
      ```

      prev_p参数(现在在edi中)被拷贝到eax，因为缺省情况下任何C函数的返回值被传递给eax寄存器。注意eax的值因此在调用\_\_switch_to()的过程中被保护起来;这非常重要，因为调用switch_to宏时会假定eax总是用来存放将被替换的进程描述符的地址。

      汇编语言指令ret把栈顶保存的返回地址装人eip程序计数器。不过，通过简单地跳转到\_\_switch_to()函数来调用该函数。因此，ret汇编指令在栈中找到标号为1的指令的地址，其中标号为1的地址是由switch_to宏推入栈中的。如果因为next第一次执行而以前从未被挂起，\_\_switch_to()就找到ret_from_fork()函数的起始地址(参见本章后面“clone(),fork()和vfork()系统调用一节”)。

#### 保存和加载FPU、MMX和XMM寄存器

从Intel 80486DX开始，算术浮点单元(floating-point unit，FPU)已被集成到CPU中。数学协处理这个名词使人想起使用昂贵的专用芯片执行浮点计算的岁月。然而，为了维持与旧模式的兼容，浮点算术函数用ESCAPE指令来执行，这个指令的一些前缀字节在0xd8和0xdf之间。这些指令作用于包含在CPU中的浮点寄存器集。显然，如果一个进程正在使用ESCAPE指令，那么，浮点寄存器的内容就属于它的硬件上下文，并且应该被保存。

在最近的Pentium模型中，Intel在它的微处理器中引入一个新的汇编指令集，叫做MMX指令，用来加速多媒体应用程序的执行。MMX指令作用于FPU的浮点寄存器。选择这种体系结构的明显缺点是编程者不能把浮点指令与MMX指令混在一起使用。优点是操作系统设计者能忽视新指令集，因为保存浮点单元状态的任务切换代码可以不加修改地应用到保存MMX状态。

MMX指令加速了多媒体应用程序的执行，因为它们在处理器内部引入了单指令多数据(single-instruction multiple-data，SIMD )流水线。Pentium III模型扩展了这种SIMD能力：它引入SSE扩展(Streaming SIMD Extensions)，该扩展为处理包含在8个128位寄存器(叫做XMM寄存器)的浮点值增加了功能。这样的寄存器不与FPU和MMX寄存器重叠，因此SSE和FPU/MMX指令可以随意地混合。Pentium 4模型指令还引入另一种特点:SSE2扩展，该扩展基本上是SSE的一个扩展，支持高精度浮点值。SSE2与SSE使用同一XMM寄存器集。

80x86微处理器并不在TSS中自动保存FPU、MMX和XMM寄存器。不过，它们包含某种硬件支持，能在需要时保存这些寄存器的值。硬件支持由cr0寄存器中的一个TS(Task-Switching)标志组成，遵循以下规则：

- 每当执行硬件上下文切换时，设置TS标志。

- 每当TS标志被设置时执行ESCAPE,  MMX, SSE或SSE2指令，控制单元就产生一个“Device not available”异常(参见第四章)。

TS标志使得内核只有在真正需要时才保存和恢复FPU, MMX和XMM寄存器。为了说明它如何工作，假设进程A使用数学协处理器。当发生上下文切换时，内核置TS标志并把浮点寄存器保存在进程A的TSS中。如果新进程B不利用协处理器，内核就不必恢复浮点寄存器的内容。但是，只要B打算执行ESCAPE或MMX指令，CPU就产生一个“Device not available”异常，并且相应的异常处理程序用保存在进程B中的TSS的值装载浮点寄存器。

现在，让我们描述为处理FPU、MMX和XMM寄存器的选择性装入而引入的数据结构。它们存放在进程描述符的thread.i387子字段中，其格式由i387_union联合体描述：
```c
union i387_union{
	struct i387_fsave_struct fsave;
  	struct i387_fxsave_struct fxsave;
	struct i387_soft_struct soft;
};
```

正如看到的，这个字段只可以存放三种不同数据结构中的一种。i387\_soft_struct结构由无数学协处理器的CPU模型使用;Linux内核通过软件模拟协处理器来支持这些老式芯片。不过，不打算进一步讨论这种遗留问题。i387\_fsave_struct结构由具有数学协处理器、也可能有MMX单元的CPU模型使用。最后，i387_fxsave_struct结构由具有SSE和SSE2扩展功能的CPU模型使用。

进程描述符包含两个附加的标志:

- 包含在thread_info描述符的status字段中的TS_USEDFPU标志。它表示进程在当前执行的过程中是否使用过FPU、MMX和XMM寄存器。
- 包含在task_struct描述符的flags字段中的PF_USED_MATH标志。这个标志表示thread.i387子字段的内容是否有意义。该标志在两种情况下被清0(没有意义)，如下所示：
  - 当进程调用execve()系统调用(参见第二十章)开始执行一个新程序时。因为控制权将不再返回到前一个程序，所以当前存放在thread.i387中的数据也不再使用。
  - 当在用户态下执行一个程序的进程开始执行一个信号处理程序时(参见第十一章)。因为信号处理程序与程序的执行流是异步的，因此，浮点寄存器对信号处理程序来说可能是毫无意义的。不过，内核开始执行信号处理程序之前在thread.i387中保存浮点寄存器，处理程序结束以后恢复它们。因此，信号处理程序可以使用数学协处理器。

##### 保存FPU寄存器

如前所述，\_\_switch_to()函数把被替换进程prev的描述符作为参数传递给\_\_unlazy_fpu宏，并执行该宏。这个宏检查prev的TS_USEDFPU标志值。如果该标志被设置，说明prev在这次执行中使用了FPU,MMX,SSE或SSE2指令;因此内核必须保存相关的硬件上下文：

```c
#define __unlazy_fpu( tsk ) do { \
	if ((tsk)->thread_info->status & TS_USEDFPU) \
		save_init_fpu( tsk ); \
} while (0)
```

save_init_fpu()函数依次执行下列操作：

1. 把FPU寄存器的内容转储到prev进程描述符中，然后重新初始化FPU。如果CPU使用SSE/SSE2扩展，则还应该转储XMM寄存器的内容，井重新初始化SSE/SSE2单元。一对功能强大的嵌入式汇编语言指令处理每件事情，如果CPU使用SSE/SSE2扩展，则：

   ```c
   asm volatile( "fxsave %0 ; fnclex"
   			      : "=m" (tsk->thread.i387.fxsave) );
   ```

   否则：

   ```c
   asm volatile( "fnsave %0 ; fwait"
   			      : "=m" (tsk->thread.i387.fsave) );
   ```

2. 重置prev的TS_USEDFPU标志：

   ```c
   tsk->thread_info->status &= ~TS_USEDFPU;
   ```

3. 用stts()宏设置cr0的TS标志，实际上，该宏产生下面的汇编语言指令：

   ```c
   movl %cr0，%eax
   orl $8，%eax
   movl %eax，%cr0
   ```

   ​

##### 装载FPU寄存器

当next进程刚恢复执行时，浮点寄存器的内容还没有被恢复，不过，cr0的TS标志位已由\_\_unlazy_fpu()设置。因此，next进程第一次试图执行ESCAPE, MMX或SSE/SSE2指令时，控制单元产生一个“Device not available”异常，内核(更确切地说，由异常调用的异常处理程序)运行math_state_restore()函数。处理程序把next进程当作current进程。

```c
asmlinkage void math_state_restore(struct pt_regs regs)
{
	struct thread_info *thread = current_thread_info();
	struct task_struct *tsk = thread->task;

	__asm__ __volatile__ ("clts")		/* Allow maths ops (or we recurse) ;clear the TS flag of cr0 */
	if (!((tsk)->flags & PF_USED_MATH))
		init_fpu(tsk);
	restore_fpu(tsk);
	thread->status |= TS_USEDFPU;	/* So we fnsave on switch_to() */
}
```

这个函数清cr0的TS标志，以便进程以后执行FPU, MMX或SSE/SSE2指令时不再触发“设备不可用”的异常。如果thread.i387子字段中的内容是无效的，也就是说，如果PF_USED_ MATH标志等于0，就调用init_fpu()重新设置thread.i387子字段，并把PF_USED_MATH标志的当前值置为1。 restore_fpu()函数把保存在thread.i387子字段中的适当值载入FPU寄存器。为此，根据CPU是否支持SSE/SSE2扩展来使用fxrstor或frstor汇编语言指令。最后，math_state_restore()设置TS_USEDFPU标志。

##### 在内核态使用FPU、MMX和SSE/SSE2单元

内核也可以使用FPU,MMX和SSE/SSE2单元。当然，这样做的时候，应该避免干扰用户态进程所进行的任何计算。因此：

- 在使用协处理器之前，如果用户态进程使用了FPU(TS_USEDFPU标志)，内核必须调用kernel_fpu_begin()，其本质就是调用save_init_fpu()来保存寄存器的内容，然后重新设置cr0寄存器的TS标志。
- 在使用完协处理器之后，内核必须调用kernel_fpu_end()设置cr0寄存器的TS标志。

稍后，当用户态进程执行协处理器指令时，math_state_restore()函数将恢复寄存器的内容(就像处理进程切换那样)。

但是，应该注意，当前用户态进程正在使用协处理器时，kernel_fpu_begin()的执行时间相当长，以至于无法通过使用FPU,MMX或SSE/SSE2单元达到加速的目的。实际上，内核只在有限的场合使用FPU, MMX或SSE/SSE2单元，典型的情况有：当移动或清除大内存区字段时，或者当计算校验和函数时。

### 创建进程

Unix操作系统紧紧依赖进程创建来满足用户的需求。例如，只要用户输入一条命令，shell进程就创建一个新进程，新进程执行shell的另一个拷贝。

传统的Unix操作系统以统一的方式对待所有的进程:子进程复制父进程所拥有的资源。这种方法使进程的创建非常慢且效率低，因为子进程需要拷贝父进程的整个地址空间。实际上，子进程几乎不必读或修改父进程拥有的所有资源，在很多情况下，子进程立即调用execve()，并清除父进程仔细拷贝过来的地址空间。

现代Unix内核通过引入三种不同的机制解决了这个问题：

- 写时复制技术允许父子进程读相同的物理页。只要两者中有一个试图写一个物理页，内核就把这个页的内容拷贝到一个新的物理页，并把这个新的物理页分配给正在写的进程。第九章将全面地解释这种技术在Linux中的实现。

- 轻量级进程允许父子进程共享每进程在内核的很多数据结构，如页表(也就是整个用户态地址空间)、打开文件表及信号处理。

- vfork()系统调用创建的进程能共享其父进程的内存地址空间。为了防止父进程重写子进程需要的数据，阻塞父进程的执行，一直到子进程退出或执行一个新的程序为止。

#### clone()、fork()及vfork()系统调用

在Linux中，轻量级进程是由名为clone()的函数创建的，这个函数使用下列参数：

| 参数          | 描述                                       |
| ----------- | ---------------------------------------- |
| fn          | 指定一个由新进程执行的函数。当这个函数返回时，子进程终止。函数返回一个整数，表示子进程的退出代码。 |
| arg         | 指向传递给fn()函数的数据。                          |
| flags       | 各种各样的信息。低字节指定子进程结束时发送到父进程的信号代码，通常选择SIGCHLD信号。剩余的3个字节给clone标志组用于编码。 |
| child_stack | 表示把用户态堆栈指针赋给子进程的esp寄存器。调用进程(指调用clone()的    父进程)应该总是为子进程分配新的堆栈。 |
| tls         | 表示线程局部存储段(TLS)数据结构的地址，该结构是为新轻量级进程定义的(参见第二章“Linux GDT”一节)。只有在CLONE_SETTLS标志被设置时才有意义。 |
| ptid        | 表示父进程的用户态变量地址，该父进程具有与新轻量级进程相同的PID。只有在CLONE_PARENT_SETTID标志被设置时才有意义。 |
| ctid        | 表示新轻量级进程的用户态变量地址，该进程具有这一类进程的PID。只有在CLONE_CHILD_ SETTID标志被设置时才有意义。 |

clone标志：

| 标志名称                 | 说明                                       |
| -------------------- | ---------------------------------------- |
| CLONE_VM             | 共享内存描述符和所有的页表(参见第九章)                     |
| CLONE_FS             | 共享根目录和当前工作目录所在的表，以及用于屏蔽新文件初始许可权的位掩码值(所谓文件的umask ) |
| CLONE_FILES          | 共享打开文件表(参见第十二章)                          |
| CLONE_SIGHAND        | 共享信号处理程序的表、阻塞信号表和挂起信号表(参见第十一章)。如果这个标志为true,就必须设置CLONE_VM标志 |
| CLONE_PTRACE         | 如果父进程被跟踪，那么，子进程也被跟踪。尤其是，debugger程序可能希望以自己作为父进程来跟踪子进程，在这种情况下，内核把该标志强置为1 |
| CLONE_VFORK          | 在发出vfork()系统调用时设置(参见本节后面)                |
| CLONE_PARENT         | 设置子进程的父进程(进程描述符中的parent和real_parent字段)为调用进程的父进程 |
| CLONE_THREAD         | 把子进程插入到父进程的同一线程组中，并迫使子进程共享父进程的信号描述符。因此也设置子进程的tgid字段和group_leader字段。如果这个标志位为true，就必须设置CLONE_SIGRAND标志 |
| CLONE_NEWNS          | 当clone需要自己的命名空间时(即它自己的已挂载文件系统视图)设置这个标志(参见第十二章)。不能同时设置CLONE_NEWNS和CLONE_FS |
| CLONE_SYSVSEM        | 共享System V IPC取消信号量的操作(参见第十九章"IPC信号量”一节) |
| CLONE_SETTLS         | 为轻量级进程创建新的线程局部存储段(TLS)，该段由参数tls所指向的结构进行描述 |
| CLONE_PARENT_SETTID  | 把子进程的PID写入由ptid参数所指向的父进程的用户态变量           |
| CLONE_CHILD_CLEARTID | 如果该标志被设置，则内核建立一种触发机制，用在子进程要退出或要开始执行新程序时。在这些情况下，内核将清除由参数ctid所指向的用户态变量，并唤醒等待这个事件的任何进程 |
| CLONE_DETACHED       | 遗留标志.内核会忽略它                              |
| CLONE_UNTRACED       | 内核设置这个标志以使CLONE_PTRACE标志失去作用(用来禁止内核线程跟踪进程，参见本章稍后的“内核线程”一节) |
| CLONE_CHILD_SETTID   | 把子进程的PID写入由ctid参数所指向的子进程的用户态变量中          |
| CLONE_STOPPED        | 强迫子进程开始于TASK_STOPPED状态                   |

实际上，clone()是在C语言库中定义的一个封装(wrapper)函数(参见第十章“POSIX API和系统调用”一节)，它负责建立新轻量级进程的堆栈并且调用对编程者隐藏的clone()系统调用。实现clone()系统调用的sys_clone()服务例程没有fn和arg参数。实际上，封装函数把fn指针存放在子进程堆栈的某个位置处，该位置就是该封装函数本身返回地址存放的位置。arg指针正好存放在子进程堆栈中fn的下面。当封装函数结束时，CPU从堆栈中取出返回地址，然后执行fn(arg)函数。

传统的fork()系统调用在Linux中是用clone()实现的，其中clone()的flags参数指定为SIGCHLD信号及所有清0的clone标志，而它的child_stack参数是父进程当前的堆栈指针。因此，父进程和子进程暂时共享同一个用户态堆栈。但是，要感谢写时复制机制，通常只要父子进程中有一个试图去改变栈，则立即各自得到用户态堆栈的一份拷贝。

前一节描述的vfork()系统调用在Linux中也是用clone()实现的，其中clone()的参数flags指定为SIGCHLD信号和CLONE_VM及CLONE_VFORK标志，clone()的参数child_ stack等于父进程当前的栈指针。

#### do_fork()函数

do_fork()函数负责处理clone(),fork()和vfork()系统调用，执行时使用下列参数：

| 参数                         | 描述                                       |
| -------------------------- | ---------------------------------------- |
| clone_flags                | 与clone()的参数flags相同                       |
| stack_start                | 与clone()的参数child_stack相同                 |
| regs                       | 指向通用寄存器值的指针，通用寄用器的值是在从用户态切换到内核态时被保存到内核态堆栈中的(参见第四章“do_IRQ()函数”一节) |
| stack_size                 | 未使用(总是被设置为O)                             |
| parent_tidptr child_tidptr | 与clone()中的对应参数ptid和ctid相同                |

do_fork()利用辅助函数copy_process()来创建进程描述符以及子进程执行所需要的所有其他内核数据结构。下面是do_fork()执行的主要步骤：

1. 通过查找pidmap_array位图，为子进程分配新的PID(参见本章前面“标识一个进程”一节)。

2. 检查父进程的ptrace字段(current->ptrace):如果它的值不等于0，说明有另外一个进程正在跟踪父进程，因而，do_fork()检查debugger程序是否自己想跟踪子进程(独立于由父进程指定的CLONE_PTRACE标志的值)。在这种情况下，如果子进程不是内核线程(CLONE_UNTRACED标志被清0)，那么do_fork()函数设置CLONE_PTRACE标志。

3. 调用copy_process()复制进程描述符。如果所有必须的资源都是可用的，该函数返回刚创建的task_struct描述符的地址。这是创建过程的关键步骤，我们将在do_fork()之后描述它。

4. 如果设置了CLONE_STOPPED标志，或者必须跟踪子进程，即在p->ptrace中设置了PT_PTRACED标志，那么子进程的状态被设置成TASK_STOPPED，并为子进程增加挂起的SIGSTOP信号(参见第十一章“信号的作用一节)。在另外一个进程(不妨假设是跟踪进程或是父进程)把子进程的状态恢复为TASK_RUNNING之前(通常是通过发送SIGCONT信号)，子进程将一直保持TASK_STOPPED状态。

5. 如果没有设置CLONE_STOPPED标志，则调用wake_up_new_task()函数以执行下述操作：
   - 调整父进程和子进程的调度参数(参见第七章“调度算法”一节)
   - 如果子进程将和父进程运行在同一个CPU上(当内核创建新进程时，父进程可能被转移到另一个CPU上执行)，而且父进程和子进程不能共享同一组页表(CLONE_VM标志被清0)，那么，就把子进程插入父进程运行队列，插入时让子进程恰好在父进程前面，因此而迫使子进程先于父进程运行。如果子进程刷新其地址空间，并在创建之后执行新程序，那么这种简单的处理会产生较好的性能。而如果我们让父进程先运行，那么写时复制机制将会执行一系列不必要的页面复制。
   - 否则，如果子进程与父进程运行在不同的CPU上，或者父进程和子进程共享同一组页表(CLONE_VM标志被设置)，就把子进程插入父进程运行队列的队尾。
6. 如果CLONE_STOPPED标志被设置，则把子进程置为TASK_STOPPED状态。
7. 如果父进程被跟踪，则把子进程的PID存入current的ptrace_message字段并调用ptrace_notify()。ptrace_notify()使当前进程停止运行，并向当前进程的父进程发送SIGCHLD信号。子进程的祖父进程是跟踪父进程的debugger进程。SIGCHLD信号通知debugger进程:current已经创建了一个子进程，可以通过查找current->ptrace_message字段获得子进程的PID。
8. 如果设置了CLONE_VFORK标志，则把父进程插入等待队列，并挂起父进程直到子进程释放自己的内存地址空间(也就是说，直到子进程结束或执行新的程序)。
9. 结束并返回子进程的PID。

#### copy_process()函数

copy_process()创建进程描述符以及子进程执行所需要的所有其他数据结构。它的参数与do_fork()的参数相同，外加子进程的PID。下面描述copy_process()的最重要的步骤：

1. 检查参数clone_flags所传递标志的一致性。在下列情况下，它返回错误代号：
   - CLONE_NEWNS和CLONE_FS标志都被设置。
   - CLONE_THREAD标志被设置，但CLONE_SIGRAND标志被清0(同一线程组中的轻量级进程必须共享信号)。
   - CLONE_SIGHAND标志被设置，但CLONE_VM被清0(共享信号处理程序的轻量级进程也必须共享内存描述符)。
2. 通过调用security_task_create()以及稍后调用的security_task_alloc()执行所有附加的安全检查。Linux 2.6提供扩展安全性的钩子函数，与传统Unix相比，它具有更加强壮的安全模型。详情参见第二十章。
3. 调用dup_task_struct()为子进程获取进程描述符。该函数执行如下操作：
   - 如果需要，则在当前进程中调用\_\_unlazy_fpu()，把FPU,MMX和SSE/SSE2寄存器的内容保存到父进程的thread_info结构中。稍后，dup_task_struct()将把这些值复制到子进程的thread_info结构中。
   - 执行alloc_task_struct()宏，为新进程获取进程描述符(task_struct结构)，并将描述符地址保存在tsk局部变量中。
   - 执行alloc_thread_info宏以获取一块空闲内存区，用来存放新进程的thread_info结构和内核栈，并将这块内存区字段的地址存在局部变量ti中。正如在本章前面“标识一个进程”一节中所述:这块内存区字段的大小是8KB或4KB。
   - 将current进程描述符的内容复制到tsk所指向的task_struct结构中，然后把tsk->thread_ info置为ti。
   - 把current进程的thread_info描述符的内容复制到ti所指向的结构中，然后把ti->task置为tsk。
   - 把新进程描述符的使用计数器(tsk->usage)置为2，用来表示进程描述符正在被使用而且其相应的进程处于活动状态(进程状态即不是EXIT_ ZOMBIE,也不是EXIT_DEAD)。
   - 返回新进程的进程描述符指针(tsk)。
4. 检查存放在current->signal->rlim[RLIMIT_NPROC].rlim_cur变量中的值是否小于或等于用户所拥有的进程数。如果是，则返回错误码，除非进程没有root权限。该函数从每用户数据结构user_struct中获取用户所拥有的进程数。通过进程描述符user字段的指针可以找到这个数据结构。
5. 递增user_struct结构的使用计数器(tsk->user->\_\_count字段)和用户所拥有的进程的计数器(tsk->user->processes)。
6. 检查系统中的进程数量(存放在nr_threads变量中)是否超过max_threads变量的值。这个变量的缺省值取决于系统内存容量的大小。总的原则是:所有thread_info描述符和内核栈所占用的空间不能超过物理内存大小的1/8。不过，系统管理员可以通过写/proc/sys/kernel/threads-max文件来改变这个值。
7. 如果实现新进程的执行域和可执行格式的内核函数(参见第二十章)都包含在内核模块中，则递增它们的使用计数器(参见附录二)。
8. 设置与进程状态相关的几个关键字段：
   - 把大内核锁计数器tsk->lock_depth初始化为-1(参见第五章“大内核锁”一节)。
   - 把tsk->did_exec字段初始化为0；它记录了进程发出的execve()系统调用的次数。
   - 更新从父进程复制到tsk->flags字段中的一些标志:首先清除PF_SUPERPRIV标志，该标志表示进程是否使用了某种超级用户权限。然后设置PF_FORKNOEXEC标志，它表示子进程还没有发出execve()系统调用。
9. 把新进程的PID存人tsk->pid字段。
10. 如果clone_flags参数中的CLONE_PARENT_SETTID标志被设置，就把子进程的PID复制到参数parent_tidptr指向的用户态变量中。
11. 初始化子进程描述符中的list_head数据结构和自旋锁，并为与挂起信号、定时器及时间统计表相关的几个字段赋初值。
12. 调用copy_semundo()，copy_files()，copy_fs()，copy_sighand()，copy_signal() , copy_mm()和copy namespace()来创建新的数据结构，并把父进程相应数据结构的值复制到新数据结构中，除非clone_flags参数指出它们有不同的值。
13. 调用copy_thread()，用发出clone()系统调用时CPU寄存器的值(正如第十章所述，这些值已经被保存在父进程的内核栈中)来初始化子进程的内核栈。不过，copy_thread()把eax寄存器对应字段的值[这是fork()和clone()系统调用在子进程中的返回值]字段强行置为0。子进程描述符的thread.esp字段初始化为子进程内核栈的基地址，汇编语言函数(ret_from_fork())的地址存放在thread.eip字段中。如果父进程使用I/O权限位图，则子进程获取该位图的一个拷贝。最后，如果CLONE_SETTLS标志被设置，则子进程获取由clone()系统调用的参数tls指向的用户态数据结构所表示的TLS段(tls并不被传递给do_fork()和嵌套函数。在第十章会看到，通过拷贝系统调用的参数的值到某个CPU寄存器来把它们传递给内核；因此，这些值与其他寄存器一起被保存在内核态堆栈中。copy_thread()只查看esi的值在内核堆栈中对应的位置保存的地址)。
14. 如果clone_flags参数的值被置为CLONE_CHILD_SETTID或CLONE_CHILD_CLEARTID,就把child_tidptr参数的值分别复制到tsk->setchid_tid或tsk->clear_child_tid字段。这些标志说明:必须改变子进程用户态地址空间的child_tidptr所指向的变量的值，不过实际的写操作要稍后再执行。
15. 清除子进程thread_info结构的TIF_SYSCALL_TRACE标志，以使ret_from_fork()函数不会把系统调用结束的消息通知给调试进程(参见第十章“进入和退出系统调用”一节)。(因为对子进程的跟踪是由tsk->ptrace中的PTRACE_SYSCALL标志来控制的，所以子进程的系统调用跟踪不会被禁用。)
16. 用clone_flags参数低位的信号数字编码初始化tsk->exit_signal字段，如果CLONE_THREAD标志被置位，就把tsk->exit_sinal字段初始化为-1。正如我们将在本章稍后“进程终止”一节所看见的，只有当线程组的最后一个成员(通常是线程组的领头)“死亡”，才会产生一个信号，以通知线程组的领头进程的父进程。
17. 调用sched_fork()完成对新进程调度程序数据结构的初始化。该函数把新进程的状态设置为TASK_RUNNING，并把thread_info结构的preempt_count字段设置为1，从而禁止内核抢占(参见第五章“内核抢占”一节)。此外，为了保证公平的进程调度，该函数在父子进程之间共享父进程的时间片(参见第七章“scheduler_tick()函数”一节)。
18. 把新进程的thread_info结构的cpu字段设置为由smp_processor_id()所返回的本地CPU号。
19. 初始化表示亲子关系的字段。尤其是，如果CLONE_PARENT或CLONE_THREAD被设置，就用curent->real_parent的值初始化tsk->real_parent和tsk->parent,因此，子进程的父进程似乎是当前进程的父进程。否则，把tsk->real_parent和tsk->parent置为当前进程。
20. 如果不需要跟踪子进程(没有设置CLONE_PTRAC标志)，就把tsk->ptrace字段设置为O。tsk->ptrace字段会存放一些标志，而这些标志是在一个进程被另外一个进程跟踪时才会用到的。采用这种方式，即使当前进程被跟踪，子进程也不会被跟踪。
21. 执行SET_LINKS宏，把新进程描述符插人进程链表。
22. 如果子进程必须被跟踪(tsk->ptrace字段的PT_PTRACED标志被设置)，就把current->parent赋给tsk->parent，并将子进程插入调试程序的跟踪链表中。
23. 调用attach_pid()把新进程描述符的PID插入pidhash[PIDTYPE_PID]散列表。
24. 如果子进程是线程组的领头进程(CLONE_THREAD标志被清0)：
    - 把tsk->tgid的初值置为tsk->pid。
    - 把tsk->group_leader的初值置为tsk。
    - 调用三次attach_pid()，把子进程分别插入PIDTYPE_TGID, PIDTYPE_PGID和PIDTYPE_SID类型的PID散列表。
25. 否则，如果子进程属于它的父进程的线程组(CLONE_THREAD标志被设置)：
    - 把tsk->tgid的初值置为tsk->current->tgid。
    - 把tsk->group_leader的初值置为current->group_leader的值。
    - 调用attach_pid()，把子进程插入PIDTYPE_TGID类型的散列表中(更具体地说，插入current->group_leader进程的每个PID链表)。
26. 现在，新进程已经被加入进程集合:递增nr_threads变量的值。
27. 递增total_forks变量以记录被创建的进程的数量。
28. 终止并返回子进程描述符指针(tsk)。

现在，我们有了处于可运行状态的完整的子进程。但是，它还没有实际运行，调度程序要决定何时把CPU交给这个子进程。在以后的进程切换中，调度程序继续完善子进程:把子进程描述符thread字段的值装入几个CPU寄存器。特别是把thread.esp(即把子进程内核态堆栈的地址)装人esp寄存器，把函数ret_from_fork()的地址装人eip寄存器。这个汇编语言函数调用schedule_tail()函数(它依次调用finish_task_switch()来完成进程切换，参见第七章“schedule()函数”一节)，用存放在栈中的值再装载所有的寄存器，并强迫CPU返回到用户态。然后，在fork(),vfork()或clone()系统调用结束时，新进程将开始执行。系统调用的返回值放在eax寄存器中:返回给子进程的值是0，返回给父进程的值是子进程的PID。回顾copy_thread()对子进程的eax寄存器所执行的操作(copy_process()的第13步)，就能理解这是如何实现的。

除非fork系统调用返回0，否则，子进程将与父进程执行相同的代码(参见copy_process()的第13步)。应用程序的开发者可以按照Unix编程者熟悉的方式利用这一事实，在基于PID值的程序中插人一个条件语句使子进程与父进程有不同的行为。

#### 内核线程

传统的Unix系统把一些重要的任务委托给周期性执行的进程，这些任务包括刷新磁盘高速缓存，交换出不用的页框，维护网络连接等等。事实上，以严格线性的方式执行这些任务的确效率不高，如果把它们放在后台调度，不管是对它们的函数还是对终端用户进程都能得到较好的响应。因为一些系统进程只运行在内核态，所以现代操作系统把它们的函数委托给内核线程(kernel thread)，内核线程不受不必要的用户态上下文的拖累。在Linux中，内核线程在以下几方面不同于普通进程：

- 内核线程只运行在内核态，而普通进程既可以运行在内核态，也可以运行在用户态。
- 因为内核线程只运行在内核态，它们只使用大于PAGE_OFFSET的线性地址空间。另一方面，不管在用户态还是在内核态，普通进程可以用4GB的线性地址空间。

##### 创建一个内核线程

kernel_thread()函数创建一个新的内核线程，它接受的参数有:所要执行的内核函数的地址(fn)、要传递给函数的参数(arg)、一组clone标志(flags)。该函数本质上以下面的方式调用do_fork()：

```c
int kernel_thread(int (*fn)(void *), void * arg, unsigned long flags)
{
	struct pt_regs regs;

	memset(&regs, 0, sizeof(regs));

	regs.ebx = (unsigned long) fn;
	regs.edx = (unsigned long) arg;

	regs.xds = __USER_DS;
	regs.xes = __USER_DS;
	regs.orig_eax = -1;
	regs.eip = (unsigned long) kernel_thread_helper;
	regs.xcs = __KERNEL_CS;
	regs.eflags = X86_EFLAGS_IF | X86_EFLAGS_SF | X86_EFLAGS_PF | 0x2;

	/* Ok, create the new process.. */
	return do_fork(flags | CLONE_VM | CLONE_UNTRACED, 0, &regs, 0, NULL, NULL);
}
```

CLONE_VM标志避免复制调用进程的页表:由于新内核线程无论如何都不会访问用户态地址空间，所以这种复制无疑会造成时间和空间的浪费。CLONE_UNTRACED标志保证不会有任何进程跟踪新内核线程，即使调用进程被跟踪。

传递给do_fork()的参数regs表示内核栈的地址，copy_thread()函数将从这里找到为新线程初始化CPU寄存器的值。kernel_thread()函数在这个栈中保留寄存器值的目的是：

- 通过copy_thread()把ebx和edx分edx设置为参数fn和arg的值。

- 把eip寄存器的值设置为下面汇编语言代码段的地址：

  ```c
  movl %edx, %eax
  pushl %edx
  call *%ebx
  pushl %eax
  call do_exit
  ```

因此，新的内核线程开始执行fn(arg)函数，如果该函数结束，内核线程执行系统调用_exit()，并把fn()的返回值传递给它(参见本章稍后“撤消进程”一节)。

##### 进程0

所有进程的祖先叫做进程0，idle进程或因为历史的原因叫做swapper进程，它是在Linux的初始化阶段从无到有创建的一个内核线程。这个祖先进程使用下列静态分配的数据结构(所有其他进程的数据结构都是动态分配的)：

- 存放在init_task变量中的进程描述符，由INIT_TASK宏完成对它的初始化。

- 存放在init_thread_union变量中的thread_info描述符和内核堆栈，由INiT_THREAD_INFO宏完成对它们的初始化。

- 由进程描述符指向的下列表：

  ——init_mm

  ——init_fs

  ——init_files

  ——init_signals

  ——init_sighand

  这些表分别由下列宏初始化：

  ——INIT_MM

  ——INIT_FS

  ——INIT_FILES

  ——INIT_SIGNALS

  ——INIT_SIGHAND

- 主内核页全局目录存放在swapper_pg_dir中(参见第二章“内核页表”一节)。

start_kernel()函数初始化内核需要的所有数据结构，激活中断，创建另一个叫进程1的内核线程(一般叫做init进程)：

```c
kernel_thread(init, NULL, CLONE_FS | CLONE_SIGHAND);
```

新创建内核线程的PID为1，并与进程0共享每进程所有的内核数据结构。此外，当调度程序选择到它时，init进程开始执行init()函数。

创建init进程后，进程0执行cpu_idle()函数，该函数本质上是在开中断的情况下重复执行hlt汇编语言指令(参见第四章)。只有当没有其他进程处于TASK_RUNNING状态时，调度程序才选择进程O。

在多处理器系统中，每个CPU都有一个进程0。只要打开机器电源，计算机的BIOS就启动某一个CPU，同时禁用其他CPU。运行在CPU 0上的swapper进程初始化内核数据结构，然后激活其他的CPU，并通过copy_process()函数创建另外的swapper进程，把0传递给新创建的swapper进程作为它们的新PID。此外，内核把适当的CPU索引赋给内核所创建的每个进程的thread_info描述符的cpu字段。

##### 进程1

由进程0创建的内核线程执行init()函数，init()依次完成内核初始化。init()调用execve()系统调用装入可执行程序init。结果，init内核线程变为一个普通进程，且拥有自己的每进程(per-process)内核数据结构(参见第二十章)。在系统关闭之前，init进程一直存活，因为它创建和监控在操作系统外层执行的所有进程的活动。

##### 其他内核线程

Linux使用很多其他内核线程。其中一些在初始化阶段创建，一直运行到系统关闭；而其他一些在内核必须执行一个任务时“按需”创建，这种任务在内核的执行上下文中得到很好的执行。

一些内核线程的例子(除了进程0和进程1)是：

| 线程              | 描述                                       |
| --------------- | ---------------------------------------- |
| keventd(也被称为事件) | 执行keventd_wq工作队列(参见第四章)中的函数。             |
| kapmd           | 处理与高级电源管理(APM)相关的事件。                     |
| kswapd          | 执行内存回收，在第十七章“周期回收”一节将进行描述。               |
| pdflush         | 刷新“脏”缓冲区中的内容到磁盘以回收内存，在第十五章“pdflush内核线程”一 |
| kblockd         | 执行kblockd_workqueue工作队列中的函数。实质上，它周期性地激活块设备驱动程序，将在第十四章“激活块设备驱动程序”一节给予描述。 |
| ksoftirqd       | 运行tasklet(参看第四章“软中断及tasklet”一节)。系统中每个CPU都有这样一个内核线程。 |

### 撤销进程

很多进程终止了它们本该执行的代码，从这种意义上说，这些进程“死”了。当这种情况发生时，必须通知内核以便内核释放进程所拥有的资源，包括内存、打开文件及其他我们在本书中讲到的零碎东西，如信号量。

进程终止的一般方式是调用exit()库函数，该函数释放c函数库所分配的资源，执行编程者所注册的每个函数，并结束从系统回收进程的那个系统调用。exit()函数可能由编程者显式地插入。另外，C编译程序总是把exit()函数插入到main()函数的最后一条语句之后。

内核可以有选择地强迫整个线程组死掉。这发生在以下两种典型情况下：

- 当进程接收到一个不能处理或忽视的信号时(参见十一章)
- 当内核正在代表进程运行时在内核态产生一个不可恢复的CPU异常时(参见第四章)。

#### 进程终止

在Linux 2.6中有两个终止用户态应用的系统调用：

- exit_grpup()系统调用，它终止整个线程组，即整个基于多线程的应用。do_group_exit()是实现这个系统调用的主要内核函数。这是C库函数exit()应该调用的系统调用。
- exit()系统调用，它终止某一个线程，而不管该线程所属线程组中的所有其他进程。do_exit()是实现这个系统调用的主要内核函数。这是被诸如pthread_exit()的Linux线程库的函数所调用的系统调用。

#### do_group_exit()函数

do_group_exit()函数杀死属于current线程组的所有进程。它接受进程终止代号作为参数，进程终止代号可能是系统调用exit_group()(正常结束)指定的一个值，也可能是内核提供的一个错误代号(异常结束)。该函数执行下述操作：

1. 检查退出进程的SIGNAL_GROUP_EXIT标志是否不为0，如果不为0，说明内核已经开始为线程组执行退出的过程。在这种情况下，就把存放在current->signal->group_exit_code中的值当作退出码，然后跳转到第4步。

2. 否则，设置进程的SIGNAL_GROUP_EXIT标志并把终止代号存放到current->signal->group_exit_code字段。

3. 调用zap_other_threads()函数杀死current线程组中的其他进程(如果有的话)。为了完成这个步骤，函数扫描与current->tgid对应的PIDTYPE_TGID类型的散列表中的每个PID链表，向表中所有不同于current的进程发送SIGKILL信号(参
   见第十一章)，结果，所有这样的进程都将执行do_exit()函数，从而被杀死。

4. 调用do_exit()函数，把进程的终止代号传递给它。do_exit()杀死进程而且不再返回。

#### do_exit()函数

所有进程的终止都是由do_exit()函数来处理的，这个函数从内核数据结构中删除对终止进程的大部分引用。do_exit()函数接受进程的终止代号作为参数并执行下列操作：

1. 把进程描述符的flag字段设置为PF_EXITING标志，以表示进程正在被删除。
2. 如果需要，通过函数del_timer_sync()(参见第六章)从动态定时器队列中删除进程描述符。
3. 分别调用exit_mm(),exit_sem(),\_\_exit_files(),\_\_exit_fs(),exit_namespace()和exit_thread()函数从进程描述符中分离出与分页、信号量、文件系统、打开文件描述符、命名空间以及I/O权限位图相关的数据结构。如果没有其他进程共享这些数据结构，那么这些函数还删除所有这些数据结构中。
4. 如果实现了被杀死进程的执行域和可执行格式(参见第二十章)的内核函数包含在内核模块中，则函数递减它们的使用计数器。
5. 把进程描述符的exit_code字段设置成进程的终止代号，这个值要么是_exit()或exit_group()系统调用参数(正常终止)，要么是由内核提供的一个错误代号(异常终止)。
6. 调用exit_notify()函数执行下面的操作：
   - 更新父进程和子进程的亲属关系。如果同一线程组中有正在运行的进程，就让终止进程所创建的所有子进程都变成同一线程组中另外一个进程的子进程，否则让它们成为init的子进程。
   - 检查被终止进程其进程描述符的exit_signal字段是否不等于-1，并检查进程是否是其所属进程组的最后一个成员(注意:正常进程都会具有这些条件，参见前面“clone(),fork()和vfork()系统调用”一节中对copy_process()的描述，第16步)。在这种情况下，函数通过给正被终止进程的父进程发送一个信号(通常是SIGCHLD)，以通知父进程子进程死亡。
   - 否则，也就是exit_signal字段等于-1，或者线程组中还有其他进程，那么只要进程正在被跟踪，就向父进程发送一个SIGCHLD信号(在这种情况下，父进程是调试程序，因而，向它报告轻量级进程死亡的信息)。
   - 如果进程描述符的exit_signal字段等于-1，而且进程没有被跟踪，就把进程描述符的exit_state字段置为EXIT_DEAD，然后调用release_task()回收进程的其他数据结构占用的内存，并递减进程描述符的使用计数器(见下一节)。使用记数器变为1(参见copy_process()函数的第3f步)，以使进程描述符本身正好不会被释放。
   - 否则，如果进程描述符的exit_signal字段不等于-1，或进程正在被跟踪，就把exit_state字段置为EXIT_ZOMBIE。在下一节我们将看到如何处理僵死进程。
   - 把进程描述符的flags字段设置为PF_DEAD标志(参见第七章“schedule()函数”一节)。
7. 调用schedule()函数(参见第七章)选择一个新进程运行。调度程序忽略处于EXIT_ZOMBIE状态的进程，所以这种进程正好在schedule()中的宏switch_to被调用之后停止执行。正如在第七章我们将看到的:调度程序将检查被替换的僵死进程描述符的PF_DEAD标志并递减使用计数器，从而说明进程不再存活的事实。


#### 进程删除

Unix允许进程查询内核以获得其父进程的PID,或者其任何子进程的执行状态。例如，进程可以创建一个子进程来执行特定的任务，然后调用诸如wait()这样的一些库函数检查子进程是否终止。如果子进程已经终止，那么，它的终止代号将告诉父进程这个任务是否已成功地完成。

为了遵循这些设计选择，不允许Unix内核在进程一终止后就丢弃包含在进程描述符字段中的数据。只有父进程发出了与被终止的进程相关的wait()类系统调用之后，才允许这样做。这就是引入僵死状态的原因:尽管从技术上来说进程已死，但必须保存它的描述符，直到父进程得到通知。

如果父进程在子进程结束之前结束会发生什么情况呢?在这种情况下，系统中会到处是僵死的进程，而且它们的进程描述符永久占据着RAM。如前所述，必须强迫所有的孤儿进程成为init进程的子进程来解决这个问题。这样，init进程在用wait()类系统调用检查其合法的子进程终止时，就会撤消僵死的进程。

release_task()函数从僵死进程的描述符中分离出最后的数据结构；对僵死进程的处理有两种可能的方式：

- 如果父进程不需要接收来自子进程的信号，就调用do_exit()。
- 如果已经给父进程发送了一个信号，就调用wait4()或waitpid()系统调用。

在后一种情况下，函数还将回收进程描述符所占用的内存空间，而在前一种情况下，内存的回收将由进程调度程序来完成(参见第七章)。该函数执行下述步骤：

1. 递减终止进程拥有者的进程个数。这个值存放在本章前面提到的user_struct结构中(参见copy_process()的第4步)。
2. 如果进程正在被跟踪，函数将它从调试程序的ptrace_children链表中删除，并让该进程重新属于初始的父进程。

3. 调用\_\_exit_signal()删除所有的挂起信号并释放进程的signal_struct描述符。如果该描述符不再被其他的轻量级进程使用，函数进一步删除这个数据结构。此外，函数调用exit_itimers()从进程中剥离掉所有的POSIX时间间隔定时器。

4. 调用\_\_exit_sighand()删除信号处理函数。

5. 调用\_\_unhash_process() ,该函数依次执行下面的操作：
   - 变量nr_threads减1。
   - 两次调用detach_pid()，分别从PIDTYPE_PID和PIDTYPE_TGID类型的PID散列表中删除进程描述符。
   - 如果进程是线程组的领头进程，那么再调用两次detach_pid()，从PIDTYPE_PGID和PIDTYPE_SID类型的散列表中删除进程描述符。
   - 用宏REMOVE_LINKS从进程链表中解除进程描述符的链接。
6. 如果进程不是线程组的领头进程，领头进程处于僵死状态，而且进程是线程组的最后一个成员，则该函数向领头进程的父进程发送一个信号，通知它进程已死亡。
7. 调用sched_exit()函数来调整父进程的时间片(这一步在逻辑上作为对copy_process()第17步的补充)。
8. 调用put_task_struct()递减进程描述符的使用计数器，如果计数器变为0，则函数终止所有残留的对进程的引用。
   - 递减进程所有者的user_struct数据结构的使用计数器(\_\_count字段)(参见copy_process()的第5步)，如果使用计数器变为0，就释放该数据结构。
   - 释放进程描述符以及thread_info描述符和内核态堆栈所占用的内存区域。

## 第4章 中断与异常

## 第5章 内核同步

## 第6章 定时测量

## 第7章 进程调度

## 第8章 内存管理

## 第9章 进程地址空间

## 第10章 系统调用

## 第11章 信号

## 第12章 虚拟文件系统

## 第13章 I/O体系结构和设备驱动程序

## 第14章 块设备驱动程序

## 第15章 页高速缓存

## 第16章 访问文件

## 第17章 回收页框

## 第18章 Ext2和Ext3文件系统

## 第19章 进程通信

## 第20章 程序的执行

## 附录一 系统启动

## 附录二 模块